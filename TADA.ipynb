{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepare (Metric, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A_metrics = pd.read_csv(\"/home/sein/mk_config/ycsb_AA/results/external_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_metrics = pd.read_csv(\"/home/sein/mk_config/ycsb_AA/results/external_metrics.csv\")\n",
    "\n",
    "metrics = A_metrics.drop(['Unnamed: 0'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.138889</td>\n",
       "      <td>11836756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.149999</td>\n",
       "      <td>16386967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.227778</td>\n",
       "      <td>19293708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.188888</td>\n",
       "      <td>10529195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.272221</td>\n",
       "      <td>9697154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tps   latency\n",
       "0       0.216666  20847397\n",
       "1       0.322221  12744942\n",
       "2    3789.313102      1076\n",
       "3       0.166667  12510551\n",
       "4       0.266666  10686198\n",
       "..           ...       ...\n",
       "995     0.138889  11836756\n",
       "996     0.149999  16386967\n",
       "997     0.227778  19293708\n",
       "998     0.188888  10529195\n",
       "999     0.272221   9697154\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics = metrics.replace([np.inf],9999999)\n",
    "metrics = metrics.replace([np.inf],9999999)\n",
    "\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepare (Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "knob_list = glob.glob(\"/home/sein/mk_config/ycsb_AA/configs/my_*.cnf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sample</th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>stored_program_cache</th>\n",
       "      <th>sync_binlog</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>489472</td>\n",
       "      <td>200000</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>374528</td>\n",
       "      <td>50000</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>37120</td>\n",
       "      <td>660000</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>427776</td>\n",
       "      <td>430000</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>388096</td>\n",
       "      <td>880000</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>4276224</td>\n",
       "      <td>945000</td>\n",
       "      <td>610000</td>\n",
       "      <td>1</td>\n",
       "      <td>4096000</td>\n",
       "      <td>432013312</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>159744</td>\n",
       "      <td>520000</td>\n",
       "      <td>91200</td>\n",
       "      <td>8000</td>\n",
       "      <td>63</td>\n",
       "      <td>7680</td>\n",
       "      <td>163577856</td>\n",
       "      <td>57344</td>\n",
       "      <td>104448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>57000</td>\n",
       "      <td>5636096</td>\n",
       "      <td>245000</td>\n",
       "      <td>211000</td>\n",
       "      <td>1</td>\n",
       "      <td>8716288</td>\n",
       "      <td>268435456</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>455936</td>\n",
       "      <td>940000</td>\n",
       "      <td>89600</td>\n",
       "      <td>2000</td>\n",
       "      <td>29</td>\n",
       "      <td>11520</td>\n",
       "      <td>230686720</td>\n",
       "      <td>69632</td>\n",
       "      <td>61440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>622592</td>\n",
       "      <td>45000</td>\n",
       "      <td>537000</td>\n",
       "      <td>1</td>\n",
       "      <td>393216</td>\n",
       "      <td>671088640</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>308480</td>\n",
       "      <td>810000</td>\n",
       "      <td>66000</td>\n",
       "      <td>8000</td>\n",
       "      <td>48</td>\n",
       "      <td>12544</td>\n",
       "      <td>536870912</td>\n",
       "      <td>81920</td>\n",
       "      <td>108544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>5505024</td>\n",
       "      <td>700000</td>\n",
       "      <td>598000</td>\n",
       "      <td>0</td>\n",
       "      <td>9125888</td>\n",
       "      <td>834666496</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>404992</td>\n",
       "      <td>260000</td>\n",
       "      <td>70400</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>3840</td>\n",
       "      <td>218103808</td>\n",
       "      <td>36864</td>\n",
       "      <td>63488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>10420224</td>\n",
       "      <td>75000</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>8683520</td>\n",
       "      <td>838860800</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>81920</td>\n",
       "      <td>140000</td>\n",
       "      <td>81600</td>\n",
       "      <td>8000</td>\n",
       "      <td>32</td>\n",
       "      <td>5632</td>\n",
       "      <td>801112064</td>\n",
       "      <td>106496</td>\n",
       "      <td>75776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Sample automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                             1     24000            7700480   \n",
       "1                             0     15000             622592   \n",
       "2                             1      8000            7110656   \n",
       "3                             0     34000            8519680   \n",
       "4                             0     12000            6291456   \n",
       "..                          ...       ...                ...   \n",
       "995                           1     18000            4276224   \n",
       "996                           1     57000            5636096   \n",
       "997                           1      2000             622592   \n",
       "998                           0     38000            5505024   \n",
       "999                           1     10000           10420224   \n",
       "\n",
       "Sample binlog_group_commit_sync_delay   \\\n",
       "0                               485000   \n",
       "1                               140000   \n",
       "2                               440000   \n",
       "3                               760000   \n",
       "4                               380000   \n",
       "..                                 ...   \n",
       "995                             945000   \n",
       "996                             245000   \n",
       "997                              45000   \n",
       "998                             700000   \n",
       "999                              75000   \n",
       "\n",
       "Sample binlog_group_commit_sync_no_delay_count  binlog_rows_query_log_events   \\\n",
       "0                                        352000                             0   \n",
       "1                                        701000                             1   \n",
       "2                                        801000                             1   \n",
       "3                                        303000                             0   \n",
       "4                                        630000                             1   \n",
       "..                                          ...                           ...   \n",
       "995                                      610000                             1   \n",
       "996                                      211000                             1   \n",
       "997                                      537000                             1   \n",
       "998                                      598000                             0   \n",
       "999                                       35000                             1   \n",
       "\n",
       "Sample binlog_stmt_cache_size  bulk_insert_buffer_size  default_week_format   \\\n",
       "0                       655360                356515840                    7   \n",
       "1                      2637824                595591168                    5   \n",
       "2                      8093696                570425344                    4   \n",
       "3                     10420224                343932928                    3   \n",
       "4                      5472256                243269632                    1   \n",
       "..                         ...                      ...                  ...   \n",
       "995                    4096000                432013312                    0   \n",
       "996                    8716288                268435456                    1   \n",
       "997                     393216                671088640                    7   \n",
       "998                    9125888                834666496                    3   \n",
       "999                    8683520                838860800                    1   \n",
       "\n",
       "Sample div_precision_increment   ... stored_program_cache  sync_binlog   \\\n",
       "0                             1  ...                489472       200000   \n",
       "1                             8  ...                374528        50000   \n",
       "2                             4  ...                 37120       660000   \n",
       "3                             4  ...                427776       430000   \n",
       "4                            13  ...                388096       880000   \n",
       "..                          ...  ...                   ...          ...   \n",
       "995                          29  ...                159744       520000   \n",
       "996                          24  ...                455936       940000   \n",
       "997                          20  ...                308480       810000   \n",
       "998                          17  ...                404992       260000   \n",
       "999                          11  ...                 81920       140000   \n",
       "\n",
       "Sample table_definition_cache  table_open_cache  table_open_cache_instances   \\\n",
       "0                        13200              4000                          18   \n",
       "1                        91600              4000                          17   \n",
       "2                        15600                 1                           9   \n",
       "3                        11200             10000                           9   \n",
       "4                        11600              4000                          25   \n",
       "..                         ...               ...                         ...   \n",
       "995                      91200              8000                          63   \n",
       "996                      89600              2000                          29   \n",
       "997                      66000              8000                          48   \n",
       "998                      70400              2000                          57   \n",
       "999                      81600              8000                          32   \n",
       "\n",
       "Sample thread_cache_size  tmp_table_size  transaction_alloc_block_size   \\\n",
       "0                   11520       255852544                         28672   \n",
       "1                   15360       402653184                        110592   \n",
       "2                    1024       851443712                          8192   \n",
       "3                   13568       163577856                         16384   \n",
       "4                    1536       348127232                        126976   \n",
       "..                    ...             ...                           ...   \n",
       "995                  7680       163577856                         57344   \n",
       "996                 11520       230686720                         69632   \n",
       "997                 12544       536870912                         81920   \n",
       "998                  3840       218103808                         36864   \n",
       "999                  5632       801112064                        106496   \n",
       "\n",
       "Sample transaction_prealloc_size  updatable_views_with_limit   \n",
       "0                           94208                           0  \n",
       "1                           71680                           1  \n",
       "2                          122880                           0  \n",
       "3                           83968                           0  \n",
       "4                           57344                           0  \n",
       "..                            ...                         ...  \n",
       "995                        104448                           1  \n",
       "996                         61440                           0  \n",
       "997                        108544                           1  \n",
       "998                         63488                           1  \n",
       "999                         75776                           1  \n",
       "\n",
       "[1000 rows x 138 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for xx in range(len(knob_list)):\n",
    "    path = \"/home/sein/mk_config/ycsb_AA/configs/my_{}.cnf\".format(xx)\n",
    "    # knob_list = glob.glob(\"/home/sein/2023_EDBT/KCC_tpcc_dataset/my_*.cnf\")\n",
    "    a_all = pd.read_csv(path, sep=\"=\", names=['Sample', 'value'], header=2)\n",
    "    a_all = a_all.set_index(\"Sample\")\n",
    "    cur_all_df = a_all.T\n",
    "    \n",
    "    if cnt == 0:\n",
    "        A_config = cur_all_df\n",
    "    else :\n",
    "        A_config = pd.concat([A_config, cur_all_df], axis=0)\n",
    "    cnt += 1\n",
    "A_config = A_config.reset_index()\n",
    "A_config = A_config.drop([\"index\"],axis=1)\n",
    "A_config = A_config.drop(A_config.columns[[0,1]], axis=1)\n",
    "\n",
    "\n",
    "A_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all_samples = config + metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>4276224</td>\n",
       "      <td>945000</td>\n",
       "      <td>610000</td>\n",
       "      <td>1</td>\n",
       "      <td>4096000</td>\n",
       "      <td>432013312</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>91200</td>\n",
       "      <td>8000</td>\n",
       "      <td>63</td>\n",
       "      <td>7680</td>\n",
       "      <td>163577856</td>\n",
       "      <td>57344</td>\n",
       "      <td>104448</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>11836756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>57000</td>\n",
       "      <td>5636096</td>\n",
       "      <td>245000</td>\n",
       "      <td>211000</td>\n",
       "      <td>1</td>\n",
       "      <td>8716288</td>\n",
       "      <td>268435456</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>89600</td>\n",
       "      <td>2000</td>\n",
       "      <td>29</td>\n",
       "      <td>11520</td>\n",
       "      <td>230686720</td>\n",
       "      <td>69632</td>\n",
       "      <td>61440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>16386967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>622592</td>\n",
       "      <td>45000</td>\n",
       "      <td>537000</td>\n",
       "      <td>1</td>\n",
       "      <td>393216</td>\n",
       "      <td>671088640</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>66000</td>\n",
       "      <td>8000</td>\n",
       "      <td>48</td>\n",
       "      <td>12544</td>\n",
       "      <td>536870912</td>\n",
       "      <td>81920</td>\n",
       "      <td>108544</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227778</td>\n",
       "      <td>19293708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>5505024</td>\n",
       "      <td>700000</td>\n",
       "      <td>598000</td>\n",
       "      <td>0</td>\n",
       "      <td>9125888</td>\n",
       "      <td>834666496</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>70400</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>3840</td>\n",
       "      <td>218103808</td>\n",
       "      <td>36864</td>\n",
       "      <td>63488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188888</td>\n",
       "      <td>10529195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>10420224</td>\n",
       "      <td>75000</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>8683520</td>\n",
       "      <td>838860800</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>81600</td>\n",
       "      <td>8000</td>\n",
       "      <td>32</td>\n",
       "      <td>5632</td>\n",
       "      <td>801112064</td>\n",
       "      <td>106496</td>\n",
       "      <td>75776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272221</td>\n",
       "      <td>9697154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                          1     24000            7700480   \n",
       "1                          0     15000             622592   \n",
       "2                          1      8000            7110656   \n",
       "3                          0     34000            8519680   \n",
       "4                          0     12000            6291456   \n",
       "..                       ...       ...                ...   \n",
       "995                        1     18000            4276224   \n",
       "996                        1     57000            5636096   \n",
       "997                        1      2000             622592   \n",
       "998                        0     38000            5505024   \n",
       "999                        1     10000           10420224   \n",
       "\n",
       "    binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                            485000                                   352000   \n",
       "1                            140000                                   701000   \n",
       "2                            440000                                   801000   \n",
       "3                            760000                                   303000   \n",
       "4                            380000                                   630000   \n",
       "..                              ...                                      ...   \n",
       "995                          945000                                   610000   \n",
       "996                          245000                                   211000   \n",
       "997                           45000                                   537000   \n",
       "998                          700000                                   598000   \n",
       "999                           75000                                    35000   \n",
       "\n",
       "    binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                               0                  655360   \n",
       "1                               1                 2637824   \n",
       "2                               1                 8093696   \n",
       "3                               0                10420224   \n",
       "4                               1                 5472256   \n",
       "..                            ...                     ...   \n",
       "995                             1                 4096000   \n",
       "996                             1                 8716288   \n",
       "997                             1                  393216   \n",
       "998                             0                 9125888   \n",
       "999                             1                 8683520   \n",
       "\n",
       "    bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                  356515840                    7                        1   \n",
       "1                  595591168                    5                        8   \n",
       "2                  570425344                    4                        4   \n",
       "3                  343932928                    3                        4   \n",
       "4                  243269632                    1                       13   \n",
       "..                       ...                  ...                      ...   \n",
       "995                432013312                    0                       29   \n",
       "996                268435456                    1                       24   \n",
       "997                671088640                    7                       20   \n",
       "998                834666496                    3                       17   \n",
       "999                838860800                    1                       11   \n",
       "\n",
       "     ... table_definition_cache  table_open_cache   \\\n",
       "0    ...                   13200              4000   \n",
       "1    ...                   91600              4000   \n",
       "2    ...                   15600                 1   \n",
       "3    ...                   11200             10000   \n",
       "4    ...                   11600              4000   \n",
       "..   ...                     ...               ...   \n",
       "995  ...                   91200              8000   \n",
       "996  ...                   89600              2000   \n",
       "997  ...                   66000              8000   \n",
       "998  ...                   70400              2000   \n",
       "999  ...                   81600              8000   \n",
       "\n",
       "    table_open_cache_instances  thread_cache_size  tmp_table_size   \\\n",
       "0                            18              11520       255852544   \n",
       "1                            17              15360       402653184   \n",
       "2                             9               1024       851443712   \n",
       "3                             9              13568       163577856   \n",
       "4                            25               1536       348127232   \n",
       "..                          ...                ...             ...   \n",
       "995                          63               7680       163577856   \n",
       "996                          29              11520       230686720   \n",
       "997                          48              12544       536870912   \n",
       "998                          57               3840       218103808   \n",
       "999                          32               5632       801112064   \n",
       "\n",
       "    transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0                           28672                      94208   \n",
       "1                          110592                      71680   \n",
       "2                            8192                     122880   \n",
       "3                           16384                      83968   \n",
       "4                          126976                      57344   \n",
       "..                            ...                        ...   \n",
       "995                         57344                     104448   \n",
       "996                         69632                      61440   \n",
       "997                         81920                     108544   \n",
       "998                         36864                      63488   \n",
       "999                        106496                      75776   \n",
       "\n",
       "    updatable_views_with_limit           tps   latency  \n",
       "0                             0     0.216666  20847397  \n",
       "1                             1     0.322221  12744942  \n",
       "2                             0  3789.313102      1076  \n",
       "3                             0     0.166667  12510551  \n",
       "4                             0     0.266666  10686198  \n",
       "..                          ...          ...       ...  \n",
       "995                           1     0.138889  11836756  \n",
       "996                           0     0.149999  16386967  \n",
       "997                           1     0.227778  19293708  \n",
       "998                           1     0.188888  10529195  \n",
       "999                           1     0.272221   9697154  \n",
       "\n",
       "[1000 rows x 140 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples = pd.concat([A_config,metrics], axis=1)\n",
    "\n",
    "all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### boolean에 해당하는 열 정리\n",
    "\n",
    "discrete_columns = [all_samples.columns[0], all_samples.columns[5],all_samples.columns[10],all_samples.columns[13],\n",
    "                    all_samples.columns[17],all_samples.columns[24],all_samples.columns[30],all_samples.columns[31],\n",
    "                    all_samples.columns[32],all_samples.columns[34],all_samples.columns[36],all_samples.columns[37],\n",
    "                    all_samples.columns[58],all_samples.columns[60],all_samples.columns[64],all_samples.columns[68],\n",
    "                    all_samples.columns[72],all_samples.columns[73],all_samples.columns[74],all_samples.columns[75],\n",
    "                    all_samples.columns[77],all_samples.columns[80],all_samples.columns[82],all_samples.columns[83],\n",
    "                    all_samples.columns[90],all_samples.columns[91],all_samples.columns[92],all_samples.columns[93],\n",
    "                    all_samples.columns[118],all_samples.columns[123],all_samples.columns[124],all_samples.columns[125],\n",
    "                    all_samples.columns[126]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### continuous 열 정리\n",
    "all_columns = all_samples.columns\n",
    "continuous_columns = all_columns.drop(discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(discrete_columns)):\n",
    "    a = discrete_columns[i]\n",
    "    all_samples = all_samples.astype({a:'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(continuous_columns)):\n",
    "    a = continuous_columns[i]\n",
    "    all_samples = all_samples.astype({a:'float'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config - metric prediction (with raw data #1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics['tps'].min() , metrics['tps'].max())\n",
    "# print(metrics['latency'].min() , metrics['latency'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.16316 | val_0_mse: 0.14767 |  0:00:00s\n",
      "epoch 10 | loss: 0.05221 | val_0_mse: 0.05906 |  0:00:01s\n",
      "epoch 20 | loss: 0.03594 | val_0_mse: 0.04931 |  0:00:02s\n",
      "epoch 30 | loss: 0.02032 | val_0_mse: 0.0619  |  0:00:03s\n",
      "epoch 40 | loss: 0.01658 | val_0_mse: 0.06049 |  0:00:04s\n",
      "epoch 50 | loss: 0.01706 | val_0_mse: 0.05691 |  0:00:05s\n",
      "epoch 60 | loss: 0.0132  | val_0_mse: 0.01409 |  0:00:06s\n",
      "epoch 70 | loss: 0.01303 | val_0_mse: 0.03969 |  0:00:07s\n",
      "epoch 80 | loss: 0.01559 | val_0_mse: 0.03018 |  0:00:08s\n",
      "epoch 90 | loss: 0.0112  | val_0_mse: 0.02089 |  0:00:09s\n",
      "epoch 100| loss: 0.00996 | val_0_mse: 0.01149 |  0:00:10s\n",
      "epoch 110| loss: 0.00905 | val_0_mse: 0.01121 |  0:00:11s\n",
      "epoch 120| loss: 0.01066 | val_0_mse: 0.00992 |  0:00:12s\n",
      "epoch 130| loss: 0.01074 | val_0_mse: 0.00953 |  0:00:13s\n",
      "epoch 140| loss: 0.01102 | val_0_mse: 0.00918 |  0:00:14s\n",
      "epoch 150| loss: 0.01286 | val_0_mse: 0.00948 |  0:00:15s\n",
      "epoch 160| loss: 0.01064 | val_0_mse: 0.01966 |  0:00:16s\n",
      "epoch 170| loss: 0.01132 | val_0_mse: 0.01408 |  0:00:17s\n",
      "epoch 180| loss: 0.00907 | val_0_mse: 0.04728 |  0:00:18s\n",
      "epoch 190| loss: 0.00857 | val_0_mse: 0.01572 |  0:00:19s\n",
      "epoch 200| loss: 0.00874 | val_0_mse: 0.00658 |  0:00:20s\n",
      "epoch 210| loss: 0.00733 | val_0_mse: 0.01974 |  0:00:21s\n",
      "epoch 220| loss: 0.00625 | val_0_mse: 0.01214 |  0:00:22s\n",
      "epoch 230| loss: 0.00666 | val_0_mse: 0.00903 |  0:00:23s\n",
      "epoch 240| loss: 0.0058  | val_0_mse: 0.01235 |  0:00:24s\n",
      "epoch 250| loss: 0.00618 | val_0_mse: 0.0109  |  0:00:25s\n",
      "epoch 260| loss: 0.00686 | val_0_mse: 0.00951 |  0:00:26s\n",
      "epoch 270| loss: 0.00821 | val_0_mse: 0.01042 |  0:00:27s\n",
      "epoch 280| loss: 0.00529 | val_0_mse: 0.00898 |  0:00:28s\n",
      "epoch 290| loss: 0.00519 | val_0_mse: 0.00702 |  0:00:29s\n",
      "epoch 300| loss: 0.00488 | val_0_mse: 0.0067  |  0:00:30s\n",
      "epoch 310| loss: 0.00698 | val_0_mse: 0.00625 |  0:00:31s\n",
      "epoch 320| loss: 0.00571 | val_0_mse: 0.00991 |  0:00:32s\n",
      "epoch 330| loss: 0.00461 | val_0_mse: 0.00778 |  0:00:33s\n",
      "epoch 340| loss: 0.00521 | val_0_mse: 0.00671 |  0:00:34s\n",
      "epoch 350| loss: 0.00451 | val_0_mse: 0.00561 |  0:00:35s\n",
      "epoch 360| loss: 0.00441 | val_0_mse: 0.0101  |  0:00:36s\n",
      "epoch 370| loss: 0.00514 | val_0_mse: 0.0093  |  0:00:37s\n",
      "epoch 380| loss: 0.00519 | val_0_mse: 0.01382 |  0:00:38s\n",
      "epoch 390| loss: 0.00508 | val_0_mse: 0.00698 |  0:00:39s\n",
      "epoch 400| loss: 0.00523 | val_0_mse: 0.00598 |  0:00:40s\n",
      "\n",
      "Early stopping occurred at epoch 403 with best_epoch = 303 and best_val_0_mse = 0.00504\n",
      "BEST VALID SCORE :  0.005042771921050544\n",
      "R2 SCORE :  0.8832320849207775\n"
     ]
    }
   ],
   "source": [
    "### TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_all = np.array(A_config)\n",
    "Y_all = np.array(metrics)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all,Y_all,test_size=0.2, shuffle=True)\n",
    "\n",
    "y_train_tps = y_train[:,0][:, np.newaxis]\n",
    "y_train_latency = y_train[:,1][:, np.newaxis]\n",
    "y_test_tps = y_test[:,0][:, np.newaxis]\n",
    "y_test_latency = y_test[:,1][:, np.newaxis]\n",
    " \n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "Y_scaler_tps  = MinMaxScaler().fit(y_train_tps)\n",
    "Y_scaler_latecy = MinMaxScaler().fit(y_train_latency)\n",
    "\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "scaled_y_train_tps = Y_scaler_tps.transform(y_train_tps)\n",
    "scaled_y_train_latecy = Y_scaler_latecy.transform(y_train_latency)\n",
    "\n",
    "scaled_y_test_tps = Y_scaler_tps.transform(y_test_tps)\n",
    "scaled_y_test_latecy = Y_scaler_latecy.transform(y_test_latency)\n",
    "\n",
    "# scaled_y_train = np.concatenate([scaled_y_train_latecy, scaled_y_train_tps], 1)\n",
    "# scaled_y_test = np.concatenate([scaled_y_test_latecy, scaled_y_test_tps], 1)\n",
    "\n",
    "scaled_y_train = np.concatenate([scaled_y_train_tps, scaled_y_train_latecy], 1)\n",
    "scaled_y_test = np.concatenate([scaled_y_test_tps, scaled_y_test_latecy], 1)\n",
    "\n",
    "# Tabnet 모델 생성\n",
    "regressor = TabNetRegressor(verbose = 10,seed = 42,optimizer_fn=torch.optim.AdamW) ### Basic\n",
    "\n",
    "# 모델 학습\n",
    "regressor.fit(X_train=scaled_X_train, y_train=scaled_y_train,\n",
    "              eval_set=[(scaled_X_test, scaled_y_test)],\n",
    "              patience=100, \n",
    "              batch_size = 128,\n",
    "              max_epochs=10000,\n",
    "              eval_metric=['mse'])\n",
    "\n",
    "\n",
    "predictions = regressor.predict(scaled_X_test)\n",
    "\n",
    "test_score = mean_squared_error(y_pred = predictions, y_true = scaled_y_test)\n",
    "# 성능 평가\n",
    "print('BEST VALID SCORE : ', regressor.best_cost)\n",
    "# print('MSE_SCORE : ', test_score)\n",
    "# print('R2 SCORE : ' , r2_score(predictions, scaled_y_test, multioutput='variance_weighted'))\n",
    "# print('R2 SCORE : ' , r2_score(predictions, scaled_y_test))\n",
    "print('R2 SCORE : ' , r2_score(scaled_y_test, predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 R2 Score: 0.9447704927766067\n",
      "Column 1 R2 Score: 0.7793267110011648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#Column 0 :TPS\n",
    "#Column 1 : Latency\n",
    "\n",
    "for i in range(2):  \n",
    "    r2_score_column = r2_score(predictions[:, i], scaled_y_test[:, i])\n",
    "    print(f'Column {i} R2 Score: {r2_score_column}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LHS SAMPLING (make samples #4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "knob_info = pd.read_csv('Knob_Information_MySQL_v5.7.csv')\n",
    "\n",
    "knob_min = knob_info['raw_min']\n",
    "knob_max = knob_info['raw_max']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>unit</th>\n",
       "      <th>s_unit</th>\n",
       "      <th>raw_min</th>\n",
       "      <th>d_f_min</th>\n",
       "      <th>raw_max</th>\n",
       "      <th>d_f_max</th>\n",
       "      <th>raw_default</th>\n",
       "      <th>d_f_default</th>\n",
       "      <th>q_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automatic_sp_privileges</td>\n",
       "      <td>boolean</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>back_log</td>\n",
       "      <td>integer</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>60</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>binlog_cache_size</td>\n",
       "      <td>integer</td>\n",
       "      <td>1024</td>\n",
       "      <td>KB</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>1.048576e+07</td>\n",
       "      <td>640</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binlog_group_commit_sync_delay</td>\n",
       "      <td>integer</td>\n",
       "      <td>1</td>\n",
       "      <td>microsecond</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binlog_group_commit_sync_no_delay_count</td>\n",
       "      <td>integer</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>thread_cache_size</td>\n",
       "      <td>integer</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638400e+04</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tmp_table_size</td>\n",
       "      <td>integer</td>\n",
       "      <td>1048576</td>\n",
       "      <td>MB</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>1.073742e+09</td>\n",
       "      <td>256</td>\n",
       "      <td>16777216.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4194304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>transaction_alloc_block_size</td>\n",
       "      <td>integer</td>\n",
       "      <td>1024</td>\n",
       "      <td>KB</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>1.310720e+05</td>\n",
       "      <td>32</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>transaction_prealloc_size</td>\n",
       "      <td>integer</td>\n",
       "      <td>1024</td>\n",
       "      <td>KB</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>1.310720e+05</td>\n",
       "      <td>64</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>updatable_views_with_limit</td>\n",
       "      <td>integer</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name     type     unit       s_unit  \\\n",
       "0                    automatic_sp_privileges  boolean        1          NaN   \n",
       "1                                   back_log  integer        1          NaN   \n",
       "2                          binlog_cache_size  integer     1024           KB   \n",
       "3             binlog_group_commit_sync_delay  integer        1  microsecond   \n",
       "4    binlog_group_commit_sync_no_delay_count  integer        1          NaN   \n",
       "..                                       ...      ...      ...          ...   \n",
       "133                        thread_cache_size  integer        1          NaN   \n",
       "134                           tmp_table_size  integer  1048576           MB   \n",
       "135             transaction_alloc_block_size  integer     1024           KB   \n",
       "136                transaction_prealloc_size  integer     1024           KB   \n",
       "137               updatable_views_with_limit  integer        1          NaN   \n",
       "\n",
       "     raw_min  d_f_min       raw_max  d_f_max  raw_default  d_f_default  \\\n",
       "0          0        0  1.000000e+00        1          0.0          0.0   \n",
       "1          1        0  6.000000e+04       60       4030.0          4.0   \n",
       "2       4096        0  1.048576e+07      640      32768.0          2.0   \n",
       "3          0        0  1.000000e+06      200          0.0          0.0   \n",
       "4          0        0  1.000000e+06     1000          0.0          0.0   \n",
       "..       ...      ...           ...      ...          ...          ...   \n",
       "133        0        0  1.638400e+04       64         -1.0          1.0   \n",
       "134     1024        0  1.073742e+09      256   16777216.0          4.0   \n",
       "135     1024        0  1.310720e+05       32       8192.0          2.0   \n",
       "136     1024        0  1.310720e+05       64       4096.0          2.0   \n",
       "137        0        0  1.000000e+00        1          0.0          0.0   \n",
       "\n",
       "     q_factor  \n",
       "0           1  \n",
       "1        1000  \n",
       "2       16384  \n",
       "3        5000  \n",
       "4        1000  \n",
       "..        ...  \n",
       "133       256  \n",
       "134   4194304  \n",
       "135      4096  \n",
       "136      2048  \n",
       "137         1  \n",
       "\n",
       "[138 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knob_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE import *\n",
    "from scipy.stats.distributions import uniform\n",
    "\n",
    "def LH_Sampling(KNOB, KNOB_DETAILS, sample_num):\n",
    "    maxvals = []\n",
    "    minvals = []\n",
    "    types = []\n",
    "    names = []\n",
    "    nfeats = len(KNOB)\n",
    "    \n",
    "    for knob in range (len(KNOB)):\n",
    "        names.append(knob)\n",
    "        knob_info = KNOB_DETAILS\n",
    "        \n",
    "        \n",
    "        if knob_info['type'][knob] == 'boolean':\n",
    "            maxvals.append(int(1))\n",
    "            minvals.append(int(0))\n",
    "        else:\n",
    "            maxvals.append((knob_info['raw_max'][knob]).astype(int))\n",
    "            minvals.append((knob_info['raw_min'][knob]).astype(int))\n",
    "        types.append(knob_info['type'])\n",
    "        \n",
    "\n",
    "    samples = lhs(nfeats, samples=sample_num, criterion='maximin')\n",
    "    \n",
    "    maxvals = np.array(maxvals)\n",
    "    minvals = np.array(minvals)\n",
    "    scales = maxvals - minvals\n",
    "    \n",
    "    for fidx in range(nfeats):\n",
    "        samples[:, fidx] = uniform(loc=minvals[fidx], scale=scales[fidx]).ppf(samples[:, fidx])\n",
    "        \n",
    "    lhs_samples = []\n",
    "    for sidx in range(sample_num):\n",
    "        lhs_samples.append(dict())\n",
    "        for fidx in range(nfeats):\n",
    "            # lhs_samples[-1][names[fidx]] = int(round(samples[sidx][fidx]))\n",
    "            lhs_samples[-1][names[fidx]] = int(round(samples[sidx][fidx]))\n",
    "            # lhs_samples[-1][names[fidx]] = int(round(samples[fidx][sidx]))\n",
    "            \n",
    "    random.shuffle(lhs_samples)\n",
    "\n",
    "    return lhs_samples\n",
    "\n",
    "A_config_columns = A_config.columns.to_list()\n",
    "A_config_columns_stripped = [column.strip() for column in A_config_columns]\n",
    "mm_sample = LH_Sampling(A_config_columns_stripped, knob_info, 4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mm_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = []\n",
    "for ll in mm_sample:\n",
    "    val = list(ll.values())\n",
    "    sample_list.append(val)\n",
    "# sample_list = [ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_list\n",
    "samples = np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 138)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict Metrics with New Samples ()= configs)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "new_X = np.array(samples)\n",
    "# new_X = np.round(new_X)\n",
    "Z_scaler = MinMaxScaler().fit(new_X)\n",
    "new_X_ = Z_scaler.transform(new_X)\n",
    "# print(new_X_)\n",
    "\n",
    "predictions_new = regressor.predict(new_X_) #scaling O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97254825"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_new.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### new_metrics_re = 원래 metric + predic_metric\n",
    "### predictions_new == predict_model.predict(new_sample)\n",
    "\n",
    "predictions_new_df = pd.DataFrame(predictions_new) \n",
    "\n",
    "\n",
    "# inverse를 통해서 원래 데이터 형태로\n",
    "inverse_new_pred_tps = Y_scaler_tps.inverse_transform(predictions_new[:, 0].reshape(-1, 1))\n",
    "inverse_new_pred_lat = Y_scaler_latecy.inverse_transform(predictions_new[:, 1].reshape(-1, 1))\n",
    "\n",
    "inverse_new_pred_sum = np.concatenate([inverse_new_pred_tps, inverse_new_pred_lat], axis=1)\n",
    "inverse_new_pred_pd = pd.DataFrame(inverse_new_pred_sum)\n",
    "inverse_new_pred_pd.rename(columns={0: \"tps\", 1:\"latency\"}, inplace=True)\n",
    "\n",
    "\n",
    "new_metrics_re = pd.concat([metrics,inverse_new_pred_pd], axis=0)\n",
    "\n",
    "\n",
    "new_metrics_re = new_metrics_re.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.496078</td>\n",
       "      <td>1.004924e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.953392</td>\n",
       "      <td>1.043255e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.330391</td>\n",
       "      <td>1.023836e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158.567429</td>\n",
       "      <td>6.826386e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.349518</td>\n",
       "      <td>9.615905e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>30.884880</td>\n",
       "      <td>9.678974e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>166.305573</td>\n",
       "      <td>8.149458e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>118.268532</td>\n",
       "      <td>7.942428e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>8883.286133</td>\n",
       "      <td>6.386598e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>83.156830</td>\n",
       "      <td>9.623523e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tps       latency\n",
       "0       33.496078  1.004924e+07\n",
       "1       38.953392  1.043255e+07\n",
       "2       34.330391  1.023836e+07\n",
       "3      158.567429  6.826386e+06\n",
       "4       39.349518  9.615905e+06\n",
       "...           ...           ...\n",
       "3995    30.884880  9.678974e+06\n",
       "3996   166.305573  8.149458e+06\n",
       "3997   118.268532  7.942428e+06\n",
       "3998  8883.286133  6.386598e+05\n",
       "3999    83.156830  9.623523e+06\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_metrics_re = new_metrics_re.drop(['index'], axis=1)\n",
    "\n",
    "inverse_new_pred_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>7.756445</td>\n",
       "      <td>12412054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>10.537349</td>\n",
       "      <td>12331810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>44.614220</td>\n",
       "      <td>11254610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>20.355700</td>\n",
       "      <td>12870400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-59.688225</td>\n",
       "      <td>12373004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tps     latency\n",
       "0        0.216666  20847397.0\n",
       "1        0.322221  12744942.0\n",
       "2     3789.313102      1076.0\n",
       "3        0.166667  12510551.0\n",
       "4        0.266666  10686198.0\n",
       "...           ...         ...\n",
       "4995     7.756445  12412054.0\n",
       "4996    10.537349  12331810.0\n",
       "4997    44.614220  11254610.0\n",
       "4998    20.355700  12870400.0\n",
       "4999   -59.688225  12373004.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metrics_re = new_metrics_re.drop(['index'], axis=1)\n",
    "new_metrics_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인자 정리\n",
    "- new_X = samples = LHS Sampling으로 생성한 데이터\n",
    "<!-- - new_metrics = 생성한 데이터에 대해서 TabNET이 예측한 metrics + 원래 metrics (scaling X) -->\n",
    "- new_metrics_re = 원래 metric (A_metrics) + 생성한 데이터로 예측한 metric (scaling X)\n",
    "- new_Samples = 원래 config + 생성한 config (scaling X)\n",
    "- newnewnew = AutoEncoder에 넣을 수 있는 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_pd = pd.DataFrame(new_X)\n",
    "# new_X_pd = round(new_X_pd).astype(int)\n",
    "for i in range(len(new_X_pd.columns)):\n",
    "    new_X_pd.rename(columns={new_X_pd.columns[i]: A_config.columns[i]}, inplace=True)   \n",
    "    \n",
    "new_Samples = pd.concat([A_config,new_X_pd] , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 60\n",
    "# pd.options.display.max_columns = 20\n",
    "\n",
    "new_Samples = new_Samples.reset_index()\n",
    "new_Samples = new_Samples.drop(['index'], axis=1)\n",
    "# new_Samples = new_Samples.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>stored_program_cache</th>\n",
       "      <th>sync_binlog</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>489472</td>\n",
       "      <td>200000</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>374528</td>\n",
       "      <td>50000</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>37120</td>\n",
       "      <td>660000</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>427776</td>\n",
       "      <td>430000</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>388096</td>\n",
       "      <td>880000</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>45125</td>\n",
       "      <td>8725130</td>\n",
       "      <td>991809</td>\n",
       "      <td>880420</td>\n",
       "      <td>1</td>\n",
       "      <td>3031954</td>\n",
       "      <td>701589288</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>433771</td>\n",
       "      <td>6395</td>\n",
       "      <td>28891</td>\n",
       "      <td>3411</td>\n",
       "      <td>3</td>\n",
       "      <td>14060</td>\n",
       "      <td>1005366874</td>\n",
       "      <td>117493</td>\n",
       "      <td>126758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>30585</td>\n",
       "      <td>2985469</td>\n",
       "      <td>729584</td>\n",
       "      <td>30902</td>\n",
       "      <td>0</td>\n",
       "      <td>1380965</td>\n",
       "      <td>632751948</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>19279</td>\n",
       "      <td>988885</td>\n",
       "      <td>454</td>\n",
       "      <td>4687</td>\n",
       "      <td>9</td>\n",
       "      <td>15360</td>\n",
       "      <td>263457812</td>\n",
       "      <td>105938</td>\n",
       "      <td>9051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>47733</td>\n",
       "      <td>9641351</td>\n",
       "      <td>135638</td>\n",
       "      <td>730445</td>\n",
       "      <td>0</td>\n",
       "      <td>1875681</td>\n",
       "      <td>566126181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>190120</td>\n",
       "      <td>50464</td>\n",
       "      <td>60059</td>\n",
       "      <td>1403</td>\n",
       "      <td>45</td>\n",
       "      <td>1045</td>\n",
       "      <td>288865733</td>\n",
       "      <td>83967</td>\n",
       "      <td>54400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>27417</td>\n",
       "      <td>5189779</td>\n",
       "      <td>624842</td>\n",
       "      <td>509095</td>\n",
       "      <td>1</td>\n",
       "      <td>6334325</td>\n",
       "      <td>103902585</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>391800</td>\n",
       "      <td>233963</td>\n",
       "      <td>13030</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>4372</td>\n",
       "      <td>1066135727</td>\n",
       "      <td>129131</td>\n",
       "      <td>86136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>53012</td>\n",
       "      <td>928994</td>\n",
       "      <td>870591</td>\n",
       "      <td>503818</td>\n",
       "      <td>1</td>\n",
       "      <td>2007369</td>\n",
       "      <td>1024715784</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>311632</td>\n",
       "      <td>36640</td>\n",
       "      <td>12012</td>\n",
       "      <td>8881</td>\n",
       "      <td>21</td>\n",
       "      <td>11553</td>\n",
       "      <td>392202384</td>\n",
       "      <td>49841</td>\n",
       "      <td>86102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                           1     24000            7700480   \n",
       "1                           0     15000             622592   \n",
       "2                           1      8000            7110656   \n",
       "3                           0     34000            8519680   \n",
       "4                           0     12000            6291456   \n",
       "...                       ...       ...                ...   \n",
       "4995                        1     45125            8725130   \n",
       "4996                        0     30585            2985469   \n",
       "4997                        0     47733            9641351   \n",
       "4998                        0     27417            5189779   \n",
       "4999                        0     53012             928994   \n",
       "\n",
       "     binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                             485000                                   352000   \n",
       "1                             140000                                   701000   \n",
       "2                             440000                                   801000   \n",
       "3                             760000                                   303000   \n",
       "4                             380000                                   630000   \n",
       "...                              ...                                      ...   \n",
       "4995                          991809                                   880420   \n",
       "4996                          729584                                    30902   \n",
       "4997                          135638                                   730445   \n",
       "4998                          624842                                   509095   \n",
       "4999                          870591                                   503818   \n",
       "\n",
       "     binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                                0                  655360   \n",
       "1                                1                 2637824   \n",
       "2                                1                 8093696   \n",
       "3                                0                10420224   \n",
       "4                                1                 5472256   \n",
       "...                            ...                     ...   \n",
       "4995                             1                 3031954   \n",
       "4996                             0                 1380965   \n",
       "4997                             0                 1875681   \n",
       "4998                             1                 6334325   \n",
       "4999                             1                 2007369   \n",
       "\n",
       "     bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                   356515840                    7                        1   \n",
       "1                   595591168                    5                        8   \n",
       "2                   570425344                    4                        4   \n",
       "3                   343932928                    3                        4   \n",
       "4                   243269632                    1                       13   \n",
       "...                       ...                  ...                      ...   \n",
       "4995                701589288                    6                        6   \n",
       "4996                632751948                    0                       13   \n",
       "4997                566126181                    0                        1   \n",
       "4998                103902585                    4                       13   \n",
       "4999               1024715784                    6                        0   \n",
       "\n",
       "      ... stored_program_cache  sync_binlog  table_definition_cache   \\\n",
       "0     ...                489472       200000                   13200   \n",
       "1     ...                374528        50000                   91600   \n",
       "2     ...                 37120       660000                   15600   \n",
       "3     ...                427776       430000                   11200   \n",
       "4     ...                388096       880000                   11600   \n",
       "...   ...                   ...          ...                     ...   \n",
       "4995  ...                433771         6395                   28891   \n",
       "4996  ...                 19279       988885                     454   \n",
       "4997  ...                190120        50464                   60059   \n",
       "4998  ...                391800       233963                   13030   \n",
       "4999  ...                311632        36640                   12012   \n",
       "\n",
       "     table_open_cache  table_open_cache_instances  thread_cache_size   \\\n",
       "0                 4000                          18              11520   \n",
       "1                 4000                          17              15360   \n",
       "2                    1                           9               1024   \n",
       "3                10000                           9              13568   \n",
       "4                 4000                          25               1536   \n",
       "...                ...                         ...                ...   \n",
       "4995              3411                           3              14060   \n",
       "4996              4687                           9              15360   \n",
       "4997              1403                          45               1045   \n",
       "4998                83                          12               4372   \n",
       "4999              8881                          21              11553   \n",
       "\n",
       "     tmp_table_size  transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0          255852544                         28672                      94208   \n",
       "1          402653184                        110592                      71680   \n",
       "2          851443712                          8192                     122880   \n",
       "3          163577856                         16384                      83968   \n",
       "4          348127232                        126976                      57344   \n",
       "...              ...                           ...                        ...   \n",
       "4995      1005366874                        117493                     126758   \n",
       "4996       263457812                        105938                       9051   \n",
       "4997       288865733                         83967                      54400   \n",
       "4998      1066135727                        129131                      86136   \n",
       "4999       392202384                         49841                      86102   \n",
       "\n",
       "     updatable_views_with_limit   \n",
       "0                              0  \n",
       "1                              1  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "4995                           1  \n",
       "4996                           1  \n",
       "4997                           1  \n",
       "4998                           1  \n",
       "4999                           0  \n",
       "\n",
       "[5000 rows x 138 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 138)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Samples.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>7.756445</td>\n",
       "      <td>12412054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>10.537349</td>\n",
       "      <td>12331810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>44.614220</td>\n",
       "      <td>11254610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>20.355700</td>\n",
       "      <td>12870400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-59.688225</td>\n",
       "      <td>12373004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tps     latency\n",
       "0        0.216666  20847397.0\n",
       "1        0.322221  12744942.0\n",
       "2     3789.313102      1076.0\n",
       "3        0.166667  12510551.0\n",
       "4        0.266666  10686198.0\n",
       "...           ...         ...\n",
       "4995     7.756445  12412054.0\n",
       "4996    10.537349  12331810.0\n",
       "4997    44.614220  11254610.0\n",
       "4998    20.355700  12870400.0\n",
       "4999   -59.688225  12373004.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_metrics_re = new_metrics_re.drop(['index'], axis=1)\n",
    "\n",
    "new_metrics_re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Train set에 추가 (1000 + 4000) AUG == new_Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnewwnew = pd.concat([new_Samples, new_metrics_re], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>45125</td>\n",
       "      <td>8725130</td>\n",
       "      <td>991809</td>\n",
       "      <td>880420</td>\n",
       "      <td>1</td>\n",
       "      <td>3031954</td>\n",
       "      <td>701589288</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>28891</td>\n",
       "      <td>3411</td>\n",
       "      <td>3</td>\n",
       "      <td>14060</td>\n",
       "      <td>1005366874</td>\n",
       "      <td>117493</td>\n",
       "      <td>126758</td>\n",
       "      <td>1</td>\n",
       "      <td>7.756445</td>\n",
       "      <td>12412054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>30585</td>\n",
       "      <td>2985469</td>\n",
       "      <td>729584</td>\n",
       "      <td>30902</td>\n",
       "      <td>0</td>\n",
       "      <td>1380965</td>\n",
       "      <td>632751948</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>454</td>\n",
       "      <td>4687</td>\n",
       "      <td>9</td>\n",
       "      <td>15360</td>\n",
       "      <td>263457812</td>\n",
       "      <td>105938</td>\n",
       "      <td>9051</td>\n",
       "      <td>1</td>\n",
       "      <td>10.537349</td>\n",
       "      <td>12331810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>47733</td>\n",
       "      <td>9641351</td>\n",
       "      <td>135638</td>\n",
       "      <td>730445</td>\n",
       "      <td>0</td>\n",
       "      <td>1875681</td>\n",
       "      <td>566126181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>60059</td>\n",
       "      <td>1403</td>\n",
       "      <td>45</td>\n",
       "      <td>1045</td>\n",
       "      <td>288865733</td>\n",
       "      <td>83967</td>\n",
       "      <td>54400</td>\n",
       "      <td>1</td>\n",
       "      <td>44.614220</td>\n",
       "      <td>11254610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>27417</td>\n",
       "      <td>5189779</td>\n",
       "      <td>624842</td>\n",
       "      <td>509095</td>\n",
       "      <td>1</td>\n",
       "      <td>6334325</td>\n",
       "      <td>103902585</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13030</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>4372</td>\n",
       "      <td>1066135727</td>\n",
       "      <td>129131</td>\n",
       "      <td>86136</td>\n",
       "      <td>1</td>\n",
       "      <td>20.355700</td>\n",
       "      <td>12870400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>53012</td>\n",
       "      <td>928994</td>\n",
       "      <td>870591</td>\n",
       "      <td>503818</td>\n",
       "      <td>1</td>\n",
       "      <td>2007369</td>\n",
       "      <td>1024715784</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12012</td>\n",
       "      <td>8881</td>\n",
       "      <td>21</td>\n",
       "      <td>11553</td>\n",
       "      <td>392202384</td>\n",
       "      <td>49841</td>\n",
       "      <td>86102</td>\n",
       "      <td>0</td>\n",
       "      <td>-59.688225</td>\n",
       "      <td>12373004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                           1     24000            7700480   \n",
       "1                           0     15000             622592   \n",
       "2                           1      8000            7110656   \n",
       "3                           0     34000            8519680   \n",
       "4                           0     12000            6291456   \n",
       "...                       ...       ...                ...   \n",
       "4995                        1     45125            8725130   \n",
       "4996                        0     30585            2985469   \n",
       "4997                        0     47733            9641351   \n",
       "4998                        0     27417            5189779   \n",
       "4999                        0     53012             928994   \n",
       "\n",
       "     binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                             485000                                   352000   \n",
       "1                             140000                                   701000   \n",
       "2                             440000                                   801000   \n",
       "3                             760000                                   303000   \n",
       "4                             380000                                   630000   \n",
       "...                              ...                                      ...   \n",
       "4995                          991809                                   880420   \n",
       "4996                          729584                                    30902   \n",
       "4997                          135638                                   730445   \n",
       "4998                          624842                                   509095   \n",
       "4999                          870591                                   503818   \n",
       "\n",
       "     binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                                0                  655360   \n",
       "1                                1                 2637824   \n",
       "2                                1                 8093696   \n",
       "3                                0                10420224   \n",
       "4                                1                 5472256   \n",
       "...                            ...                     ...   \n",
       "4995                             1                 3031954   \n",
       "4996                             0                 1380965   \n",
       "4997                             0                 1875681   \n",
       "4998                             1                 6334325   \n",
       "4999                             1                 2007369   \n",
       "\n",
       "     bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                   356515840                    7                        1   \n",
       "1                   595591168                    5                        8   \n",
       "2                   570425344                    4                        4   \n",
       "3                   343932928                    3                        4   \n",
       "4                   243269632                    1                       13   \n",
       "...                       ...                  ...                      ...   \n",
       "4995                701589288                    6                        6   \n",
       "4996                632751948                    0                       13   \n",
       "4997                566126181                    0                        1   \n",
       "4998                103902585                    4                       13   \n",
       "4999               1024715784                    6                        0   \n",
       "\n",
       "      ... table_definition_cache  table_open_cache   \\\n",
       "0     ...                   13200              4000   \n",
       "1     ...                   91600              4000   \n",
       "2     ...                   15600                 1   \n",
       "3     ...                   11200             10000   \n",
       "4     ...                   11600              4000   \n",
       "...   ...                     ...               ...   \n",
       "4995  ...                   28891              3411   \n",
       "4996  ...                     454              4687   \n",
       "4997  ...                   60059              1403   \n",
       "4998  ...                   13030                83   \n",
       "4999  ...                   12012              8881   \n",
       "\n",
       "     table_open_cache_instances  thread_cache_size  tmp_table_size   \\\n",
       "0                             18              11520       255852544   \n",
       "1                             17              15360       402653184   \n",
       "2                              9               1024       851443712   \n",
       "3                              9              13568       163577856   \n",
       "4                             25               1536       348127232   \n",
       "...                          ...                ...             ...   \n",
       "4995                           3              14060      1005366874   \n",
       "4996                           9              15360       263457812   \n",
       "4997                          45               1045       288865733   \n",
       "4998                          12               4372      1066135727   \n",
       "4999                          21              11553       392202384   \n",
       "\n",
       "     transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0                            28672                      94208   \n",
       "1                           110592                      71680   \n",
       "2                             8192                     122880   \n",
       "3                            16384                      83968   \n",
       "4                           126976                      57344   \n",
       "...                            ...                        ...   \n",
       "4995                        117493                     126758   \n",
       "4996                        105938                       9051   \n",
       "4997                         83967                      54400   \n",
       "4998                        129131                      86136   \n",
       "4999                         49841                      86102   \n",
       "\n",
       "     updatable_views_with_limit           tps     latency  \n",
       "0                              0     0.216666  20847397.0  \n",
       "1                              1     0.322221  12744942.0  \n",
       "2                              0  3789.313102      1076.0  \n",
       "3                              0     0.166667  12510551.0  \n",
       "4                              0     0.266666  10686198.0  \n",
       "...                          ...          ...         ...  \n",
       "4995                           1     7.756445  12412054.0  \n",
       "4996                           1    10.537349  12331810.0  \n",
       "4997                           1    44.614220  11254610.0  \n",
       "4998                           1    20.355700  12870400.0  \n",
       "4999                           0   -59.688225  12373004.0  \n",
       "\n",
       "[5000 rows x 140 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnewwnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 138)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Samples.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder (raw data + new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_samples = scaler.fit_transform(new_Samples)\n",
    "# tps , latency 따로 scaling\n",
    "scaled_new_metrics_re_tps = scaler.fit_transform(new_metrics_re['tps'].values.reshape(-1, 1))\n",
    "scaled_new_metrics_re_lat = scaler.fit_transform(new_metrics_re['latency'].values.reshape(-1, 1))\n",
    "\n",
    "scaled_new_Samples = np.concatenate([scaled_samples,scaled_new_metrics_re_tps,scaled_new_metrics_re_lat], axis = 1)\n",
    "\n",
    "# tps , Latency 따로 sclaling하고 합친거\n",
    "X_train, X_test = train_test_split(scaled_new_Samples, test_size=0.2, shuffle=True)\n",
    "\n",
    "dataset_tr = TensorDataset(torch.tensor(X_train))\n",
    "dataset_te = TensorDataset(torch.tensor(X_test))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset_tr, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset_te, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 원본\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Linear(140,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(128,64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,32),\n",
    "        nn.Sigmoid())\n",
    "    \n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.Linear(32,64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 140), \n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  \n",
    "  #인코더와 디코더 연산을 차례대로 수행하도록 설정 \n",
    "  def forward(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] tr_loss : 0.125 | val_loss : 0.125\n",
      "[301] tr_loss : 0.086 | val_loss : 0.090\n",
      "[601] tr_loss : 0.074 | val_loss : 0.075\n",
      "[901] tr_loss : 0.069 | val_loss : 0.069\n",
      "[1201] tr_loss : 0.065 | val_loss : 0.065\n",
      "[1501] tr_loss : 0.064 | val_loss : 0.064\n",
      "[1801] tr_loss : 0.062 | val_loss : 0.062\n",
      "[2101] tr_loss : 0.061 | val_loss : 0.061\n",
      "[2401] tr_loss : 0.060 | val_loss : 0.059\n",
      "[2701] tr_loss : 0.059 | val_loss : 0.058\n",
      "[3001] tr_loss : 0.058 | val_loss : 0.058\n",
      "[3301] tr_loss : 0.057 | val_loss : 0.058\n",
      "[3601] tr_loss : 0.057 | val_loss : 0.057\n",
      "[3901] tr_loss : 0.057 | val_loss : 0.056\n",
      "[4201] tr_loss : 0.056 | val_loss : 0.056\n",
      "[4501] tr_loss : 0.056 | val_loss : 0.055\n",
      "[4801] tr_loss : 0.055 | val_loss : 0.055\n",
      "[5101] tr_loss : 0.055 | val_loss : 0.055\n",
      "[5401] tr_loss : 0.054 | val_loss : 0.055\n",
      "[5701] tr_loss : 0.055 | val_loss : 0.055\n",
      "[6001] tr_loss : 0.054 | val_loss : 0.055\n",
      "[6301] tr_loss : 0.054 | val_loss : 0.055\n",
      "[6601] tr_loss : 0.054 | val_loss : 0.055\n",
      "[6901] tr_loss : 0.054 | val_loss : 0.055\n",
      "[7201] tr_loss : 0.053 | val_loss : 0.054\n",
      "[7501] tr_loss : 0.054 | val_loss : 0.054\n",
      "[7801] tr_loss : 0.053 | val_loss : 0.054\n",
      "[8101] tr_loss : 0.053 | val_loss : 0.054\n",
      "[8401] tr_loss : 0.053 | val_loss : 0.054\n",
      "[8701] tr_loss : 0.053 | val_loss : 0.054\n",
      "[9001] tr_loss : 0.053 | val_loss : 0.054\n",
      "[9301] tr_loss : 0.053 | val_loss : 0.054\n",
      "[9601] tr_loss : 0.054 | val_loss : 0.054\n",
      "[9901] tr_loss : 0.053 | val_loss : 0.054\n"
     ]
    }
   ],
   "source": [
    "# from torch import device\n",
    "from torch import optim\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# model =Autoencoder().to(device)\n",
    "model = Autoencoder().to(device)\n",
    "# model = Autoencoder()\n",
    "\n",
    "\n",
    "critertion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#lr=1e-4\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "trainloss = []\n",
    "validationloss = []\n",
    "epoch_list = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  \n",
    "  for data in trainloader:\n",
    "    inputs = data[0].float().to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs) \n",
    "    loss = critertion(inputs, outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "  train_loss = running_loss / len(trainloader)\n",
    "  trainloss.append(train_loss)\n",
    "  # epoch_list.append(epoch)\n",
    "  \n",
    "  if epoch % 300 == 0:\n",
    "    total_val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      running_loss = 0\n",
    "      \n",
    "      for data in testloader:\n",
    "        inputs = data[0].float().to(device)\n",
    "        # optimizer.zero_grad()\n",
    "        outputs = model(inputs) \n",
    "        loss = critertion(inputs, outputs)\n",
    "        running_loss += loss.item()\n",
    "        inputs_np = inputs.cpu().detach().numpy()\n",
    "        outputs_np = outputs.cpu().detach().numpy()\n",
    "      total_val_loss = running_loss / len(testloader)\n",
    "      validationloss.append(total_val_loss)\n",
    "        \n",
    "    print('[%d] tr_loss : %.3f | val_loss : %.3f' %(epoch +1, train_loss, total_val_loss))\n",
    "    # print('MSE_Loss :', critertion(inputs, outputs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder T-SNE (Reconstruction이 잘 되었는지 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "input_array = scaler.fit_transform(inputs_np)\n",
    "\n",
    "\n",
    "tsne_model = TSNE(n_components=n_components)\n",
    "\n",
    "r = tsne_model.fit_transform(input_array)\n",
    "\n",
    "# print(tsne_model.fit_transform(input_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# from sklearn.datasets import load_digit\n",
    "import torch\n",
    "\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "tsne_model = TSNE(n_components=n_components)\n",
    "\n",
    "# r2 = tsne_model.fit_transform(torch.tensor(synthetic_data).cpu())\n",
    "scaler = MinMaxScaler()\n",
    "output_array = scaler.fit_transform(outputs_np)\n",
    "r2 = tsne_model.fit_transform(output_array)\n",
    "\n",
    " \n",
    "# print(tsne_model.fit_transform(input_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAHFCAYAAAAKbwgcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQ2klEQVR4nO3deXgURfoH8O8kkIOQhCOGEBMgciYQzrAeoICLXC4CuiwiIniwi0YOcQERkYAIq3IpCAr8FrzwWoOyrEGRQ0REAQlyhCOEawWMICaAEMykf39kZ8gkk8kcfVRXfz/PMw/MXd2p6Xq76q1qm6IoCoiIiIhMLsjoAhARERGpgUENERERSYFBDREREUmBQQ0RERFJgUENERERSYFBDREREUmBQQ0RERFJgUENERERSYFBDREREUmBQQ0R6W7r1q3IyMjAr7/+6tXrFUXBe++9h1tvvRWxsbEICwtDQkICevbsiWXLlrm81mazwWaz4R//+EeFz1mxYgVsNht27NjhfCwjI8P5Hne3Y8eOBbKpRKQjBjVEpLutW7di2rRpXgc1kyZNwuDBg5GcnIxly5YhKysLM2bMQL169fDJJ5+4fc8//vEP/PLLL16Xae3atfjmm28q3OrXr+/1ZxCRsaoZXQAiIk8uX76M+fPn44EHHsCSJUtcnhs+fDhKSkoqvKd79+7YtGkTnn/+ecyZM8er7+nQoQNiYmJUKTMRGYM9NUSkq4yMDIwfPx4AkJSU5Bzm2bRpk9vXX7p0CUVFRZX2mAQFVTyMNW/eHA8//DBeffVVHD9+XLWyE5HYGNQQka4eeeQRjBo1CgCQmZnpHOZp376929fHxMSgSZMmWLRoEebOnYsDBw5AUZQqvycjIwPBwcGYMmWKV+Wy2+0oLi52udntdu83jIgMx6CGiHSVkJCABg0aAADatWuHm266CTfddBOioqIqfc/KlStRu3ZtPPnkk0hOTkZ0dDT69u2Lt956q9IAJy4uDk888QTeeecd/PDDD1WWKy4uDtWrV3e5NW/e3L+NJCJDMKeGiIRQUlLikh9js9kQHBwMAOjYsSNyc3OxYcMGbN68GTt27MD69euxZs0afPDBB1i9ejVsNluFz5wwYQJef/11TJw4EVlZWR6//4svvkB0dLTLY2FhYSpsGRHphUENEQlh+vTpmDZtmvN+w4YNXaZTV69eHT179kTPnj0BAOfOncOf//xnrFmzBllZWejTp0+Fz4yKisIzzzyDsWPHYuPGjR6/v02bNkwUJjI5Dj8RkRD++te/Yvv27c7bv//9b4+vr1u3LsaOHQsA2Lt3b6Wve/TRR5GUlISJEyd6lYtDRObFnhoi0l1oaCiA0unaDvHx8YiPj6/w2t9//x2FhYWoW7duhedycnKc761MSEgIZsyYgSFDhrAnhkhyDGqISHepqakAgJdffhnDhg1zJuVGRkZWeG1BQQEaNWqEgQMHonv37khMTMTFixexadMmvPzyy0hOTsbdd9/t8fsGDx6M2bNne8yr2blzZ4WcGgBISUnxmMRMROJgUENEuuvatSsmTZqEN954A0uXLkVJSQk2btyIrl27VnhtVFQUpk2bhvXr1+Ppp5/GTz/9BJvNhqSkJIwdOxYTJ05EjRo1PH6fzWbDCy+8gB49elT6ml69erl9fN26dejevbtP20dExrApHGQmIiIiCTBRmIiIiKTAoIaIiIikwKCGiIiIpMCghoiIiKTAoIaIiIikwKCGiIiIpGCpdWpKSkpw6tQpREZGur34HREREYlHURRcuHAB8fHxCAqqvD/GUkHNqVOnkJiYaHQxiIiIyA8nT55EQkJCpc9bKqhxLMF+8uRJLntORERkEoWFhUhMTHR7KZWyTBPUFBcXIyMjA++88w7OnDmD+vXrY/jw4XjmmWc8dkWV5RhyioqKYlBDRERkMlWljpgmqHnhhRfw2muv4Y033kDLli2xY8cOPPjgg4iOjsaYMWOMLh4REREZzDRBzTfffIN+/frhzjvvBAA0atQI7777Lnbs2GFwyYiIiEgEppnS3blzZ6xfvx6HDh0CAOzevRtbtmxBnz59DC4ZERERicA0PTUTJ05EQUEBWrRogeDgYNjtdjz//PMYPHhwpe8pKipCUVGR835hYaEeRSUiUoXdbsfvv/9udDGINFe9enUEBwcH/DmmCWref/99vP3221i5ciVatmyJ7OxsjB07FvHx8Rg2bJjb98yaNQvTpk3TuaRERIFRFAVnzpzBr7/+anRRiHRTq1YtxMXFBbSOnE1RFEXFMmkmMTERTz31FNLT052PzZgxA2+//TYOHDjg9j3uemoSExNRUFDA2U9EJKzTp0/j119/RWxsLGrUqMHFQklqiqLgt99+Q35+PmrVqoX69etXeE1hYSGio6OrbL9N01Pz22+/VZi6HRwcjJKSkkrfExoaitDQUK2LRkSkGrvd7gxo6tata3RxiHQRHh4OAMjPz0dsbKzfQ1GmCWr69u2L559/Hg0aNEDLli2xa9cuzJ07Fw899JDRRSMiUo0jh6ZGjRoGl4RIX446//vvv8sf1CxYsABTpkzBY489hvz8fMTHx+Nvf/sbnn32WaOLRkSkOg45kdWoUedNE9RERkZi/vz5mD9/vtFFISIiIgGZZp0aIiKynmPHjsFmsyE7O9un961YsQK1atXSpEwkLgY1REQBsNuNLgGppVGjRhwNMDkGNUREfjh4EGjZEqhWrfTfgweNLpF4rl69anQRyGIY1BAR+eHuu68FMgcPlt63uq5du+Lxxx/HuHHjEBMTgzvuuAP79+9Hnz59ULNmTdSrVw9Dhw7F2bNnne9Zu3YtOnfujFq1aqFu3br405/+hCNHjvj83StWrECDBg1Qo0YNDBgwAOfOnXN5/siRI+jXrx/q1auHmjVromPHjvjiiy9cyn78+HE88cQTsNlszqTVc+fOYfDgwUhISECNGjWQmpqKd9991889RFpjUENE5CO7Hdi//9rQU/n7wtGxYG+88QaqVauGr7/+Gv/4xz/QpUsXtG3bFjt27MDatWvx008/4S9/+Yvz9ZcuXcK4ceOwfft2rF+/HkFBQRgwYIDHNcjK+/bbb/HQQw/hscceQ3Z2Nrp164YZM2a4vObixYvo06cPvvjiC+zatQs9e/ZE3759ceLECQBAZmYmEhISMH36dJw+fRqnT58GAFy5cgUdOnTAmjVrsHfvXvz1r3/F0KFD8e2336qwt0h1ioUUFBQoAJSCggKji0JEJpeSoijBwYoClP6bkqLO516+fFnZv3+/cvny5cA/7MCB0oIBpf8eOBD4Z3rQpUsXpW3bts77U6ZMUXr06OHympMnTyoAlIMHD7r9jPz8fAWAsmfPHkVRFOXo0aMKAGXXrl2Vfu/gwYOVXr16uTw2aNAgJTo62mN5U1JSlAULFjjvN2zYUJk3b57H9yiKovTp00d58sknq3wd+cZT3fe2/WZPDRGRHzIzgebNS//fvHnpfeEYMEaWlpbm/P/OnTuxceNG1KxZ03lr0aIFADiHmI4cOYL77rsPN9xwA6KiopCUlAQAzh6U8lq2bOn8rN69ewMAcnJycPPNN7u8rvz9S5cuYcKECUhJSUGtWrVQs2ZNHDhwoNLvcXBcPLl169aoW7cuatasic8//7zK95ExTLNODRGRSJo3B/btKx3ZUeHiwupzjImVv69xgSMiIpz/LykpQd++ffHCCy9UeJ3j+j59+/ZFYmIili5divj4eJSUlKBVq1aVJhl/+umnzlWXHUvrK15cwnD8+PH47LPPMHv2bDRp0gTh4eH485//XGUy85w5czBv3jzMnz8fqampiIiIwNixY5kELSgGNUREARAyoAFKC5aSUtpD4whkmjfXtcDt27fHRx99hEaNGqFatYrNzblz55CTk4PXX38dt956KwBgy5YtHj+zYcOGFR5LSUnBtm3bXB4rf/+rr77C8OHDMWDAAAClOTbHjh1zeU1ISAjs5fKPvvrqK/Tr1w/3338/gNJA7fDhw0hOTvZYTjIGh5+IiGRl8BhZeno6fvnlFwwePBjfffcd8vLy8Pnnn+Ohhx6C3W5H7dq1UbduXSxZsgS5ubnYsGEDxo0b5/P3jB49GmvXrsWLL76IQ4cOYeHChVi7dq3La5o0aYLMzExkZ2dj9+7duO+++yokIzdq1AibN2/Gjz/+6Jyh1aRJE6xbtw5bt25FTk4O/va3v+HMmTP+7xTSFIMaIiJZOcbIiotL/3UEODqJj4/H119/Dbvdjp49e6JVq1YYM2YMoqOjERQUhKCgILz33nvYuXMnWrVqhSeeeAIvvfSSz99z0003YdmyZViwYAHatm2Lzz//HM8884zLa+bNm4fatWvjlltuQd++fdGzZ0+0b9/e5TXTp0/HsWPH0LhxY1x33XUAgClTpqB9+/bo2bMnunbtiri4OPTv39/vfULasineDEZKorCwENHR0SgoKEBUVJTRxSEiquDKlSs4evQokpKSEBYWZnRxLO/KFSA3t/TfsDCgSZPSf0l9nuq+t+03e2qIiIgq4QhogGsBDomLQQ0REZEbinItoHG4cqX0cRITgxoiIrI8d4GKzVZxqCksrPRxEhOndBMRkV8UxfwNfFU5M02aVHyexMWghoiIfCJT8qy7nJlWra49HxZWel+GAM4KOPxEREQ+kSV51pecGQY05sCghohIZ8JezdsLMiXPMmdGPgxqiIh0cvAg0LIlUK1a6b+Oa02aiWyBQNmhM+bMmB9zaoiIdOLuotn79hlbJn/IlDzLnBm5sKeGiEgHZS+S7e6+mTgCgQ4dSv81a5JwWSIFNDabDR9//LHlvlsNDGqIiHTguGi24yLZ5e/rRc3cl/KBwPDhw2Gz2WCz2VCtWjU0aNAAjz76KM6fP6/el2ro2LFjsNlsyM7O1uX7MjIy0LZt2wqPnz59Gr1799alDIGqbBuMwqCGiMhLgfaqGHnR7CtXgL17gZ07S/8tn+yrll69euH06dM4duwYli1bhn//+9947LHHtPkyg1y9elXTz4+Li0NoaKim3yErBjVERFVQK8HXyItm6zUNOzQ0FHFxcUhISECPHj0waNAgfP75587nly9fjuTkZISFhaFFixZYtGiRy/v/+9//4t5770WdOnUQERGBtLQ0fPvtt87nFy9ejMaNGyMkJATNmzfHW2+95fJ+m82GZcuWYcCAAahRowaaNm2K1atXO58/f/48hgwZguuuuw7h4eFo2rQpli9fDgBISkoCALRr1w42mw1du3YFUNoD1b9/f8yaNQvx8fFo1qyZ87vKD9XUqlULK1asqHJ7VqxYgWnTpmH37t3O3i3H+8p/7p49e3D77bcjPDwcdevWxV//+ldcvHjR+byjfLNnz0b9+vVRt25dpKen4/fff/f4tzp8+DBuu+02hIWFISUlBevWravwmokTJ6JZs2aoUaMGbrjhBkyZMsX5uZ62Ye7cuUhNTUVERAQSExPx2GOPuZRZK0wUJiKqgtoJvnoPORUXVz4NW8tckry8PKxduxbVq1cHACxduhRTp07FwoUL0a5dO+zatQsjRoxAREQEhg0bhosXL6JLly64/vrrsXr1asTFxeH7779HSUkJAGDVqlUYM2YM5s+fj+7du2PNmjV48MEHkZCQgG7dujm/d9q0aXjxxRfx0ksvYcGCBRgyZAiOHz+OOnXqYMqUKdi/fz+ysrIQExOD3NxcXL58GQDw3Xff4Q9/+AO++OILtGzZEiEhIc7PXL9+PaKiorBu3TooXo7hedqeQYMGYe/evVi7di2++OILAEB0dHSFz/jtt9/Qq1cv3HTTTdi+fTvy8/PxyCOP4PHHH3cJnjZu3Ij69etj48aNyM3NxaBBg9C2bVuMGDHCbdlKSkpw9913IyYmBtu2bUNhYSHGjh1b4XWRkZFYsWIF4uPjsWfPHowYMQKRkZGYMGGCx20ICgrCK6+8gkaNGuHo0aN47LHHMGHChApBrOoUCykoKFAAKAUFBUYXhYhMorhYUUqbf9dbcbE233f58mVl//79yuXLlwP+rAMHFCUlpbS8N9ygKB9+qCjbt5fe9uxRobDlDBs2TAkODlYiIiKUsLAwBYACQJk7d66iKIqSmJiorFy50uU9zz33nHLzzTcriqIor7/+uhIZGamcO3fO7effcsstyogRI1weGzhwoNKnTx/nfQDKM88847x/8eJFxWazKVlZWYqiKErfvn2VBx980O3nHz16VAGg7Nq1q8J21atXTykqKnJ5HICyatUql8eio6OV5cuXe7U9U6dOVdq0aVPh8bKfu2TJEqV27drKxYsXnc//5z//UYKCgpQzZ844y9ewYUOluEylHDhwoDJo0CC336soivLZZ58pwcHBysmTJ52PZWVlud2msl588UWlQ4cOVW5DeR988IFSt25dj6/xVPe9bb85/ERE5IEoCb7+KNvDdPw4MHFi6f+1nIbdrVs3ZGdn49tvv8WoUaPQs2dPjBo1Cj///DNOnjyJhx9+GDVr1nTeZsyYgSNHjgAAsrOz0a5dO9SpU8ftZ+fk5KBTp04uj3Xq1Ak5OTkuj7Vu3dr5/4iICERGRiI/Px8A8Oijj+K9995D27ZtMWHCBGzdutWr7UpNTXXpufFGVdvjjZycHLRp0wYRERHOxzp16oSSkhIcLDMO2rJlSwSXqZT169d3bvPMmTNd9vmJEyeQk5ODBg0aICEhwfmem2++ucL3/+tf/0Lnzp0RFxeHmjVrYsqUKThx4kSV5d64cSPuuOMOXH/99YiMjMQDDzyAc+fO4dKlS37tB28xqCEiqoKRCb7+cjeFPC8PaNtW22nYERERaNKkCVq3bo1XXnkFRUVFmDZtmnMIaenSpcjOznbe9u7di23btgEAwsPDq/x8W7nxMkVRKjzmGO4q+x7H9/fu3RvHjx/H2LFjcerUKfzxj3/E3//+d6+2y11ZlHJDUWXzWLzZnqq4276y3+/gaZtHjhzpss/j4+PdDqGV/55t27bh3nvvRe/evbFmzRrs2rULkydPrjJR+vjx4+jTpw9atWqFjz76CDt37sSrr74KAFXm+QSKQQ0RURWMTPD1V2U9TNV0zqScOnUqZs+eDbvdjuuvvx55eXlo0qSJy82RoNu6dWtkZ2fjl19+cftZycnJ2LJli8tjW7duRXJysk9luu666zB8+HC8/fbbmD9/PpYsWQIAzp4Yu5fT3K677jqcPn3aef/w4cP47bffnPer2p6QkJAqvyslJQXZ2dkuPRxff/01goKCnAnLValTp47L/q5WrRpSUlJw4sQJnDp1yvm6b775xuV9X3/9NRo2bIjJkycjLS0NTZs2xfHjx6vchh07dqC4uBhz5szBTTfdhGbNmrl8j5YY1BAReckMQ05lidDD1LVrV7Rs2RIzZ85ERkYGZs2ahZdffhmHDh3Cnj17sHz5csydOxcAMHjwYMTFxaF///74+uuvkZeXh48++sjZ2I4fPx4rVqzAa6+9hsOHD2Pu3LnIzMz0qqfF4dlnn8Unn3yC3Nxc7Nu3D2vWrHEGRbGxsQgPD8fatWvx008/oaCgwONn3X777Vi4cCG+//577NixAyNHjnTpMalqexxJtNnZ2Th79iyKiooqfMeQIUMQFhaGYcOGYe/evdi4cSNGjRqFoUOHol69el5vd3ndu3dH8+bN8cADD2D37t346quvMHnyZJfXNGnSBCdOnMB7772HI0eO4JVXXsGqVatcXuNuGxo3bozi4mIsWLAAeXl5eOutt/Daa6/5XVafVJndIxEmChOR6NRMFHbQKqm5vGHDhin9+vWr8Pg777yjhISEKCdOnFDeeecdpW3btkpISIhSu3Zt5bbbblMyMzOdrz127Jhyzz33KFFRUUqNGjWUtLQ05dtvv3U+v2jRIuWGG25QqlevrjRr1kx58803Xb4LVSTvPvfcc0pycrISHh6u1KlTR+nXr5+Sl5fnfO3SpUuVxMREJSgoSOnSpYvH7frxxx+VHj16KBEREUrTpk2VTz/91OW7qtqeK1euKPfcc49Sq1YtBYDzfeW34YcfflC6deumhIWFKXXq1FFGjBihXLhwweN+HzNmjLP8lTl48KDSuXNnJSQkRGnWrJmydu3aCt89fvx4pW7dukrNmjWVQYMGKfPmzVOio6Odz1e2DXPnzlXq16+vhIeHKz179lTefPNNBYBy/vz5SsujRqKwTVHMeG1V/xQWFiI6OhoFBQWIiooyujhERBVcuXIFR48eRVJSEsJkuP4AkZc81X1v228OPxEREZEUGNQQERGRFBjUEBERkRQY1BAREZEUGNQQEQnIQnM4iACoU+cZ1BD5yMt1uYj84ljnpOwibkRW4Kjz5VdH9gWv0k3kJcfVmffvL12ZtezCZmQxdrtmK/EFBwejVq1azuv21KhRo9Jl8olkoCgKfvvtN+Tn56NWrVou17DyFYMaIi+VvTigI8DZt8/YMpWlYTtLDjpFtnFxcQDgDGyIrKBWrVrOuu8vUy2+9+OPP2LixInIysrC5cuX0axZM/zf//0fOnTo4NX7ufge+ctud3/NnOJi4wMJ9iDpqGXL0h3uiCAdF4XSiN1u1/wCgEQiqF69usceGm/bb9P01Jw/fx6dOnVCt27dkJWVhdjYWBw5cgS1atUyumhkAY6LAZZvz4wOaADxe5Ck4bjsdfn7Gg9FBdIVT2Q1pglqXnjhBSQmJmL58uXOxxo1amRcgchyMjOv9YgYdXHA8gxoZ30jTEFUIHJkS0QATDT7afXq1UhLS8PAgQMRGxuLdu3aYenSpUYXi1Qk+qwix0hDcXHpvyIM8TjaWUe7Wv6+YQ4eLB2qqVbt2pCNDES47LVaRP/BEfnBNEFNXl4eFi9ejKZNm+Kzzz7DyJEjMXr0aLz55puVvqeoqAiFhYUuNxKP2do/wwOGcoRsZ92NiclAxMjWV2b7wRH5wDSJwiEhIUhLS8PWrVudj40ePRrbt2/HN9984/Y9GRkZmDZtWoXHmSgsFp1zL6UlzEiPyFnVxB8cmZJ0V+muX78+UlJSXB5LTk7GiRMnKn3PpEmTUFBQ4LydPHlS62KSj8rmgLi7T94TJl4QdkyM+IMj2ZkmqOnUqRMOlusmPXToEBo2bFjpe0JDQxEVFeVyI7Gw/dOH7m2WkGNixB8cyc40Qc0TTzyBbdu2YebMmcjNzcXKlSuxZMkSpKenG100ChDbP+0Ylj4hQ+6JrPiDI4mZJqcGANasWYNJkybh8OHDSEpKwrhx4zBixAiv38/F98QmTE6IRIRIn+Af1jOj9g//LmQi3rbfpgpqAsWghqzE8HxdLnXsGfcPkdekSxQmIt8Ynj4h67RutVh0/zAnmbTEoIZIYoalT3CWjWcW3D9cHof0wKCGSGLl83WbNNHpiw3vJhKcBfePRTumSGcMaogsIDfXgLNkzrLxzEL7x4IdU2QQJgoTWYChs6A4y8Yzi+wfIWbikWkxUZiIAAhwlmyBBjsg5fePpN0XFuqYIgMxqCHylkkbGwumb5iT5Jm0XI+R9MCghqgqEjQ2PEs2AYtk0jKYJi0xp4aoKhIlA1gkfcN8DF8pkUhszKkhUkNVCSkmG5Ji+yiGCtWGY4REqmBQQ+RJZY2NIXOkjWeyGE44Hkcy3YwRcn8T+YZBDVFV3CWkWCT/wUGCtCIheKw2ZTJpD2buQ8u7m3N/E/mIOTVE3nIkpFgw/0GitCLD+FJtrLq/mfNFlWFODZHaKst3kDz/wfB1biThbbWx4v5mTyCphUENkT8sNEfaYjGcprypNlbc3xYbzXVL5qBVTwxqiPxhsZXELBTDacrbamOl/W3Fnqmy2EulLubUEJHXmPOgL6vsb6vmEAHabrtM9Yc5NUSkOlkOkGZhlf1tpZ6psrTqpbJy74+bXHwiIiL9OHonZOpZ8IYjX6p8T02g+8BdjpJVer7YU0NEREKwUkDjoHYvldVzlNhTQ0RCsNpZOhGgfi+VVr0/ZsGeGiIylJXH/4kc1Aw6rJqjBHD2ExEZzMozX4i0JFPvJ2c/EZHwRBv/t0reAVmDLAGNLxjUEJFhRFk9l0NgRHJgUENEhhJh/J/L9BPJgbOfiMhQRq9R4hjyKn9fpnwEIqtgTw0RCcGoAEKUITAiChyDGiKyPBGGwMzE64RqZl6TzhjUEJHlWeyi637zOqHamxcy4CENMKixOB5XiK6x4pCTL8cArxOqPb2QU81IQwxqLIrHFSJr8/UY4PWaQlW9kFPNSEMMaiyKxxULY/ccwfdjgNcJ1Z5eKNpqiyQdBjUWxOOKRbF7jv7H32OA1wnVlb2QU81IYwxqLKiq4wqDG0mxe47+x9/YwuuEak8v5FQz0hCDGotyd1zhibzE2D1H5QQSW3jdseLuhZxqRhriVbotruyqqbxasuRSUoBDh/gHJhdcOZnMgFfpJq+UHXLiibwHPuwI4faZowsuJ+faH5zd/vQ/DGhIJgxqCADz9yrlw5icsMN3ZXNp7HYgOZnd/kQkJQY15MT8PTd8SK4t+9IDBwTJw3XXBZeTo1p3kqq9UsJ1cZFMWL2sgUENOTF/rxwfxuTKP1VSUnq/7NWfDaFRF5yqvVLCdnGRDFi9rMW0Qc2sWbNgs9kwduxYo4siHb2GnIQ/c/IhIHA8Vd7AgRqX0RsadMGpOjucU81JQ6xe1mLKoGb79u1YsmQJWrdubXRRyA+mOnPyISD48MOKjwmRbK1yF5yqSeWiZaj7+L2G/23JI9GqF2nPdEHNxYsXMWTIECxduhS1a9c2ujjkB1OdOfkQEKSkCJ5srVJBVB3REiVD3cdI21SBuYWJUr1IP6YLatLT03HnnXeie/fuRheF/GDaMycvj4JWSbZWdTtF2Gk+RtqmCswtToTqRfqpZnQBfPHee+/h+++/x/bt2716fVFREYqKipz3CwsLtSoaeclxplR+kT9ZzpwcHTuyL2im6nYavdMckXX5+5WUx8eXk8F0r16sCIYyTU/NyZMnMWbMGLz99tsICwvz6j2zZs1CdHS085aYmKhxKckbVjhzssoxTdXtNGqn+ThGwSENc/Lp7+NP13EAY5LC91SbiGkuk/Dxxx9jwIABCC5TM+12O2w2G4KCglBUVOTyHOC+pyYxMZGXSRAET2hIGI4xpP37SyOUspF34C8nswjkD+vHdWaq+joeI6/x9jIJpglqLly4gOPHj7s89uCDD6JFixaYOHEiWrVqVeVn8NpPROSRj60IGx3J+HsBPLu9tIemvOJijxWksq9j0FyRt+23aXJqIiMjKwQuERERqFu3rlcBDRFRlTxFKG4iGAY0EgkkWcqPZEFPX+cuEZ3XnvWOaXJqiIgMoeP8beZWGCjQZCkfkwUr+zrApDNEBWHqoGbTpk2YP3++0cUgIpnpMH+b694IIpBZDH4scunu65iIHhjT5NSogTk1FsSkBwqEn7kSvvI3lYM0ovNxo/zXMaemIm/bb1P31BBViqe+pAYdTptNuyClzHQ+ESr/dby4sP8Y1JCcuOQrqUXjhZU43ECVYR3wHYMakg9PfUlNOpw2W2FBSiI9mGZKN5HXZL8WAxlDw/pj9JUiiGTBnhqSE099yYRUC2jYK0l+MnvVYVBDcmKmHRnE0EaBCfLkJ1mqDoMakhv78kknQjQKTJAnP8lSdbhODREBYD5HoAxfa0anNXWkwkoPwBxVh+vUEJFXhOhhMDkhJtxxbrj3WOldyFR1GNQQWZws3c5GEqZRYIK8d1jpK5Cl6nD4icjCROh2lmUEQKil7WXZqVoQodILTNSqw+EnIqqSkT0Mso0A+DzhTsuxKRFbpf8xfMqwMN1qYjL7bmBQQ2Iy/MhnHUZ1O8s6AlBloyBbNOcloTZblrEWqoDDT5IRtevQa4H04Zt+442l5+6z9AiAztOkRPlZGD47zB1Rdg5VicNPFiPUWVAg/Dl9N8HGm6HjSc9ju2VHAHScJiXSz0KI2WHuSF/hrIdBjSSk6Mr398gn8MZ7bFgMP6IbS8gRAK3/JjpGcyL9LCwbxJLuGNRIQNizIF/5c+QTfOPdNiwinUIbSKgrWej5N9EhmhPxZyFkEEvSYU6NJIQcr/aHPzk1gm58pXkjyakIPpQjXHktzYg6pHE+hyqbpEEZmcZC/mBOjcVIcxbkz+m7oBvvtuMpWUFwzl6xTqGtzqhuDY1b9oB+Fhr2XDGgIS2xp0Yylj4LEnDj3XY83S1mz1KlBNyvqhO0t08Nfv35JN4fZE7sqbEo2dsejwTceLcdT4L2LFVgpdwfs/xN/ODzz0LEhBwiL7GnhsgooveAWPFsXfS/iV6s+LcnobGnhirimZZYRG48rXq2LvLfRE8S91yR3BjUqEToY72VhhFIHZIuLCL071QkQs23J19ZuZ4zqAmQKeIFkVbhIvOQ6GzdFL9TEZk8iLUa1nPm1ARM+KFnS19kxztMo6iCBDtI+N+pNyT4O5C2pKjnldAkp+by5cvYsmUL9u/fX+G5K1eu4M033/S9pCZmirQDSYcR1MCzGi+ZvK6Y4nfqCSsqecH09VwlXgc1hw4dQnJyMm677Takpqaia9euOH36tPP5goICPPjgg5oUUlSmiRckGkZQE0flrME0v9PKsKJqToaG3/T1XCVeBzUTJ05Eamoq8vPzcfDgQURFRaFTp044ceKEluUTniniBSb9VcCzGmsxxe/UHVZUTQnZCRbA39a09VxFXufU1KtXD1988QVSU1Odj6Wnp2PNmjXYuHEjIiIiEB8fD7vAPzYt16nhcLf5yDz+TO6Z8nfKiqoZoXatP9e9q4Qp63kVVM+puXz5MqqVSzh99dVXcdddd6FLly44dOiQ/6WVgGwVyAp4VmM9pvydsqJqQrhOMBWHGU1Zz1XiZlqMey1atMCOHTuQnJzs8viCBQugKAruuusu1QtH1mHEmYXjrEzGsxqSCCuqJhw5J+V7agzZxY6Iqvx9/s195nVPzYABA/Duu++6fW7hwoUYPHgwLDQ73BQEHgl0EmFMm8cMMgVWVNUJ0wnGLF/VcJ0aCak4NKs5oca0iciShOgQMdOB2wDett8MaiRklkCB6wISEZUjRIQlHl7Q0qKES37zgD2uRETl8AAYEAY1kjFboCDMmDYR6UbEkyySA4MaCZkpUOC6gHJgI0XeEGFiQHmsu3JhUCMhIQOFKo4covYkkWciNlKkEg1ae5Gu+MC6Kye/EoUPHTqETZs2IT8/HyUlJS7PPfvss6oVTm1WSRQWCjP6pWZIUjoTKbWl0W9WtIkBZplQQaU0m/20dOlSPProo4iJiUFcXBxsNtu1D7PZ8P333/tfao0xqDGA1Y8cEjfAujdSDJD1oeFvVpTDgWgBFlVNs9lPM2bMwPPPP48zZ84gOzsbu3btct60DGhmzZqFjh07IjIyErGxsejfvz8Osr9QbGaaiqU2M/Zt+/h30T0pXaSxC1lp/JsVJd/PbBMqyHs+BzXnz5/HwIEDtSiLR19++SXS09Oxbds2rFu3DsXFxejRowcuXbqke1nIS1Y+cpipAQ4gANOtkbJygKwnjX+zmuX7+VEPRAmwSF0+Dz89/PDD6NixI0aOHKlVmbzy888/IzY2Fl9++SVuu+02r97D4ScDWHHIwGx92yqMCWg5yub8bAPHLiQeRazITL9ZFcpqqb+tiXnbfnt9QUuHJk2aYMqUKdi2bRtSU1NRvXp1l+dHjx7te2n9UFBQAACoU6dOpa8pKipCUVGR835hYaHm5aJyrHgxPqGulFcFlS6kp8WmVWivZv8bzf/et/QBnU6tzdS+q8ZMv1l3PaI+BrqibyL5xueemqSkpMo/zGZDXl5ewIWqiqIo6NevH86fP4+vvvqq0tdlZGRg2rRpFR5nTw1pzkytoSjZm94WS8fGVtBdQ4D5ekQpIFJf+yk9PR3/+c9/sGXLFiQkJFT6Onc9NYmJiQxqSD9mONsVMAATob0SoQxUBUadlqHLtZ8URYHeMdGoUaOwevVqbNy40WNAAwChoaGIiopyuRHpygytn2irNdrtQuSYi1AGAEyG9oTZvlSOX0HNm2++idTUVISHhyM8PBytW7fGW2+9pXbZXCiKgscffxyZmZnYsGGDx2EwIvKD0QFYuVlYmbPzDG+v/GkzVYtBVF4WQMrYSLSAnAznc1Azd+5cPProo+jTpw8++OADvP/+++jVqxdGjhyJefPmaVFGAKVDTm+//TZWrlyJyMhInDlzBmfOnMHly5c1+04id6RsHERQLumz+d/7Gt5e+dJmqr40kUrLAphxySSfGR2QkzD8ShSeNm0aHnjgAZfH33jjDWRkZODo0aOqFtCh7MrFZS1fvhzDhw/36jM4pZsCIWDqiTwkSGBRNb1Dxf3BtBOSgWaJwmFhYdi7dy+aNGni8vjhw4eRmpqKK1eu+FdiHTCooUCwcdCYiXewJjGZSusHmTxWJJEYOPFBs0ThJk2a4IMPPqjw+Pvvv4+mTZv6+nFEpsAFbXVg4qRPTZKKVdgfwiQ7k7mZaAzT556ajz76CIMGDUL37t3RqVMn2Gw2bNmyBevXr8cHH3yAAQMGaFXWgLGnRi56nzSYuCPBXMwwDd4NzYYnA9wfHDalgAlw8NN0nZqdO3di3rx5yMnJgaIoSElJwZNPPol27doFVGitMaiRg1EHaTYO5A1RYzIhyiVEIcgngoxhSr34nr8Y1MjB6JMGHpeJfMQzAnMz+qALlXNqyl4zqbCw0OONSEsi5LYwoCHykZmuWu8NqyXTmSjfzasLWtauXRunT59GbGwsatWq5XZ6taIosNlssFvtj026MtO1IokIql00VQhW7XEy0UVOvQpqNmzY4Lwa9saNGzUtEFFVMjOvHVcEP2kAYIrjAJF2ZDoTUeGq4KZmgr8Zc2rItEQPFqx6UkdUgRc/BtF/z6IkzFqVZuvUrF27Flu2bHHef/XVV9G2bVvcd999OH/+vH+lJfKD6McRzdIIOMRLZuPhehOmWQKFi/6Ygs9Bzfjx450JwXv27MG4cePQp08f5OXlYdy4caoXkMiMNEloNs3Rn6gSbgIAU+UQi5YwyxOcCnwOao4ePYqUlBQApQvx9e3bFzNnzsSiRYuQlZWlegHJnKz+W9PkpM5UR3+iqokwm9EnolwVnCc4lfI5qAkJCcFvv/0GAPjiiy/Qo0cPAECdOnU4pZvk+60FcHQN+KSu7Heb7uhvEdz/ATHtiI7RBeQJTqV8Dmo6d+6McePG4bnnnsN3332HO++8EwBw6NAhJCQkqF5AMhdpfmsqRGd+n9S5+27THv0lJV30bhzRRnSExxMcj3wOahYuXIhq1arhX//6FxYvXozrr78eAJCVlYVevXqpXkAyD6l+aypGZz7HHZV9N4/+4pAmejeeKCM6psETHI84pZtUJcBq2oEzcuqmN98t/NxXyXFqLxnNgutFeNt+e7X4XnklJSXIzc1Ffn4+SkpKXJ677bbb/PlIkoTZFsZzy8jFwrz5bjacxpJpMTkyJxOt8Ks3n4Oabdu24b777sPx48dRvpOHl0kgaX5rRkZnUkSGkuPfiEQg0EFWlGO+z8NPbdu2RbNmzTBt2jTUr1+/wnWgoqOjVS2gmjj8RD4z8pcqylGCKmfQ34hVg0Sh10iYt+23z0FNREQEdu/ejSZNmgRcSL0xqCEiM7NgKgUJTq88Ss0uk3DjjTciNzc3oMIREZHvOOmKRCLijFefc2pGjRqFJ598EmfOnEFqaiqqV6/u8nzr1q1VKxwREZVyNBjl73MoiowiYs68z8NPQUEVO3dsNhsURRE+UVim4SceyEhrrGPikWLJBJKKaDk1PvfUHD16NKCCUWA4pk5aYx0TV6WTrgSKQAUqCulAtBmvXHzPZHimRlozax0T5aCqB+e2ChSBClQU87JSJfaRZonCAPDWW2+hU6dOiI+Px/HjxwEA8+fPxyeffOJfackrIiZlkVzMWMeseBkmZ7snUOawQEUxH50qsci/Y7X4HNQsXrwY48aNQ58+ffDrr786c2hq1aqF+fPnq10+KoOX/CBP1DhgiVTHvN0eyzamvkSgGrdmZgyGhaJxJbZS4O9zULNgwQIsXboUkydPRnCZI11aWhr27NmjauGoIl7TkMpT+4BldB2rsD37K28ZLd2YehOB6tSaiRQMm44OldhKgb/PQc3Ro0fRrl27Co+Hhobi0qVLqhSKKscr2lJ5ah+wjK5jLtuzvxh3tzxQaYNs+ca0qghUx9bM6GDYtDSuxFYL/H0OapKSkpCdnV3h8aysLKSkpKhRJvKCZQ7a5JE/ByxvD2ZGDTm5bA+qYT9awn7gcKUNsqUbU08RqM6tmdHBsKlpWImtFvj7HNSMHz8e6enpeP/996EoCr777js8//zzePrppzF+/HgtykhElfDlgGWGcfVr5S+dlBmMYqRgH4JLfq+0QWZjCvd/cINaM58/XtYuA19oXIktFfgrfliyZInSoEEDxWazKTabTUlISFCWLVvmz0fpqqCgQAGgFBQUGF0UItUcOKAoKSmKApT+e+CA+9elpChKcHDp64KDS++LyGV7sE85gGZiF1hk3lYOI4hcNkkVFxtdAv95234HtE7N2bNnUVJSgtjYWPWiLA3JsE4NUWU8LXFht5f20JRXXCxuN7R9/0EED+TCJ6oQcf2Tli2BAweAkhJzLYhEhtBsReGyYmJiAnk7EanIU5sl4jVaqhKcIthSpb4QrcwilQUoDVR5ISvSgM85NefOnUN6ejpSUlIQExODOnXquNyISEyWGlc3ihkSl0QwcGDFx2TOXiXd+NxTc//99+PIkSN4+OGHUa9ePdhsNi3KRWXx7MWcBPu7iXaNliqZcd19d1OoOaTiqvzlxh0+/FD/spB0fM6piYyMxJYtW9CmTRutyqQZ0+XUlD2oJycDq1aJf1APlGlaXA/M2BiLSKeLUKlW5cyYuGQUs15gTEsyHPs0pNm1n1q0aIHLly8HVDjy0t13lybSAUBODtC6tbzXBJGp295Ky3dqRYc1VlSvclZbECQQHAu9JsCKaPixWzA+BzWLFi3C5MmT8eWXX+LcuXMoLCx0uZFKHAfxkpJrj129CgwYoOrXCBNLlA0EDhwwbyBgteU7taJDgKBJ7MnG2jtcXOgaPyuiMMduwfg8/HT48GEMHjwYu3btcnlcURTYbDbnBS5FZLrhp5SU0h6a8lTszhaiF7iybvt9+0r3gdkIsVMloOEwnuYjRRxK8Jkld1kAFdFqhxnNpnQPGTIEISEhWLlyJROFtbZqVemQ09WrpfdVnodbPl/PsFmVjrPw8smDAwea81eamXmtMebZuv80zGzWfIq75Vpn/1k6Bc3PiijMsdsdowvh66p+4eHhygGTrvxoyhWFDxxQlORkzVbdFGaV2X37SgtR/mbmJTDNXHYLMNOCtsJVJRULJMwxyCh+VkTh9pvGPyhv22+fc2rS0tJw8uRJ9aMrLy1atAhJSUkICwtDhw4d8NVXXxlWFl00b14agst+TZCUFPmSLM1cdgswQ1qHcHkTKheIKWjwuyIKc+x2EGSChM85NR9++CEyMjIwfvx4pKamonr16i7Pt27dWtUClvX+++9j6NChWLRoETp16oTXX38dy5Ytw/79+9GgQYMq32+6nBodGd1jCMDi/dBEFQmXN6FBgYTbRpMR4titw3IG3rbfPgc1QUEVO3dsNpsuicI33ngj2rdvj8WLFzsfS05ORv/+/TFr1qwq38+gxiSE+JUSGUu4ZW80KhDPZSShcXSqWaLw0aNHAyqYv65evYqdO3fiqaeecnm8R48e2Lp1q9v3FBUVoaioyHmfU85NggENkXjX69KoQKZb6ZrcE2SChM9BTcOGDbUoR5XOnj0Lu92OevXquTxer149nDlzxu17Zs2ahWnTpulRPCK5sIURgiDthC4F0qO6sVprSJDo1KugZvXq1ejduzeqV6+O1atXe3ztXXfdpUrBKlN+Crlj2MudSZMmYdy4cc77hYWFSExM1LR8RKbGsQChCNJOXCNcgbzDaq0jg+uFV0FN//79cebMGcTGxqJ///6Vvk7LnJqYmBgEBwdX6JXJz8+v0HvjEBoaitDQUE3KQyQlXpBRSMLFD8IVyDNWa+vwakp3SUkJYmNjnf+v7KZlknBISAg6dOiAdevWuTy+bt063HLLLZp9L5FlcH4tSYjV2lp8XqfGSOPGjcOyZcvwz3/+Ezk5OXjiiSdw4sQJjBw50uiiEZkfL8hIEmK1thafEoVLSkqwYsUKZGZm4tixY7DZbEhKSsKf//xnDB06VPNLJgwaNAjnzp3D9OnTcfr0abRq1QqffvqpYcnLRNIRLjOVKHCs1tbh9To1iqKgb9+++PTTT9GmTRu0aNECiqIgJycHe/bswV133YWPP/5Y4+IGhuvUEHnJZImgRN5gtTYv1depWbFiBTZv3oz169ejW7duLs9t2LAB/fv3x5tvvokHHnjA/1ITkRh45CcJsVrLz+ucmnfffRdPP/10hYAGAG6//XY89dRTeOedd1QtHBFRQCyaDWrRzSbyPqj54Ycf0KtXr0qf7927N3bv3q1KoYiIAiLclSD1YdHNJnLyOqj55ZdfKl0PBihd2ff8+fOqFIpINjxz1pkgVwzWm0U3m8jJ66DGbrejmruLmf1PcHAwiouLVSkUkSx45mwAiy5MYtHNJnLhdaKwoigYPnx4pSv0lr1wJBGVMvtKpqacLaL1lSAF3SnCXQCTyABe99QMGzYMsbGxiI6OdnuLjY3lzCeiMjQ/c9bwFNz0PUxlL+6j1sIkJtgpWmw2kZl4vU6NDLhODenN0faVPXMOuKdGh6vzaVJuT7Tq/VDzc3XfKf4TtDOJyG/ett+mukwCkdlocuascTaorrkZWvd+qDnkZKKEFQY0ZFUMaog05DiZLy4u/TfgDhUdGlddr5Vjluk6vIAQkSkwqCHSgWptn06Nqy65GSbr/WDCCpH4fLqgJemMA+MVcJdAl6vzOXqYNN3fZpuuo8tOIU3xbyc99tSIyASzLPTGXVKG6mNaldP8+G/G3g82iubDA4hlcPaTiEw0y0Iv3CUaEeXMVZRykJx4ADE9zn4yK7PlGejAl11i4d3kG9HOXBnQkFZ4TLUUBjWi4SyLCrzZJaK10cIzy6wjokA4emZ4TLUMBjUiMmOegcaq2iVso33AM1eSXfmznNmzeUy1CObUiIx5BhW42yV2e+mxq7ziYu6+SjHHgGRWWf3mMdW0mFMjA/74KnC3S9i77Af2BpKsPPVE8qAgPQY1JAW20T7ScVo4ka54lmNpDGpICmyj/VTuQM+0GpICz3Isi0ENSYUnY/7h7DGSCs9yLItBDRFZevYYe6ckJvtZDitvBQxqiCzOqjO8Tdc7JfsfhLxnusqrHwY1RBZn1bxK0/ROsQGj8kxTefXHoIaILJdXaareKW8aMCELTpowVeXVH4MaIrJcXqVpeqeqasBE6sVho6oP01ReYzCoIfKF5AduKx0XTdE7VVUDJsIwhEiBlVWYovIag5dJIHXIvlqno8HYv7+0USl7UCFTc8SpwlbfyuqeKNcH4SU3jCP7cbcMXiaB9GG2szR/e1pEOCMm1R08CLRuLXj1rWxsUIRhCOZ3GMsiAY0vGNRQYMzS2AcSfFn5wC35Npql+gJw34AZPQwhQmBFVAaDGvKfmRr7QFovKx64zdYD5wczVd9KiZDhbXRgRVQGgxryX3AwkJysWmOvWWOiRutltQO3qbow/CNVrGpkoX0MrEwVNJLpMKgh/zjO5HNyrh1Q/WzsNe8UUKP1EuGMWC9SdGF4x2qxqqaq+D1ZoPOPBMDZT+Sf8jMemjUrbfhU+ChNJk9w9pJvLDajxUKTSAxjsSpFKvO2/WZQQ75TcSqp7rNS2Xp5h0EgqUiU2edkXpzSTdpRMRlB97wGHkG9Y6XhtspIONxmFKnyl0hoDGrIPyomI2ia18CGKTBWbHWY/KGasj8/5i+RHjj8RIFRcThH1ZEhDp+YnmEjhUz+CJinnx9HgMkfHH4ifah4dFL1QCfblGQfe5zM3EFlaEeJhWZ+AdptlqefHwMa0hKDGpKPDg2Tbm2cjy28DCMnhsajFkn+0LKeWCwuJMGYIqg5duwYHn74YSQlJSE8PByNGzfG1KlTcfXqVaOLRiLSsGHSPWjwsYU3eweVEA2iBZI/tKwnFokLXTBgE4cpgpoDBw6gpKQEr7/+Ovbt24d58+bhtddew9NPP2100UhUGjVMugYNPrbwQgQEARKiQZR85pce9cQCcSEAOXpGZWPaROGXXnoJixcvRl5entfvYaKwBamcyOxurY2iIiAkRJWvqMjHpFUZclyZ4609veqJ7EnBMvzezEL6ROGCggLUqVPH42uKiopQWFjociOLUTmRuWyvQVBQaTATGqrhWZqPp7wynCFL3lEiBL3qicwBzdWr5u8ZlZEpe2qOHDmC9u3bY86cOXjkkUcqfV1GRgamTZtW4XH21JC/yvYihISUHsB0OUvz8ZRX9jNkUgfrie/KHwOKi4GSEvbUaM0UPTUZGRmw2Wwebzt27HB5z6lTp9CrVy8MHDjQY0ADAJMmTUJBQYHzdvLkSS03hyzAcdAqKio9U9PtLM3HlocNFXmD9cR3ZfPqyg5Jm7VnVDaG9tScPXsWZ8+e9fiaRo0aISwsDEBpQNOtWzfceOONWLFiBYKCfIvJmFNDauJ4OpG1GJJXRwC8b7/d/Hn0ExMTg5iYGK9e++OPP6Jbt27o0KEDli9f7nNAQ6S2zMxr3dA8SyOSnyOvrvzJDAMacRga1Hjr1KlT6Nq1Kxo0aIDZs2fj559/dj4XFxdnYMnIyhw9M8xLILIOnsyIzRRBzeeff47c3Fzk5uYiISHB5TkT5jmTZBjQEFkHT2bEZooxnOHDh0NRFLc3IiLVcV4uVYEBjZhMEdQQEemCS8QSmRqDGiIiB7NfPIvI4hjUEBEBclw8i8jiGNQQEQGCXE2TiALBoIaIyEGGi2cRWZgppnQTkTr8mYZqqamrnK9LZGrsqSGyAH8m9Vh6IpCbgEaa1BppNoSoIgY1RBbgz6SegCYCSdRwShPcSbMhKpCofpIrBjVEkvNnUo/fE4EkbDilmeUtzYYEQML6Sa4Y1BBJzp9JPX5PBJKs4ZRmlrc0GxIgyeonVcSghsgC/JnU4/N7JGw4pZnlLc2GBEDC+kkVMaghsgDHpJ7i4tJ/HcGKqu+RtOGUZpa3NBviJ1/qJwMd02JQQ2Qh/sQXPr1HwobTn4BQSNJsSACqqp/MuTE9m2KhS10XFhYiOjoaBQUFiIqKMro4RPLiOi8kgsrqYWWPOwIZx/OOQJAM5237zZ4aIlIfAxoyUlU9LpUFOsy5MT0GNUSkLTYKpDd/ZjlJmhNmNQxqiEgbzE8gIwTS4yJhTpjV8NpPRKQNd2fLzE8grTl6WMrnxnjT48Jrf5kee2pILhzqEAPzE8hIgfa4MKAxLQY1JAcOdYiF+QlkJE5ftywGNSQHLn8uHuYnkNEYRFsOc2rI/BxDG+Xvm2Fc3Axl9BfzE4hIZ+ypIfMz41CHlYbLRP47EJFUGNSQHMw21MHhMtIak7LJghjUkBzMlBjImUGkJSv1AhKVw6CG5GKGoQ4zDpeRebAXkCyMQQ2REcw2XEbmwF5AsjjOfiIyAmcGkRYCWU2XSALsqSEyEhsbUht7AcnC2FNDRPphz5T22AtIFsaeGiLSHmfk6I8BDVkQgxoi0p6OM3KYE0tkXQxqiMpjq6gunWbksDOIiBjUEDno1CpaLmbSaV0eLs9CRAxqiBw0bhUt3ZOg8Ywc0ZdnEaUcRLJjUEME6NIqWronQePLWIi6SLOlA1kiAzCoIQI0bxVF70nQjYZRRsCdQRr8MSwdyBIZgEENkYOGQySi9iTIxO/OII26UxjIEumPQQ2Rg8ZDJFzoVR8+B4oadaeIFMgykCKrYFBDVJ4WrY7drnXMRP7QuDvF6ECWOT1kNQxqiLTkplXhkJNANO5OMTqQZU4PWY3pgpqioiK0bdsWNpsN2dnZRheHyDO2KuLToTvFkCGnq3bm9JDlmC6omTBhAuLj440uBunB7EdfZoqag9HdKWr7X+9gcGg1pITkIjhYAcDkdLIGUwU1WVlZ+PzzzzF79myji0JakiURQKRMUaqaLH+XMr2DmcV3oXnwEQBMTidrqGZ0Abz1008/YcSIEfj4449Ro0YNr95TVFSEoqIi5/3CwkKtikdqcjdks2+fsWXyV2Zmafn372erQtpz9Ab+T/OSHOy72hT2omIEhwQetNnt8sR+JCdT9NQoioLhw4dj5MiRSEtL8/p9s2bNQnR0tPOWmJioYSlJFbIN2cg2tEFiq6R3MNCARpbOU5KfoUFNRkYGbDabx9uOHTuwYMECFBYWYtKkST59/qRJk1BQUOC8nTx5UqMtIdXIOmRj9vKTeWiQ+Mx8dzILm6IoilFffvbsWZw9e9bjaxo1aoR7770X//73v2Gz2ZyP2+12BAcHY8iQIXjjjTe8+r7CwkJER0ejoKAAUVFRAZWdNOQ4au7fXxrQlD1IE5F3VBorsttLe2jKKy5mrE768bb9NjSo8daJEydc8mFOnTqFnj174l//+hduvPFGJCQkePU5DGpMhgP4REJwDDk5fpKOUVUivXjbfpsiUbhBgwYu92vWrAkAaNy4sdcBDZkQAxoiITDfnczCFEENEREZx9Ezw85TEp0pg5pGjRrBBKNmRKQjNrja4/4l0ZliSjcRUWU43ZiIHBjUEJGpcboxETkwqCEi05JtrUYiCgyDGiIyLVnXaiQi/zCoISJT02ABXSIyKVPOfiIicuB0YyJyYE8NEUmBAQ0RMaghEhkzXomIvMaghkhEXHyFiMhnDGqIRMTFV4iIfMaghkg0XHyFiMgvDGqIRMPFV0gLDIrJAhjUEImIi6+QWpifRRZiUyx0uevCwkJER0ejoKAAUVFRRheHqGpcfIUC5QhkHHXJsbAPkYl4236zp4ZIZAxoKBDMzyKLYVBDRCQr5meRxTCoISKSGfOzyEJ47SciIpnx4lhkIeypISKyAgY0ZAEMaoiIiEgKDGqIiIhICgxqiIiISAoMaoiIiEgKDGqIiIhICgxqiEhOV68aXQIi0hmDGiKSS1YWEBp67ZaVZXSJiEgnDGqISC79+1/rpbl6tfQ+EVkCgxoiksfVqxWHndw9RkRSYlBDRPIICSm9VfUYEUmJQQ0RyeXjj68FMSEhpfeJyBJ4QUsikkvv3kBRUemQE3toiCyFPTVEJCcGNESWw6CGiIiIpMCghoiIiKTAoIaIiIikwKCGiIiIpMCghoiIiKTAoIaIiIikwKCGiIiIpMCghoiIiKTAoIaIiIikwKCGiIiIpMCghoiIiKRgqQtaKooCACgsLDS4JEREROQtR7vtaMcrY6mg5sKFCwCAxMREg0tCREREvrpw4QKio6Mrfd6mVBX2SKSkpASnTp1CZGQkbDab0cXxW2FhIRITE3Hy5ElERUUZXRwhcJ+4x/3iHveLe9wv7nG/uKfnflEUBRcuXEB8fDyCgirPnLFUT01QUBASEhKMLoZqoqKi+AMrh/vEPe4X97hf3ON+cY/7xT299ounHhoHJgoTERGRFBjUEBERkRQY1JhQaGgopk6ditDQUKOLIgzuE/e4X9zjfnGP+8U97hf3RNwvlkoUJiIiInmxp4aIiIikwKCGiIiIpMCghoiIiKTAoIaIiIikwKBGAv/5z39w4403Ijw8HDExMbj77ruNLpIwioqK0LZtW9hsNmRnZxtdHEMdO3YMDz/8MJKSkhAeHo7GjRtj6tSpuHr1qtFF092iRYuQlJSEsLAwdOjQAV999ZXRRTLUrFmz0LFjR0RGRiI2Nhb9+/fHwYMHjS6WUGbNmgWbzYaxY8caXRTD/fjjj7j//vtRt25d1KhRA23btsXOnTuNLhYABjWm99FHH2Ho0KF48MEHsXv3bnz99de47777jC6WMCZMmID4+HijiyGEAwcOoKSkBK+//jr27duHefPm4bXXXsPTTz9tdNF09f7772Ps2LGYPHkydu3ahVtvvRW9e/fGiRMnjC6aYb788kukp6dj27ZtWLduHYqLi9GjRw9cunTJ6KIJYfv27ViyZAlat25tdFEMd/78eXTq1AnVq1dHVlYW9u/fjzlz5qBWrVpGF62UQqb1+++/K9dff72ybNkyo4sipE8//VRp0aKFsm/fPgWAsmvXLqOLJJwXX3xRSUpKMroYuvrDH/6gjBw50uWxFi1aKE899ZRBJRJPfn6+AkD58ssvjS6K4S5cuKA0bdpUWbdundKlSxdlzJgxRhfJUBMnTlQ6d+5sdDEqxZ4aE/v+++/x448/IigoCO3atUP9+vXRu3dv7Nu3z+iiGe6nn37CiBEj8NZbb6FGjRpGF0dYBQUFqFOnjtHF0M3Vq1exc+dO9OjRw+XxHj16YOvWrQaVSjwFBQUAYKm6UZn09HTceeed6N69u9FFEcLq1auRlpaGgQMHIjY2Fu3atcPSpUuNLpYTgxoTy8vLAwBkZGTgmWeewZo1a1C7dm106dIFv/zyi8GlM46iKBg+fDhGjhyJtLQ0o4sjrCNHjmDBggUYOXKk0UXRzdmzZ2G321GvXj2Xx+vVq4czZ84YVCqxKIqCcePGoXPnzmjVqpXRxTHUe++9h++//x6zZs0yuijCyMvLw+LFi9G0aVN89tlnGDlyJEaPHo0333zT6KIBYFAjpIyMDNhsNo+3HTt2oKSkBAAwefJk3HPPPejQoQOWL18Om82GDz/80OCtUJ+3+2XBggUoLCzEpEmTjC6yLrzdL2WdOnUKvXr1wsCBA/HII48YVHLj2Gw2l/uKolR4zKoef/xx/PDDD3j33XeNLoqhTp48iTFjxuDtt99GWFiY0cURRklJCdq3b4+ZM2eiXbt2+Nvf/oYRI0Zg8eLFRhcNAFDN6AJQRY8//jjuvfdej69p1KgRLly4AABISUlxPh4aGoobbrhByqRHb/fLjBkzsG3btgrXI0lLS8OQIUPwxhtvaFlM3Xm7XxxOnTqFbt264eabb8aSJUs0Lp1YYmJiEBwcXKFXJj8/v0LvjRWNGjUKq1evxubNm5GQkGB0cQy1c+dO5Ofno0OHDs7H7HY7Nm/ejIULF6KoqAjBwcEGltAY9evXd2lzACA5ORkfffSRQSVyxaBGQDExMYiJianydR06dEBoaCgOHjyIzp07AwB+//13HDt2DA0bNtS6mLrzdr+88sormDFjhvP+qVOn0LNnT7z//vu48cYbtSyiIbzdL0DpVMxu3bo5e/WCgqzVWRsSEoIOHTpg3bp1GDBggPPxdevWoV+/fgaWzFiKomDUqFFYtWoVNm3ahKSkJKOLZLg//vGP2LNnj8tjDz74IFq0aIGJEydaMqABgE6dOlWY7n/o0CFh2hwGNSYWFRWFkSNHYurUqUhMTETDhg3x0ksvAQAGDhxocOmM06BBA5f7NWvWBAA0btzY0mefp06dQteuXdGgQQPMnj0bP//8s/O5uLg4A0umr3HjxmHo0KFIS0tz9ladOHHCUrlF5aWnp2PlypX45JNPEBkZ6ezJio6ORnh4uMGlM0ZkZGSFnKKIiAjUrVvX0rlGTzzxBG655RbMnDkTf/nLX/Ddd99hyZIlwvT6MqgxuZdeegnVqlXD0KFDcfnyZdx4443YsGEDateubXTRSDCff/45cnNzkZubWyG4UxTFoFLpb9CgQTh37hymT5+O06dPo1WrVvj000+FOdM0giMfomvXri6PL1++HMOHD9e/QCSsjh07YtWqVZg0aRKmT5+OpKQkzJ8/H0OGDDG6aAAAm2KloxkRERFJy1oD6kRERCQtBjVEREQkBQY1REREJAUGNURERCQFBjVEREQkBQY1REREJAUGNURERCQFBjVEpBqbzYaPP/7Y6GJ4tGnTJthsNvz6669GF4WIVMaghog8Gj58uPNq39WrV0e9evVwxx134J///KfzSvEOp0+fRu/evQ0qqXduueUWnD59GtHR0Zp+z+bNm9G3b1/Ex8ebItgjkgGDGiKqUq9evXD69GkcO3YMWVlZ6NatG8aMGYM//elPKC4udr4uLi6uwtXRRRMSEoK4uDjYbDZNv+fSpUto06YNFi5cqOn3ENE1DGqIqEqhoaGIi4vD9ddfj/bt2+Ppp5/GJ598gqysLKxYscL5urI9EseOHYPNZsMHH3yAW2+9FeHh4ejYsSMOHTqE7du3Iy0tDTVr1kSvXr1cLq4JlF5zKDk5GWFhYWjRogUWLVrkfM7xuZmZmejWrRtq1KiBNm3a4JtvvnG+5vjx4+jbty9q166NiIgItGzZEp9++ikA98NPH330EVq2bInQ0FA0atQIc+bMcSlPo0aNMHPmTDz00EOIjIxEgwYNqryAX+/evTFjxgzcfffdvuxqIgoAgxoi8svtt9+ONm3aIDMz0+Prpk6dimeeeQbff/89qlWrhsGDB2PChAl4+eWX8dVXX+HIkSN49tlnna9funQpJk+ejOeffx45OTmYOXMmpkyZgjfeeMPlcydPnoy///3vyM7ORrNmzTB48GBnr1F6ejqKioqwefNm7NmzBy+88ILzau3l7dy5E3/5y19w7733Ys+ePcjIyMCUKVNcgjUAmDNnDtLS0rBr1y489thjePTRR3HgwAE/9hwRaUYhIvJg2LBhSr9+/dw+N2jQICU5Odl5H4CyatUqRVEU5ejRowoAZdmyZc7n3333XQWAsn79eudjs2bNUpo3b+68n5iYqKxcudLle5577jnl5ptvrvRz9+3bpwBQcnJyFEVRlNTUVCUjI8NtmTdu3KgAUM6fP68oiqLcd999yh133OHymvHjxyspKSnO+w0bNlTuv/9+5/2SkhIlNjZWWbx4sdvvKK/sfiEi7bCnhoj8pihKlbkprVu3dv6/Xr16AIDU1FSXx/Lz8wEAP//8M06ePImHH34YNWvWdN5mzJiBI0eOVPq59evXBwDn54wePRozZsxAp06dMHXqVPzwww+Vli8nJwedOnVyeaxTp044fPgw7Ha72++z2WyIi4tzfh8RiYFBDRH5LScnB0lJSR5fU716def/HQFQ+cccs6gc/y5duhTZ2dnO2969e7Ft27YqP9fx/kceeQR5eXkYOnQo9uzZg7S0NCxYsMBt+dwFZoqieNyO8uUmIjEwqCEiv2zYsAF79uzBPffco9pn1qtXD9dffz3y8vLQpEkTl1tVwVN5iYmJGDlyJDIzM/Hkk09i6dKlbl+XkpKCLVu2uDy2detWNGvWDMHBwX5vCxHpr5rRBSAi8RUVFeHMmTOw2+346aefsHbtWsyaNQt/+tOf8MADD6j6XRkZGRg9ejSioqLQu3dvFBUVYceOHTh//jzGjRvn1WeMHTsWvXv3RrNmzXD+/Hls2LABycnJbl/75JNPomPHjnjuuecwaNAgfPPNN1i4cKHLjCt/XLx4Ebm5uc77R48eRXZ2NurUqYMGDRoE9NlE5B6DGiKq0tq1a1G/fn1Uq1YNtWvXRps2bfDKK69g2LBhCApSt8P3kUceQY0aNfDSSy9hwoQJiIiIQGpqKsaOHev1Z9jtdqSnp+O///0voqKi0KtXL8ybN8/ta9u3b48PPvgAzz77LJ577jnUr18f06dPx/DhwwPajh07dqBbt27O+46AbNiwYRVmVhGROmyKu8FjIiIiIpNhTg0RERFJgUENERERSYFBDREREUmBQQ0RERFJgUENERERSYFBDREREUmBQQ0RERFJgUENERERSYFBDREREUmBQQ0RERFJgUENERERSYFBDREREUnh/wExC/e/By5zDgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# t-SNE 결과 시각화\n",
    "plt.scatter(r[:, 0], r[:, 1], s=7, color='red',  label='real-data')\n",
    "plt.scatter(r2[:, 0], r2[:, 1], s=7, color='blue', label='Reconstruction-data')\n",
    "\n",
    "plt.title('t-SNE')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization in latent space (TabNet)\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BO'S Encoded Latent Vector: tensor([[0.4229, 0.3642, 0.5859,  ..., 0.4978, 0.0344, 0.5296],\n",
      "        [0.4785, 0.4575, 0.5046,  ..., 0.4237, 0.3297, 0.5853],\n",
      "        [0.4769, 0.4597, 0.6786,  ..., 0.4041, 0.3227, 0.4230],\n",
      "        ...,\n",
      "        [0.6376, 0.3351, 0.5307,  ..., 0.6659, 0.2147, 0.2715],\n",
      "        [0.5401, 0.4833, 0.3755,  ..., 0.5942, 0.3623, 0.6368],\n",
      "        [0.3853, 0.3690, 0.3335,  ..., 0.5329, 0.7623, 0.4495]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ex_scaled_new_Samples = torch.Tensor(scaled_new_Samples).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_vector_BO = model.encoder(ex_scaled_new_Samples)\n",
    "    print(\"BO'S Encoded Latent Vector:\", encoded_vector_BO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.17246 | val_0_mse: 0.06255 |  0:00:00s\n",
      "epoch 10 | loss: 0.0235  | val_0_mse: 0.03641 |  0:00:05s\n",
      "epoch 20 | loss: 0.01986 | val_0_mse: 0.02431 |  0:00:10s\n",
      "epoch 30 | loss: 0.01606 | val_0_mse: 0.01592 |  0:00:16s\n",
      "epoch 40 | loss: 0.01042 | val_0_mse: 0.00897 |  0:00:21s\n",
      "epoch 50 | loss: 0.0117  | val_0_mse: 0.00903 |  0:00:26s\n",
      "epoch 60 | loss: 0.01069 | val_0_mse: 0.00846 |  0:00:31s\n",
      "epoch 70 | loss: 0.00967 | val_0_mse: 0.00893 |  0:00:36s\n",
      "epoch 80 | loss: 0.00969 | val_0_mse: 0.00834 |  0:00:41s\n",
      "epoch 90 | loss: 0.0096  | val_0_mse: 0.00917 |  0:00:46s\n",
      "epoch 100| loss: 0.00941 | val_0_mse: 0.0085  |  0:00:52s\n",
      "epoch 110| loss: 0.00963 | val_0_mse: 0.00863 |  0:00:57s\n",
      "epoch 120| loss: 0.0097  | val_0_mse: 0.00854 |  0:01:02s\n",
      "epoch 130| loss: 0.0093  | val_0_mse: 0.00882 |  0:01:07s\n",
      "epoch 140| loss: 0.00921 | val_0_mse: 0.0088  |  0:01:13s\n",
      "epoch 150| loss: 0.00883 | val_0_mse: 0.00813 |  0:01:18s\n",
      "epoch 160| loss: 0.00889 | val_0_mse: 0.0091  |  0:01:23s\n",
      "epoch 170| loss: 0.00898 | val_0_mse: 0.01133 |  0:01:29s\n",
      "epoch 180| loss: 0.00901 | val_0_mse: 0.00973 |  0:01:34s\n",
      "epoch 190| loss: 0.00913 | val_0_mse: 0.00953 |  0:01:40s\n",
      "epoch 200| loss: 0.00879 | val_0_mse: 0.00949 |  0:01:46s\n",
      "epoch 210| loss: 0.00875 | val_0_mse: 0.00804 |  0:01:51s\n",
      "epoch 220| loss: 0.00894 | val_0_mse: 0.00958 |  0:01:57s\n",
      "epoch 230| loss: 0.00931 | val_0_mse: 0.00877 |  0:02:03s\n",
      "epoch 240| loss: 0.00888 | val_0_mse: 0.00959 |  0:02:09s\n",
      "epoch 250| loss: 0.0083  | val_0_mse: 0.00986 |  0:02:14s\n",
      "epoch 260| loss: 0.00857 | val_0_mse: 0.00873 |  0:02:21s\n",
      "epoch 270| loss: 0.009   | val_0_mse: 0.01002 |  0:02:26s\n",
      "epoch 280| loss: 0.00856 | val_0_mse: 0.00852 |  0:02:32s\n",
      "epoch 290| loss: 0.00962 | val_0_mse: 0.01016 |  0:02:38s\n",
      "epoch 300| loss: 0.00892 | val_0_mse: 0.00929 |  0:02:44s\n",
      "epoch 310| loss: 0.00829 | val_0_mse: 0.00867 |  0:02:50s\n",
      "epoch 320| loss: 0.00874 | val_0_mse: 0.00872 |  0:02:55s\n",
      "epoch 330| loss: 0.00872 | val_0_mse: 0.01125 |  0:03:00s\n",
      "epoch 340| loss: 0.0081  | val_0_mse: 0.00937 |  0:03:05s\n",
      "epoch 350| loss: 0.00924 | val_0_mse: 0.01019 |  0:03:11s\n",
      "epoch 360| loss: 0.00851 | val_0_mse: 0.00892 |  0:03:16s\n",
      "epoch 370| loss: 0.00824 | val_0_mse: 0.00935 |  0:03:21s\n",
      "epoch 380| loss: 0.00826 | val_0_mse: 0.00979 |  0:03:26s\n",
      "epoch 390| loss: 0.00866 | val_0_mse: 0.00834 |  0:03:31s\n",
      "epoch 400| loss: 0.00835 | val_0_mse: 0.00963 |  0:03:36s\n",
      "epoch 410| loss: 0.00832 | val_0_mse: 0.00855 |  0:03:41s\n",
      "epoch 420| loss: 0.00817 | val_0_mse: 0.00883 |  0:03:46s\n",
      "epoch 430| loss: 0.00822 | val_0_mse: 0.01099 |  0:03:51s\n",
      "epoch 440| loss: 0.01036 | val_0_mse: 0.01667 |  0:03:56s\n",
      "epoch 450| loss: 0.00786 | val_0_mse: 0.01248 |  0:04:02s\n",
      "epoch 460| loss: 0.00804 | val_0_mse: 0.00993 |  0:04:07s\n",
      "epoch 470| loss: 0.0086  | val_0_mse: 0.00909 |  0:04:12s\n",
      "epoch 480| loss: 0.00807 | val_0_mse: 0.00879 |  0:04:17s\n",
      "epoch 490| loss: 0.00816 | val_0_mse: 0.0118  |  0:04:22s\n",
      "epoch 500| loss: 0.00774 | val_0_mse: 0.00928 |  0:04:27s\n",
      "epoch 510| loss: 0.00829 | val_0_mse: 0.00987 |  0:04:33s\n",
      "epoch 520| loss: 0.00778 | val_0_mse: 0.00958 |  0:04:38s\n",
      "epoch 530| loss: 0.01073 | val_0_mse: 0.01187 |  0:04:44s\n",
      "epoch 540| loss: 0.00852 | val_0_mse: 0.00941 |  0:04:50s\n",
      "epoch 550| loss: 0.0076  | val_0_mse: 0.00986 |  0:04:55s\n",
      "epoch 560| loss: 0.00758 | val_0_mse: 0.00981 |  0:05:02s\n",
      "epoch 570| loss: 0.00866 | val_0_mse: 0.0103  |  0:05:07s\n",
      "epoch 580| loss: 0.00851 | val_0_mse: 0.00946 |  0:05:13s\n",
      "epoch 590| loss: 0.00746 | val_0_mse: 0.00956 |  0:05:19s\n",
      "\n",
      "Early stopping occurred at epoch 596 with best_epoch = 96 and best_val_0_mse = 0.00767\n",
      "BEST VALID SCORE :  0.007669766946011693\n",
      "R2 SCORE :  0.8157599890820143\n"
     ]
    }
   ],
   "source": [
    "### TabNet\n",
    "### X = encoded_vector_BO (Scaling O) , Y = metrics (Scaling X)\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_latent = np.array(encoded_vector_BO.cpu().numpy())\n",
    "Y_latent = np.array(new_metrics_re)\n",
    "\n",
    "lt_X_train, lt_X_test, lt_y_train, lt_y_test = train_test_split(X_latent,Y_latent,test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "y_train_tps = lt_y_train[:,0][:, np.newaxis]\n",
    "y_train_latecy = lt_y_train[:,1][:, np.newaxis]\n",
    "y_test_tps = lt_y_test[:,0][:, np.newaxis]\n",
    "y_test_latecy = lt_y_test[:,1][:, np.newaxis]\n",
    "\n",
    "\n",
    "Y_scaler_tps  = MinMaxScaler().fit(y_train_tps)\n",
    "Y_scaler_latecy = MinMaxScaler().fit(y_train_latecy)\n",
    "\n",
    "\n",
    "scaled_lt_y_train_tps = Y_scaler_tps.transform(y_train_tps)\n",
    "scaled_lt_y_train_latency = Y_scaler_latecy.transform(y_train_latecy)\n",
    "\n",
    "\n",
    "scaled_lt_y_test_tps = Y_scaler_tps.transform(y_test_tps)\n",
    "scaled_lt_y_test_latency = Y_scaler_latecy.transform(y_test_latecy)\n",
    "\n",
    "\n",
    "scaled_lt_y_train = np.concatenate([scaled_lt_y_train_tps, scaled_lt_y_train_latency], axis = 1)\n",
    "scaled_lt_y_test = np.concatenate([scaled_lt_y_test_tps, scaled_lt_y_test_latency], axis = 1)\n",
    "\n",
    "# Tabnet 모델 생성\n",
    "lt_regressor = TabNetRegressor(verbose = 10,seed = 42,optimizer_fn=torch.optim.AdamW) \n",
    "    \n",
    "# 모델 학습\n",
    "lt_regressor.fit(X_train=lt_X_train, y_train=scaled_lt_y_train,\n",
    "              eval_set=[(lt_X_test, scaled_lt_y_test)],\n",
    "              patience=500, \n",
    "              batch_size = 128,\n",
    "              max_epochs=10000,\n",
    "              eval_metric=['mse'])\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "lt_predictions = lt_regressor.predict(lt_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "print('BEST VALID SCORE : ', lt_regressor.best_cost)\n",
    "print('R2 SCORE : ' , r2_score(scaled_lt_y_test, lt_predictions))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 R2 Score: 0.8280060898280014\n",
      "Column 1 R2 Score: 0.7326875440205318\n"
     ]
    }
   ],
   "source": [
    "#Column 0 : TPS\n",
    "#Column 1 : Latency\n",
    "\n",
    "for i in range(2):  \n",
    "    r2_score_column = r2_score(lt_predictions[:, i], scaled_lt_y_test[:, i])\n",
    "    print(f'Column {i} R2 Score: {r2_score_column}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_pd = pd.DataFrame(encoded_vector_BO.cpu().numpy())\n",
    "latent_pd_T = latent_pd.T\n",
    "# latent_pd_T.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BO 코드\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "\n",
    "class BO(object):\n",
    "    def __init__(self, iteration, configs, metrics, config_info_path=None):\n",
    "        self.iteration = iteration\n",
    "        self.configs = configs\n",
    "        self.metrics = metrics\n",
    "        self.config_info_path = config_info_path\n",
    "        # self.min_max_same_knobs = []\n",
    "        \n",
    "        self._get_config_info()\n",
    "        self._init_pbounds()\n",
    "    \n",
    "    def _get_config_info(self):\n",
    "        if self.config_info_path is None:\n",
    "            self.config_info = pd.read_csv('/home/sein/mk_config/Knob_Information_MySQL_v5.7.csv', index_col=0)\n",
    "        else:\n",
    "            self.config_info = pd.read_csv(self.config_info_path, index_col=0)\n",
    "        \n",
    "        # if self.top_z_knob is not None:\n",
    "        #     self.config_info = self.config_info.loc[self.top_z_knob]\n",
    "        #     self.configs = self.configs[self.top_z_knob]\n",
    "            \n",
    "\n",
    "#     def _get_history(self):\n",
    "#         self.history_configs = self.smac.runhistory.get_configs()\n",
    "    \n",
    "    def _init_pbounds(self):\n",
    "        self.pbounds = {}\n",
    "        \n",
    "        for v in latent_pd_T.index:\n",
    "            self.pbounds[str(v)] = (0, 1)\n",
    "            \n",
    "    \n",
    "    def train_regression_model(self):\n",
    "        X_all = np.array(self.configs)\n",
    "        Y_all = np.array(self.metrics)\n",
    "        \n",
    "        cnt = 0\n",
    "        while(True):\n",
    "            bo_lt_X_train, bo_lt_X_test, bo_lt_y_train, bo_lt_y_test = train_test_split(X_all,Y_all,test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "            bo_y_train_tps = bo_lt_y_train[:,0][:, np.newaxis]\n",
    "            bo_y_train_latecy = bo_lt_y_train[:,1][:, np.newaxis]\n",
    "            bo_y_test_tps = bo_lt_y_test[:,0][:, np.newaxis]\n",
    "            bo_y_test_latecy = bo_lt_y_test[:,1][:, np.newaxis]\n",
    "\n",
    "\n",
    "            bo_Y_scaler_tps  = MinMaxScaler().fit(bo_y_train_tps)\n",
    "            bo_Y_scaler_latecy = MinMaxScaler().fit(bo_y_train_latecy)\n",
    "\n",
    "\n",
    "            bo_scaled_lt_y_train_tps = bo_Y_scaler_tps.transform(bo_y_train_tps)\n",
    "            bo_scaled_lt_y_train_latency = bo_Y_scaler_latecy.transform(bo_y_train_latecy)\n",
    "\n",
    "\n",
    "            bo_scaled_lt_y_test_tps = bo_Y_scaler_tps.transform(bo_y_test_tps)\n",
    "            bo_scaled_lt_y_test_latency = bo_Y_scaler_latecy.transform(bo_y_test_latecy)\n",
    "\n",
    "\n",
    "            bo_scaled_lt_y_train = np.concatenate([bo_scaled_lt_y_train_tps, bo_scaled_lt_y_train_latency], axis = 1)\n",
    "            bo_scaled_lt_y_test = np.concatenate([bo_scaled_lt_y_test_tps, bo_scaled_lt_y_test_latency], axis = 1)\n",
    "\n",
    "            # Tabnet 모델 생성\n",
    "            bo_lt_regressor = TabNetRegressor(verbose = 10,seed = 42,optimizer_fn=torch.optim.AdamW) \n",
    "                \n",
    "            # 모델 학습\n",
    "            bo_lt_regressor.fit(X_train=bo_lt_X_train, y_train=bo_scaled_lt_y_train,\n",
    "                        eval_set=[(bo_lt_X_test, bo_scaled_lt_y_test)],\n",
    "                        patience=200, \n",
    "                        batch_size = 128,\n",
    "                        max_epochs=10000,\n",
    "                        eval_metric=['mse'])\n",
    "\n",
    "            # 테스트 데이터로 예측\n",
    "            bo_lt_predictions = bo_lt_regressor.predict(bo_lt_X_test)\n",
    "\n",
    "            accuracy = r2_score(bo_scaled_lt_y_test, bo_lt_predictions)\n",
    "            cnt += 1\n",
    "            \n",
    "            print(cnt, accuracy)\n",
    "            # print(r2_score_)\n",
    "            if accuracy > 0.80 or cnt > 15:\n",
    "            # if accuracy > 0.80 or cnt > 10:\n",
    "                break\n",
    "\n",
    "\n",
    "        self.model = bo_lt_regressor\n",
    "    \n",
    "    def _target_function(self, **kwargs):\n",
    "        x = np.fromiter(kwargs.values(), dtype=float)        \n",
    "        # scaled_X = self.X_scaler.transform([x])\n",
    "        x = x.reshape(1, -1)\n",
    "\n",
    "        res = self.model.predict(x)\n",
    "        res = res[:,0] / res[:,1]\n",
    "\n",
    "        \n",
    "        return res.squeeze()\n",
    "        # return res\n",
    "    \n",
    "    \n",
    "    def tune(self):\n",
    "        self.optimizer = BayesianOptimization(f=self._target_function, pbounds=self.pbounds, verbose=2, random_state=2)\n",
    "\n",
    "        self.acquisition_function = UtilityFunction(kind=\"ucb\", kappa=2.5, xi=0.0)\n",
    "        \n",
    "        self.optimizer.maximize(n_iter=self.iteration, acquisition_function=self.acquisition_function)\n",
    "    \n",
    "    \n",
    "    def plot_history(self):\n",
    "        self.y_obs = - np.array([res[\"target\"] for res in self.optimizer.res])\n",
    "        \n",
    "        self.his_inc = []\n",
    "        inc = np.inf\n",
    "        ## Get minimum results on each iteration\n",
    "        for res in self.y_obs:\n",
    "            if res < inc:\n",
    "                inc = res\n",
    "            self.his_inc.append(inc)\n",
    "#             res.append(his_res)\n",
    "\n",
    "        plt.plot(self.his_inc)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('result')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.16335 | val_0_mse: 0.05572 |  0:00:00s\n",
      "epoch 10 | loss: 0.04503 | val_0_mse: 0.03824 |  0:00:05s\n",
      "epoch 20 | loss: 0.02641 | val_0_mse: 0.02193 |  0:00:11s\n",
      "epoch 30 | loss: 0.02142 | val_0_mse: 0.01762 |  0:00:16s\n",
      "epoch 40 | loss: 0.01279 | val_0_mse: 0.01015 |  0:00:21s\n",
      "epoch 50 | loss: 0.01194 | val_0_mse: 0.00848 |  0:00:27s\n",
      "epoch 60 | loss: 0.01106 | val_0_mse: 0.00819 |  0:00:32s\n"
     ]
    }
   ],
   "source": [
    "tuner1 = BO(iteration=500, \n",
    "           configs=encoded_vector_BO.cpu().numpy(),\n",
    "           metrics=new_metrics_re\n",
    "           )\n",
    "tuner1.train_regression_model()\n",
    "tuner1.tune()\n",
    "# tuner1.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [0.3546, 0.9711, 0.9019, 0.2642, 0.2349, 0.4112, 0.1512, 0.1086, 0.1675, 0.4652,\n",
    "           0.376, 0.9042, 0.6211, 0.1626, 0.07484, 0.6172, 0.552, 0.9333, 0.304, 0.9188,\n",
    "           0.693, 0.6077, 0.7896, 0.04812, 0.7077, 0.9259, 0.9158, 0.8643, 0.8661, 0.6548,\n",
    "           0.02615, 0.4607    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [0.9618, 0.3722, 0.7729, 0.4546, 0.8661, 0.06776, 0.9388, 0.2249, 0.07023, 0.8804, 0.4176,\n",
    "           0.4351, 0.5852, 0.725, 0.3785, 0.5668, 0.7144, 0.995, 0.3073, 0.3751, 0.2147, 0.7408, 0.5485,\n",
    "           0.2331, 0.2247, 0.9888, 0.9828, 0.3256, 0.2536, 0.01244, 0.64, 0.9643]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 301\n",
    "ex_data = [0.4931, 0.7291, 0.4505, 0.3691, 0.6367, 0.6561, 0.3723, 0.4976, 0.107, 0.4179, 0.4955, 0.2148,\n",
    "           0.5197, 0.6373, 0.8811, 0.3118, 0.1337, 0.7465, 0.419, 0.8468, 0.7187, 0.224, 0.8018, 0.242,\n",
    "           0.2459, 0.4506, 0.1481, 0.9133, 0.04877, 0.1811, 0.6616, 0.5162]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data =[ 0.295, 0.2464, 0.02532, 0.2994 , 0.9239 , 0.5085, 0.7516, 0.5198, 0.1143, 0.07715, 0.19,\n",
    "          0.2036, 0.1861, 0.8925, 0.5809, 0.07957, 0.04564 , 0.4103, 0.9057 , 0.858, 0.1212 , 0.1456,\n",
    "          0.5389, 0.01004, 0.4877, 0.3032, 0.1374  , 0.3655, 0.3292, 0.1167, 0.9661, 0.5865    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [ 0.5989, 0.6535, 1.0, 1.0, 0.9358, 0.2016, 0.6339, 0.2643, 0.4399, 0.8901, 0.1237,\n",
    "           0.8871, 0.01579, 0.0, 0.7095, 1.0, 0.7003, 0.0, 0.6319, 0.5627, 0.4721, 1.0, 0.6835,\n",
    "           1.0, 0.4434, 0.6883, 0.3917, 0.7877, 0.9302, 0.0 , 0.3283,0.05329]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [ 0.9467, 0.8897, 0.04139, 0.8331 , 0.03097, 0.8817, 0.938, 0.9646, 0.423, 0.6093, 0.2503,\n",
    "           0.8941, 0.5266, 0.4789, 0.9658, 0.1991, 0.4304, 0.3647, 0.5328, 0.7102, 0.4317, 0.1061, 0.6753,\n",
    "           0.2636, 0.08931, 0.3551, 0.1502, 0.4734,  0.7568, 0.9803, 0.5425, 0.02154]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [1.0, 1.0, 1.0, 0.0,  0.7975, 0.3905, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0,\n",
    "           0.0, 1.0, 0.0, 0.7256, 0.0, 1.0, 0.527, 1.0, 0.0, 1.0, 0.4914, 1.0, 0.0, 0.0\n",
    "           ,0.0, 0.01117, 0.0, 1.0       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [0.5494, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5693, 0.0, 1.0,\n",
    "           1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4091, 0.1591, 0.0, 0.0,\n",
    "           0.01145, 0.2698, 1.0, 0.0, 0.0, 0.3225    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [ 1.0, 1.0, 1.0, 0.9799, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,\n",
    "           1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8323,\n",
    "           1.0, 0.1401, 0.6034, 0.607, 1.0, 1.0       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Value: tensor([9.9990e-01, 7.4570e-01, 9.3402e-01, 3.2051e-02, 9.8199e-01, 1.2157e-03,\n",
      "        5.3465e-01, 5.0008e-01, 3.5348e-02, 1.6705e-01, 0.0000e+00, 5.4939e-01,\n",
      "        4.7619e-01, 9.5016e-18, 3.9248e-01, 7.2038e-01, 4.2528e-02, 1.6436e-05,\n",
      "        9.2699e-01, 4.4143e-01, 7.4226e-01, 2.3713e-01, 8.1035e-01, 7.0610e-01,\n",
      "        1.0000e+00, 4.9119e-02, 5.2803e-01, 8.4461e-01, 4.9481e-01, 8.3590e-01,\n",
      "        1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0556e-01, 1.5783e-05, 4.3472e-01,\n",
      "        9.9952e-01, 1.0000e+00, 4.4598e-01, 8.2319e-01, 3.2329e-01, 3.0116e-02,\n",
      "        7.1169e-01, 9.8863e-01, 9.9308e-01, 5.2211e-01, 9.4932e-01, 5.1375e-01,\n",
      "        9.4406e-01, 6.5461e-01, 7.9183e-01, 3.1489e-01, 7.2419e-01, 3.4959e-03,\n",
      "        9.8779e-01, 6.0336e-01, 9.4011e-01, 1.1281e-01, 2.3797e-05, 1.4208e-01,\n",
      "        1.0000e+00, 6.5383e-02, 2.4558e-01, 2.6332e-01, 0.0000e+00, 6.5148e-01,\n",
      "        7.2104e-01, 1.5026e-01, 1.0000e+00, 6.1937e-01, 3.4244e-01, 1.8032e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.5148e-11, 8.8563e-29, 8.0676e-02, 3.5753e-07,\n",
      "        6.8496e-02, 1.0413e-01, 1.6229e-12, 8.4185e-01, 1.0000e+00, 9.9986e-01,\n",
      "        6.6246e-01, 2.3369e-01, 1.2604e-01, 2.5460e-02, 5.4175e-01, 3.7177e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.1697e-10, 9.0799e-01, 8.4106e-01, 3.6571e-01,\n",
      "        1.5937e-02, 9.9732e-01, 8.6311e-01, 3.9098e-01, 1.9077e-01, 4.7788e-01,\n",
      "        6.7599e-01, 9.9094e-01, 5.2068e-01, 5.4616e-01, 6.9890e-02, 3.0739e-01,\n",
      "        4.5133e-02, 4.1117e-01, 3.4293e-02, 3.6837e-09, 5.9816e-01, 3.8372e-03,\n",
      "        3.9035e-01, 5.7442e-01, 1.8429e-01, 5.3722e-01, 8.8945e-02, 2.9151e-01,\n",
      "        1.0388e-08, 9.4060e-01, 5.7646e-02, 5.5153e-01, 0.0000e+00, 1.0000e+00,\n",
      "        5.6120e-07, 4.6600e-01, 9.9098e-01, 7.5168e-01, 2.6871e-01, 1.6352e-01,\n",
      "        1.3144e-01, 7.0426e-02, 7.0088e-01, 1.7680e-02, 8.1259e-01, 7.2542e-05,\n",
      "        9.9984e-01, 5.0074e-03], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ex_data = torch.tensor(ex_data)\n",
    "ex_data = ex_data.to('cuda:0')  # ex_data를 GPU로 이동\n",
    "\n",
    "with torch.no_grad():\n",
    "    decode_value = model.decoder(ex_data)\n",
    "    print(\"Decoded Value:\", decode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_values = [float(value) for value in decode_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 원본\n",
    "\n",
    "df_converted_values = pd.DataFrame(converted_values)\n",
    "\n",
    "real_bo_config = df_converted_values[:138] \n",
    "real_v = np.array(real_bo_config)\n",
    "\n",
    "rescaled_bo_config = X_scaler.inverse_transform(real_v.reshape(1,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.887820721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.514091551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.489566714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.388822943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276590407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.474616259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.959251344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.401089281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.495631337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0   0.887820721\n",
       "1   0.514091551\n",
       "2   0.489566714\n",
       "3   0.388822943\n",
       "4   0.276590407\n",
       "..          ...\n",
       "133 0.474616259\n",
       "134 0.959251344\n",
       "135 0.401089281\n",
       "136 0.495631337\n",
       "137 1.000000000\n",
       "\n",
       "[138 rows x 1 columns]"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_bo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999897599</td>\n",
       "      <td>44742.240098119</td>\n",
       "      <td>9794163.385498047</td>\n",
       "      <td>32051.287591457</td>\n",
       "      <td>981987.655162811</td>\n",
       "      <td>0.001215736</td>\n",
       "      <td>5608096.706787109</td>\n",
       "      <td>536955584.000000000</td>\n",
       "      <td>0.247436769</td>\n",
       "      <td>5.011551529</td>\n",
       "      <td>...</td>\n",
       "      <td>519307.327426910</td>\n",
       "      <td>751677.751541138</td>\n",
       "      <td>27163.336646557</td>\n",
       "      <td>1636.067554563</td>\n",
       "      <td>9.280848533</td>\n",
       "      <td>1153.856201172</td>\n",
       "      <td>752564210.299133301</td>\n",
       "      <td>3323.266632080</td>\n",
       "      <td>106699.472167969</td>\n",
       "      <td>0.000072542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0               1                 2               3    \\\n",
       "0 0.999897599 44742.240098119 9794163.385498047 32051.287591457   \n",
       "\n",
       "               4           5                 6                   7    \\\n",
       "0 981987.655162811 0.001215736 5608096.706787109 536955584.000000000   \n",
       "\n",
       "          8           9    ...              128              129  \\\n",
       "0 0.247436769 5.011551529  ... 519307.327426910 751677.751541138   \n",
       "\n",
       "              130            131         132            133  \\\n",
       "0 27163.336646557 1636.067554563 9.280848533 1153.856201172   \n",
       "\n",
       "                  134            135              136         137  \n",
       "0 752564210.299133301 3323.266632080 106699.472167969 0.000072542  \n",
       "\n",
       "[1 rows x 138 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.9f}'.format #지수함수 없이 출력하는 option\n",
    "\n",
    "rescaled_actual_pd = pd.DataFrame(rescaled_bo_config)\n",
    "rescaled_actual_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3577182.25"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(A_config.columns)\n",
    "rescaled_bo_config.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatic_sp_privileges  = 1\n",
      "back_log  = 44742\n",
      "binlog_cache_size  = 9794163\n",
      "binlog_group_commit_sync_delay  = 32051\n",
      "binlog_group_commit_sync_no_delay_count  = 981988\n",
      "binlog_rows_query_log_events  = 0\n",
      "binlog_stmt_cache_size  = 5608097\n",
      "bulk_insert_buffer_size  = 536955584\n",
      "default_week_format  = 0\n",
      "div_precision_increment  = 5\n",
      "end_markers_in_json  = 0\n",
      "eq_range_index_dive_limit  = 5494\n",
      "expire_logs_days  = 3\n",
      "explicit_defaults_for_timestamp  = 0\n",
      "flush_time  = 71\n",
      "ft_min_word_len  = 12\n",
      "ft_query_expansion_limit  = 43\n",
      "general_log  = 0\n",
      "group_concat_max_len  = 3797\n",
      "innodb_adaptive_hash_index_parts  = 227\n",
      "innodb_adaptive_max_sleep_delay  = 742264\n",
      "innodb_autoextend_increment  = 239\n",
      "innodb_buffer_pool_size  = 14125306624\n",
      "innodb_change_buffer_max_size  = 35\n",
      "innodb_cmp_per_index_enabled  = 1\n",
      "innodb_commit_concurrency  = 49\n",
      "innodb_compression_failure_threshold_pct  = 53\n",
      "innodb_compression_level  = 8\n",
      "innodb_compression_pad_pct_max  = 37\n",
      "innodb_concurrency_tickets  = 83590\n",
      "innodb_deadlock_detect  = 1\n",
      "innodb_disable_sort_file_cache  = 0\n",
      "innodb_file_per_table  = 1\n",
      "innodb_fill_factor  = 20\n",
      "innodb_flush_sync  = 0\n",
      "innodb_ft_cache_size  = 35547704\n",
      "innodb_ft_enable_diag_print  = 1\n",
      "innodb_ft_enable_stopword  = 1\n",
      "innodb_ft_max_token_size  = 118\n",
      "innodb_ft_min_token_size  = 13\n",
      "innodb_ft_num_word_optimize  = 3910\n",
      "innodb_ft_result_cache_limit  = 33306726\n",
      "innodb_ft_sort_pll_degree  = 23\n",
      "innodb_ft_total_cache_size  = 1285817595\n",
      "innodb_io_capacity  = 9931\n",
      "innodb_io_capacity_max  = 52207\n",
      "innodb_log_buffer_size  = 1015399643\n",
      "innodb_log_file_size  = 553679269\n",
      "innodb_log_write_ahead_size  = 15496\n",
      "innodb_lru_scan_depth  = 6581\n",
      "innodb_max_dirty_pages_pct  = 78\n",
      "innodb_max_dirty_pages_pct_lwm  = 31\n",
      "innodb_max_purge_lag  = 72419\n",
      "innodb_max_purge_lag_delay  = 34959\n",
      "innodb_max_undo_log_size  = 16970201137\n",
      "innodb_old_blocks_time  = 36201\n",
      "innodb_online_alter_log_max_size  = 1009441173\n",
      "innodb_open_files  = 11290\n",
      "innodb_optimize_fulltext_only  = 0\n",
      "innodb_page_cleaners  = 10\n",
      "innodb_print_all_deadlocks  = 1\n",
      "innodb_purge_batch_size  = 328\n",
      "innodb_purge_rseg_truncate_frequency  = 32\n",
      "innodb_purge_threads  = 9\n",
      "innodb_random_read_ahead  = 0\n",
      "innodb_read_ahead_threshold  = 42\n",
      "innodb_read_io_threads  = 46\n",
      "innodb_replication_delay  = 9016\n",
      "innodb_rollback_on_timeout  = 1\n",
      "innodb_rollback_segments  = 80\n",
      "innodb_sort_buffer_size  = 23023772\n",
      "innodb_spin_wait_delay  = 36\n",
      "innodb_stats_auto_recalc  = 1\n",
      "innodb_stats_include_delete_marked  = 1\n",
      "innodb_stats_on_metadata  = 0\n",
      "innodb_stats_persistent  = 0\n",
      "innodb_stats_transient_sample_pages  = 8069\n",
      "innodb_strict_mode  = 0\n",
      "innodb_sync_array_size  = 71\n",
      "innodb_sync_spin_loops  = 21\n",
      "innodb_table_locks  = 0\n",
      "innodb_thread_concurrency  = 84\n",
      "innodb_undo_log_truncate  = 1\n",
      "innodb_use_native_aio  = 1\n",
      "innodb_write_io_threads  = 43\n",
      "join_buffer_size  = 2450556\n",
      "key_buffer_size  = 135329616\n",
      "key_cache_age_threshold  = 352\n",
      "key_cache_block_size  = 9111\n",
      "key_cache_division_limit  = 38\n",
      "local_infile  = 1\n",
      "log_bin_trust_function_creators  = 1\n",
      "log_queries_not_using_indexes  = 0\n",
      "log_slow_admin_statements  = 1\n",
      "long_query_time  = 151\n",
      "max_allowed_packet  = 392685080\n",
      "max_binlog_cache_size  = 21239492\n",
      "max_binlog_size  = 2141736971\n",
      "max_binlog_stmt_cache_size  = 1853523889\n",
      "max_digest_length  = 410596\n",
      "max_error_count  = 12530\n",
      "max_heap_table_size  = 513130410\n",
      "max_length_for_sort_data  = 5670609\n",
      "max_points_in_geometry  = 1039079\n",
      "max_prepared_stmt_count  = 545968\n",
      "max_sort_length  = 4581502\n",
      "max_write_lock_count  = 69891\n",
      "net_buffer_length  = 323031\n",
      "net_read_timeout  = 37\n",
      "net_write_timeout  = 109\n",
      "ngram_token_size  = 1\n",
      "optimizer_prune_level  = 0\n",
      "optimizer_search_depth  = 37\n",
      "preload_buffer_size  = 258527\n",
      "query_alloc_block_size  = 26145432\n",
      "query_cache_limit  = 616775296\n",
      "query_cache_min_res_unit  = 12367775\n",
      "query_cache_size  = 576832000\n",
      "query_cache_wlock_invalidate  = 0\n",
      "query_prealloc_size  = 19748481\n",
      "range_alloc_block_size  = 4097\n",
      "read_buffer_size  = 63123263\n",
      "read_rnd_buffer_size  = 3868527\n",
      "session_track_schema  = 1\n",
      "session_track_state_change  = 0\n",
      "show_compatibility_56  = 1\n",
      "slow_query_log  = 0\n",
      "sort_buffer_size  = 31290400\n",
      "stored_program_cache  = 519307\n",
      "sync_binlog  = 751678\n",
      "table_definition_cache  = 27163\n",
      "table_open_cache  = 1636\n",
      "table_open_cache_instances  = 9\n",
      "thread_cache_size  = 1154\n",
      "tmp_table_size  = 752564210\n",
      "transaction_alloc_block_size  = 3323\n",
      "transaction_prealloc_size  = 106699\n",
      "updatable_views_with_limit  = 0\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(A_config.columns)):\n",
    "    print('{} = {}'.format(A_config.columns[i], round(rescaled_actual_pd.iloc[0][i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
