{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sdv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPS과 Latency에 대해서 각각 다른 scaler 사용하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepare (Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A_metrics = pd.read_csv(\"/home/sein/mk_config/ycsb_AA/results/external_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_metrics = pd.read_csv(\"/home/sein/mk_config/ycsb_AA/results/external_metrics.csv\")\n",
    "\n",
    "metrics = A_metrics.drop(['Unnamed: 0'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.138889</td>\n",
       "      <td>11836756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.149999</td>\n",
       "      <td>16386967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.227778</td>\n",
       "      <td>19293708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.188888</td>\n",
       "      <td>10529195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.272221</td>\n",
       "      <td>9697154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tps   latency\n",
       "0       0.216666  20847397\n",
       "1       0.322221  12744942\n",
       "2    3789.313102      1076\n",
       "3       0.166667  12510551\n",
       "4       0.266666  10686198\n",
       "..           ...       ...\n",
       "995     0.138889  11836756\n",
       "996     0.149999  16386967\n",
       "997     0.227778  19293708\n",
       "998     0.188888  10529195\n",
       "999     0.272221   9697154\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = metrics.replace([np.inf],9999999)\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1055552118015207 4163.050339357126\n",
      "898 22452142\n"
     ]
    }
   ],
   "source": [
    "print(metrics['tps'].min() , metrics['tps'].max())\n",
    "print(metrics['latency'].min() , metrics['latency'].max())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepare (Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "knob_list = glob.glob(\"/home/sein/mk_config/ycsb_AA/configs/my_*.cnf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sample</th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>stored_program_cache</th>\n",
       "      <th>sync_binlog</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>489472</td>\n",
       "      <td>200000</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>374528</td>\n",
       "      <td>50000</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>37120</td>\n",
       "      <td>660000</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>427776</td>\n",
       "      <td>430000</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>388096</td>\n",
       "      <td>880000</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>4276224</td>\n",
       "      <td>945000</td>\n",
       "      <td>610000</td>\n",
       "      <td>1</td>\n",
       "      <td>4096000</td>\n",
       "      <td>432013312</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>159744</td>\n",
       "      <td>520000</td>\n",
       "      <td>91200</td>\n",
       "      <td>8000</td>\n",
       "      <td>63</td>\n",
       "      <td>7680</td>\n",
       "      <td>163577856</td>\n",
       "      <td>57344</td>\n",
       "      <td>104448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>57000</td>\n",
       "      <td>5636096</td>\n",
       "      <td>245000</td>\n",
       "      <td>211000</td>\n",
       "      <td>1</td>\n",
       "      <td>8716288</td>\n",
       "      <td>268435456</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>455936</td>\n",
       "      <td>940000</td>\n",
       "      <td>89600</td>\n",
       "      <td>2000</td>\n",
       "      <td>29</td>\n",
       "      <td>11520</td>\n",
       "      <td>230686720</td>\n",
       "      <td>69632</td>\n",
       "      <td>61440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>622592</td>\n",
       "      <td>45000</td>\n",
       "      <td>537000</td>\n",
       "      <td>1</td>\n",
       "      <td>393216</td>\n",
       "      <td>671088640</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>308480</td>\n",
       "      <td>810000</td>\n",
       "      <td>66000</td>\n",
       "      <td>8000</td>\n",
       "      <td>48</td>\n",
       "      <td>12544</td>\n",
       "      <td>536870912</td>\n",
       "      <td>81920</td>\n",
       "      <td>108544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>5505024</td>\n",
       "      <td>700000</td>\n",
       "      <td>598000</td>\n",
       "      <td>0</td>\n",
       "      <td>9125888</td>\n",
       "      <td>834666496</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>404992</td>\n",
       "      <td>260000</td>\n",
       "      <td>70400</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>3840</td>\n",
       "      <td>218103808</td>\n",
       "      <td>36864</td>\n",
       "      <td>63488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>10420224</td>\n",
       "      <td>75000</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>8683520</td>\n",
       "      <td>838860800</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>81920</td>\n",
       "      <td>140000</td>\n",
       "      <td>81600</td>\n",
       "      <td>8000</td>\n",
       "      <td>32</td>\n",
       "      <td>5632</td>\n",
       "      <td>801112064</td>\n",
       "      <td>106496</td>\n",
       "      <td>75776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Sample automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                             1     24000            7700480   \n",
       "1                             0     15000             622592   \n",
       "2                             1      8000            7110656   \n",
       "3                             0     34000            8519680   \n",
       "4                             0     12000            6291456   \n",
       "..                          ...       ...                ...   \n",
       "995                           1     18000            4276224   \n",
       "996                           1     57000            5636096   \n",
       "997                           1      2000             622592   \n",
       "998                           0     38000            5505024   \n",
       "999                           1     10000           10420224   \n",
       "\n",
       "Sample binlog_group_commit_sync_delay   \\\n",
       "0                               485000   \n",
       "1                               140000   \n",
       "2                               440000   \n",
       "3                               760000   \n",
       "4                               380000   \n",
       "..                                 ...   \n",
       "995                             945000   \n",
       "996                             245000   \n",
       "997                              45000   \n",
       "998                             700000   \n",
       "999                              75000   \n",
       "\n",
       "Sample binlog_group_commit_sync_no_delay_count  binlog_rows_query_log_events   \\\n",
       "0                                        352000                             0   \n",
       "1                                        701000                             1   \n",
       "2                                        801000                             1   \n",
       "3                                        303000                             0   \n",
       "4                                        630000                             1   \n",
       "..                                          ...                           ...   \n",
       "995                                      610000                             1   \n",
       "996                                      211000                             1   \n",
       "997                                      537000                             1   \n",
       "998                                      598000                             0   \n",
       "999                                       35000                             1   \n",
       "\n",
       "Sample binlog_stmt_cache_size  bulk_insert_buffer_size  default_week_format   \\\n",
       "0                       655360                356515840                    7   \n",
       "1                      2637824                595591168                    5   \n",
       "2                      8093696                570425344                    4   \n",
       "3                     10420224                343932928                    3   \n",
       "4                      5472256                243269632                    1   \n",
       "..                         ...                      ...                  ...   \n",
       "995                    4096000                432013312                    0   \n",
       "996                    8716288                268435456                    1   \n",
       "997                     393216                671088640                    7   \n",
       "998                    9125888                834666496                    3   \n",
       "999                    8683520                838860800                    1   \n",
       "\n",
       "Sample div_precision_increment   ... stored_program_cache  sync_binlog   \\\n",
       "0                             1  ...                489472       200000   \n",
       "1                             8  ...                374528        50000   \n",
       "2                             4  ...                 37120       660000   \n",
       "3                             4  ...                427776       430000   \n",
       "4                            13  ...                388096       880000   \n",
       "..                          ...  ...                   ...          ...   \n",
       "995                          29  ...                159744       520000   \n",
       "996                          24  ...                455936       940000   \n",
       "997                          20  ...                308480       810000   \n",
       "998                          17  ...                404992       260000   \n",
       "999                          11  ...                 81920       140000   \n",
       "\n",
       "Sample table_definition_cache  table_open_cache  table_open_cache_instances   \\\n",
       "0                        13200              4000                          18   \n",
       "1                        91600              4000                          17   \n",
       "2                        15600                 1                           9   \n",
       "3                        11200             10000                           9   \n",
       "4                        11600              4000                          25   \n",
       "..                         ...               ...                         ...   \n",
       "995                      91200              8000                          63   \n",
       "996                      89600              2000                          29   \n",
       "997                      66000              8000                          48   \n",
       "998                      70400              2000                          57   \n",
       "999                      81600              8000                          32   \n",
       "\n",
       "Sample thread_cache_size  tmp_table_size  transaction_alloc_block_size   \\\n",
       "0                   11520       255852544                         28672   \n",
       "1                   15360       402653184                        110592   \n",
       "2                    1024       851443712                          8192   \n",
       "3                   13568       163577856                         16384   \n",
       "4                    1536       348127232                        126976   \n",
       "..                    ...             ...                           ...   \n",
       "995                  7680       163577856                         57344   \n",
       "996                 11520       230686720                         69632   \n",
       "997                 12544       536870912                         81920   \n",
       "998                  3840       218103808                         36864   \n",
       "999                  5632       801112064                        106496   \n",
       "\n",
       "Sample transaction_prealloc_size  updatable_views_with_limit   \n",
       "0                           94208                           0  \n",
       "1                           71680                           1  \n",
       "2                          122880                           0  \n",
       "3                           83968                           0  \n",
       "4                           57344                           0  \n",
       "..                            ...                         ...  \n",
       "995                        104448                           1  \n",
       "996                         61440                           0  \n",
       "997                        108544                           1  \n",
       "998                         63488                           1  \n",
       "999                         75776                           1  \n",
       "\n",
       "[1000 rows x 138 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for xx in range(len(knob_list)):\n",
    "    path = \"/home/sein/mk_config/ycsb_AA/configs/my_{}.cnf\".format(xx)\n",
    "    # knob_list = glob.glob(\"/home/sein/2023_EDBT/KCC_tpcc_dataset/my_*.cnf\")\n",
    "    a_all = pd.read_csv(path, sep=\"=\", names=['Sample', 'value'], header=2)\n",
    "    a_all = a_all.set_index(\"Sample\")\n",
    "    cur_all_df = a_all.T\n",
    "    \n",
    "    if cnt == 0:\n",
    "        A_config = cur_all_df\n",
    "    else :\n",
    "        A_config = pd.concat([A_config, cur_all_df], axis=0)\n",
    "    cnt += 1\n",
    "A_config = A_config.reset_index()\n",
    "A_config = A_config.drop([\"index\"],axis=1)\n",
    "A_config = A_config.drop(A_config.columns[[0,1]], axis=1)\n",
    "\n",
    "\n",
    "A_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>4276224</td>\n",
       "      <td>945000</td>\n",
       "      <td>610000</td>\n",
       "      <td>1</td>\n",
       "      <td>4096000</td>\n",
       "      <td>432013312</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>91200</td>\n",
       "      <td>8000</td>\n",
       "      <td>63</td>\n",
       "      <td>7680</td>\n",
       "      <td>163577856</td>\n",
       "      <td>57344</td>\n",
       "      <td>104448</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>11836756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>57000</td>\n",
       "      <td>5636096</td>\n",
       "      <td>245000</td>\n",
       "      <td>211000</td>\n",
       "      <td>1</td>\n",
       "      <td>8716288</td>\n",
       "      <td>268435456</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>89600</td>\n",
       "      <td>2000</td>\n",
       "      <td>29</td>\n",
       "      <td>11520</td>\n",
       "      <td>230686720</td>\n",
       "      <td>69632</td>\n",
       "      <td>61440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>16386967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>622592</td>\n",
       "      <td>45000</td>\n",
       "      <td>537000</td>\n",
       "      <td>1</td>\n",
       "      <td>393216</td>\n",
       "      <td>671088640</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>66000</td>\n",
       "      <td>8000</td>\n",
       "      <td>48</td>\n",
       "      <td>12544</td>\n",
       "      <td>536870912</td>\n",
       "      <td>81920</td>\n",
       "      <td>108544</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227778</td>\n",
       "      <td>19293708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>5505024</td>\n",
       "      <td>700000</td>\n",
       "      <td>598000</td>\n",
       "      <td>0</td>\n",
       "      <td>9125888</td>\n",
       "      <td>834666496</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>70400</td>\n",
       "      <td>2000</td>\n",
       "      <td>57</td>\n",
       "      <td>3840</td>\n",
       "      <td>218103808</td>\n",
       "      <td>36864</td>\n",
       "      <td>63488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188888</td>\n",
       "      <td>10529195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>10420224</td>\n",
       "      <td>75000</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>8683520</td>\n",
       "      <td>838860800</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>81600</td>\n",
       "      <td>8000</td>\n",
       "      <td>32</td>\n",
       "      <td>5632</td>\n",
       "      <td>801112064</td>\n",
       "      <td>106496</td>\n",
       "      <td>75776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272221</td>\n",
       "      <td>9697154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                          1     24000            7700480   \n",
       "1                          0     15000             622592   \n",
       "2                          1      8000            7110656   \n",
       "3                          0     34000            8519680   \n",
       "4                          0     12000            6291456   \n",
       "..                       ...       ...                ...   \n",
       "995                        1     18000            4276224   \n",
       "996                        1     57000            5636096   \n",
       "997                        1      2000             622592   \n",
       "998                        0     38000            5505024   \n",
       "999                        1     10000           10420224   \n",
       "\n",
       "    binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                            485000                                   352000   \n",
       "1                            140000                                   701000   \n",
       "2                            440000                                   801000   \n",
       "3                            760000                                   303000   \n",
       "4                            380000                                   630000   \n",
       "..                              ...                                      ...   \n",
       "995                          945000                                   610000   \n",
       "996                          245000                                   211000   \n",
       "997                           45000                                   537000   \n",
       "998                          700000                                   598000   \n",
       "999                           75000                                    35000   \n",
       "\n",
       "    binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                               0                  655360   \n",
       "1                               1                 2637824   \n",
       "2                               1                 8093696   \n",
       "3                               0                10420224   \n",
       "4                               1                 5472256   \n",
       "..                            ...                     ...   \n",
       "995                             1                 4096000   \n",
       "996                             1                 8716288   \n",
       "997                             1                  393216   \n",
       "998                             0                 9125888   \n",
       "999                             1                 8683520   \n",
       "\n",
       "    bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                  356515840                    7                        1   \n",
       "1                  595591168                    5                        8   \n",
       "2                  570425344                    4                        4   \n",
       "3                  343932928                    3                        4   \n",
       "4                  243269632                    1                       13   \n",
       "..                       ...                  ...                      ...   \n",
       "995                432013312                    0                       29   \n",
       "996                268435456                    1                       24   \n",
       "997                671088640                    7                       20   \n",
       "998                834666496                    3                       17   \n",
       "999                838860800                    1                       11   \n",
       "\n",
       "     ... table_definition_cache  table_open_cache   \\\n",
       "0    ...                   13200              4000   \n",
       "1    ...                   91600              4000   \n",
       "2    ...                   15600                 1   \n",
       "3    ...                   11200             10000   \n",
       "4    ...                   11600              4000   \n",
       "..   ...                     ...               ...   \n",
       "995  ...                   91200              8000   \n",
       "996  ...                   89600              2000   \n",
       "997  ...                   66000              8000   \n",
       "998  ...                   70400              2000   \n",
       "999  ...                   81600              8000   \n",
       "\n",
       "    table_open_cache_instances  thread_cache_size  tmp_table_size   \\\n",
       "0                            18              11520       255852544   \n",
       "1                            17              15360       402653184   \n",
       "2                             9               1024       851443712   \n",
       "3                             9              13568       163577856   \n",
       "4                            25               1536       348127232   \n",
       "..                          ...                ...             ...   \n",
       "995                          63               7680       163577856   \n",
       "996                          29              11520       230686720   \n",
       "997                          48              12544       536870912   \n",
       "998                          57               3840       218103808   \n",
       "999                          32               5632       801112064   \n",
       "\n",
       "    transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0                           28672                      94208   \n",
       "1                          110592                      71680   \n",
       "2                            8192                     122880   \n",
       "3                           16384                      83968   \n",
       "4                          126976                      57344   \n",
       "..                            ...                        ...   \n",
       "995                         57344                     104448   \n",
       "996                         69632                      61440   \n",
       "997                         81920                     108544   \n",
       "998                         36864                      63488   \n",
       "999                        106496                      75776   \n",
       "\n",
       "    updatable_views_with_limit           tps   latency  \n",
       "0                             0     0.216666  20847397  \n",
       "1                             1     0.322221  12744942  \n",
       "2                             0  3789.313102      1076  \n",
       "3                             0     0.166667  12510551  \n",
       "4                             0     0.266666  10686198  \n",
       "..                          ...          ...       ...  \n",
       "995                           1     0.138889  11836756  \n",
       "996                           0     0.149999  16386967  \n",
       "997                           1     0.227778  19293708  \n",
       "998                           1     0.188888  10529195  \n",
       "999                           1     0.272221   9697154  \n",
       "\n",
       "[1000 rows x 140 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.concat([A_config,metrics], axis=1)\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### boolean에 해당하는 열 정리\n",
    "\n",
    "discrete_columns = [samples.columns[0], samples.columns[5],samples.columns[10],samples.columns[13],\n",
    "                    samples.columns[17],samples.columns[24],samples.columns[30],samples.columns[31],\n",
    "                    samples.columns[32],samples.columns[34],samples.columns[36],samples.columns[37],\n",
    "                    samples.columns[58],samples.columns[60],samples.columns[64],samples.columns[68],\n",
    "                    samples.columns[72],samples.columns[73],samples.columns[74],samples.columns[75],\n",
    "                    samples.columns[77],samples.columns[80],samples.columns[82],samples.columns[83],\n",
    "                    samples.columns[90],samples.columns[91],samples.columns[92],samples.columns[93],\n",
    "                    samples.columns[118],samples.columns[123],samples.columns[124],samples.columns[125],\n",
    "                    samples.columns[126]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### continuous 열 정리\n",
    "all_columns = samples.columns\n",
    "continuous_columns = all_columns.drop(discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(discrete_columns)):\n",
    "    a = discrete_columns[i]\n",
    "    samples = samples.astype({a:'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(continuous_columns)):\n",
    "    a = continuous_columns[i]\n",
    "    samples = samples.astype({a:'float'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config - metric prediction (with raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_all = np.array(A_config)\n",
    "Y_all = np.array(metrics)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all,Y_all,test_size=0.3, shuffle=True)\n",
    "\n",
    "y_train_tps = y_train[:,0][:, np.newaxis]\n",
    "y_train_latency = y_train[:,1][:, np.newaxis]\n",
    "y_test_tps = y_test[:,0][:, np.newaxis]\n",
    "y_test_latency = y_test[:,1][:, np.newaxis]\n",
    " \n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "Y_scaler_latecy = MinMaxScaler().fit(y_train_latency)\n",
    "Y_scaler_tps  = MinMaxScaler().fit(y_train_tps)\n",
    "\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "scaled_y_train_latecy = Y_scaler_latecy.transform(y_train_latency)\n",
    "scaled_y_train_tps = Y_scaler_tps.transform(y_train_tps)\n",
    "\n",
    "scaled_y_test_latecy = Y_scaler_latecy.transform(y_test_latency)\n",
    "scaled_y_test_tps = Y_scaler_tps.transform(y_test_tps)\n",
    "\n",
    "# scaled_y_train = np.concatenate([scaled_y_train_latecy, scaled_y_train_tps], 1)\n",
    "# scaled_y_test = np.concatenate([scaled_y_test_latecy, scaled_y_test_tps], 1)\n",
    "\n",
    "scaled_y_train = np.concatenate([scaled_y_train_tps, scaled_y_train_latecy], 1)\n",
    "scaled_y_test = np.concatenate([scaled_y_test_tps, scaled_y_test_latecy], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 138)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_config.shape\n",
    "# metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.40805 | val_0_mse: 0.15066 |  0:00:00s\n",
      "epoch 10 | loss: 0.06098 | val_0_mse: 0.05742 |  0:00:01s\n",
      "epoch 20 | loss: 0.0562  | val_0_mse: 0.05122 |  0:00:01s\n",
      "epoch 30 | loss: 0.05024 | val_0_mse: 0.05242 |  0:00:02s\n",
      "epoch 40 | loss: 0.04261 | val_0_mse: 0.05373 |  0:00:03s\n",
      "epoch 50 | loss: 0.03195 | val_0_mse: 0.05459 |  0:00:04s\n",
      "epoch 60 | loss: 0.02637 | val_0_mse: 0.0571  |  0:00:05s\n",
      "epoch 70 | loss: 0.02364 | val_0_mse: 0.06252 |  0:00:06s\n",
      "epoch 80 | loss: 0.01788 | val_0_mse: 0.05875 |  0:00:07s\n",
      "epoch 90 | loss: 0.01696 | val_0_mse: 0.04602 |  0:00:08s\n",
      "epoch 100| loss: 0.01314 | val_0_mse: 0.04374 |  0:00:09s\n",
      "epoch 110| loss: 0.01281 | val_0_mse: 0.04782 |  0:00:09s\n",
      "epoch 120| loss: 0.01335 | val_0_mse: 0.04679 |  0:00:10s\n",
      "epoch 130| loss: 0.00784 | val_0_mse: 0.04622 |  0:00:11s\n",
      "epoch 140| loss: 0.00718 | val_0_mse: 0.04834 |  0:00:12s\n",
      "epoch 150| loss: 0.00802 | val_0_mse: 0.04358 |  0:00:13s\n",
      "epoch 160| loss: 0.00803 | val_0_mse: 0.05088 |  0:00:14s\n",
      "epoch 170| loss: 0.00882 | val_0_mse: 0.04517 |  0:00:15s\n",
      "epoch 180| loss: 0.01133 | val_0_mse: 0.03834 |  0:00:16s\n",
      "epoch 190| loss: 0.00966 | val_0_mse: 0.03956 |  0:00:17s\n",
      "epoch 200| loss: 0.007   | val_0_mse: 0.03608 |  0:00:17s\n",
      "epoch 210| loss: 0.01087 | val_0_mse: 0.03326 |  0:00:18s\n",
      "epoch 220| loss: 0.01668 | val_0_mse: 0.03583 |  0:00:19s\n",
      "epoch 230| loss: 0.01053 | val_0_mse: 0.01592 |  0:00:20s\n",
      "epoch 240| loss: 0.00925 | val_0_mse: 0.02017 |  0:00:21s\n",
      "epoch 250| loss: 0.00761 | val_0_mse: 0.02746 |  0:00:22s\n",
      "epoch 260| loss: 0.00648 | val_0_mse: 0.01872 |  0:00:23s\n",
      "epoch 270| loss: 0.00912 | val_0_mse: 0.02363 |  0:00:24s\n",
      "epoch 280| loss: 0.00538 | val_0_mse: 0.01738 |  0:00:24s\n",
      "epoch 290| loss: 0.0079  | val_0_mse: 0.01667 |  0:00:25s\n",
      "epoch 300| loss: 0.00707 | val_0_mse: 0.01403 |  0:00:26s\n",
      "epoch 310| loss: 0.00753 | val_0_mse: 0.01644 |  0:00:27s\n",
      "epoch 320| loss: 0.00423 | val_0_mse: 0.01204 |  0:00:28s\n",
      "epoch 330| loss: 0.00483 | val_0_mse: 0.01013 |  0:00:29s\n",
      "epoch 340| loss: 0.00539 | val_0_mse: 0.01162 |  0:00:30s\n",
      "epoch 350| loss: 0.00606 | val_0_mse: 0.00991 |  0:00:31s\n",
      "epoch 360| loss: 0.00731 | val_0_mse: 0.00928 |  0:00:32s\n",
      "epoch 370| loss: 0.00724 | val_0_mse: 0.01417 |  0:00:32s\n",
      "epoch 380| loss: 0.00676 | val_0_mse: 0.01219 |  0:00:33s\n",
      "epoch 390| loss: 0.00786 | val_0_mse: 0.01696 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 397 with best_epoch = 297 and best_val_0_mse = 0.00807\n",
      "BEST VALID SCORE :  0.008071737711146146\n",
      "R2 SCORE :  0.7910685689381354\n"
     ]
    }
   ],
   "source": [
    "### TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# X_all = np.array(A_config)\n",
    "# Y_all = np.array(metrics)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_all,Y_all,test_size=0.3, shuffle=True)\n",
    "# X_scaler = MinMaxScaler().fit(X_train)\n",
    "# Y_scaler = MinMaxScaler().fit(y_train)\n",
    "\n",
    "# scaled_X_train = X_scaler.transform(X_train)\n",
    "# scaled_X_test = X_scaler.transform(X_test)\n",
    "# scaled_y_train = Y_scaler.transform(y_train)\n",
    "# scaled_y_test = Y_scaler.transform(y_test)\n",
    "\n",
    "# Tabnet 모델 생성\n",
    "regressor = TabNetRegressor(verbose = 10,seed = 42,optimizer_fn=torch.optim.AdamW) ### Basic\n",
    "\n",
    "# 모델 학습\n",
    "regressor.fit(X_train=scaled_X_train, y_train=scaled_y_train,\n",
    "              eval_set=[(scaled_X_test, scaled_y_test)],\n",
    "              patience=100, \n",
    "              batch_size = 128,\n",
    "              max_epochs=10000,\n",
    "              eval_metric=['mse'])\n",
    "\n",
    "predictions = regressor.predict(scaled_X_test)\n",
    "\n",
    "test_score = mean_squared_error(y_pred = predictions, y_true = scaled_y_test)\n",
    "# 성능 평가\n",
    "print('BEST VALID SCORE : ', regressor.best_cost)\n",
    "# print('MSE_SCORE : ', test_score)\n",
    "print('R2 SCORE : ' , r2_score(predictions, scaled_y_test, multioutput='variance_weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score :  0.9782563403900324\n",
      "r2_score :  0.9996099847923541\n",
      "r2_score :  0.9310220806433419\n",
      "r2_score :  0.9985115679882028\n",
      "r2_score :  0.9990994266423234\n",
      "r2_score :  0.9974280193995283\n",
      "r2_score :  0.993010343376478\n",
      "r2_score :  0.24463190779397426\n",
      "r2_score :  0.7991758159788436\n",
      "r2_score :  0.9914877565733856\n",
      "r2_score :  0.9884651492882747\n",
      "r2_score :  0.9647999431395307\n",
      "r2_score :  0.9831199116451871\n",
      "r2_score :  0.9779865737171908\n",
      "r2_score :  0.9886251981036578\n",
      "r2_score :  0.9943959939533816\n",
      "r2_score :  0.9037838406239698\n",
      "r2_score :  0.9997822711061204\n",
      "r2_score :  0.9952209531911554\n",
      "r2_score :  0.9846875067654155\n",
      "r2_score :  0.18293504909283265\n",
      "r2_score :  0.999939555138187\n",
      "r2_score :  0.9252565223822917\n",
      "r2_score :  0.9987273454696858\n",
      "r2_score :  0.9971334323995134\n",
      "r2_score :  0.9793725711908015\n",
      "r2_score :  0.9923113025811909\n",
      "r2_score :  0.9990111752567151\n",
      "r2_score :  0.9975946590469867\n",
      "r2_score :  0.9841542296222879\n",
      "r2_score :  0.9995179827336359\n",
      "r2_score :  0.9718746853663012\n",
      "r2_score :  0.9986075833862132\n",
      "r2_score :  -0.3292753207199388\n",
      "r2_score :  0.7851736801136567\n",
      "r2_score :  0.9771484762243315\n",
      "r2_score :  0.993138267446241\n",
      "r2_score :  0.9925847017665675\n",
      "r2_score :  0.9728097415976242\n",
      "r2_score :  0.9438127378138395\n",
      "r2_score :  0.9118402963649245\n",
      "r2_score :  0.9943239699075753\n",
      "r2_score :  0.9932365242006344\n",
      "r2_score :  0.9850603910377743\n",
      "r2_score :  0.9668784765193179\n",
      "r2_score :  0.9132151206511139\n",
      "r2_score :  0.9834429499032802\n",
      "r2_score :  0.9732703476995516\n",
      "r2_score :  0.9954633414698035\n",
      "r2_score :  0.9907820409183783\n",
      "r2_score :  0.7515078393435459\n",
      "r2_score :  0.9645448080940459\n",
      "r2_score :  0.9899347217931223\n",
      "r2_score :  0.9563181048015522\n",
      "r2_score :  0.8713580151709492\n",
      "r2_score :  0.9955686148367845\n",
      "r2_score :  0.9895211988750107\n",
      "r2_score :  0.9190848945178962\n",
      "r2_score :  0.4479530317024044\n",
      "r2_score :  0.990055003051287\n",
      "r2_score :  0.9999982776124867\n",
      "r2_score :  0.9998532242194812\n",
      "r2_score :  0.9982547503786876\n",
      "r2_score :  0.5967188862123558\n",
      "r2_score :  0.8721801959245238\n",
      "r2_score :  0.9940413361641675\n",
      "r2_score :  0.9999779219265316\n",
      "r2_score :  0.981858152590899\n",
      "r2_score :  0.9599253157977202\n",
      "r2_score :  0.9791219534267233\n",
      "r2_score :  0.9943799850317365\n",
      "r2_score :  0.9973068113005661\n",
      "r2_score :  0.9927785253274342\n",
      "r2_score :  0.9969082756827884\n",
      "r2_score :  0.9674503322716091\n",
      "r2_score :  0.9855916964689113\n",
      "r2_score :  0.965809931617058\n",
      "r2_score :  0.998155471121105\n",
      "r2_score :  0.992897591976035\n",
      "r2_score :  0.9939320248090816\n",
      "r2_score :  0.9757737785871266\n",
      "r2_score :  0.9930300744471229\n",
      "r2_score :  0.8582898498006781\n",
      "r2_score :  0.9739325615526016\n",
      "r2_score :  0.9697052143209127\n",
      "r2_score :  0.9657503272724373\n",
      "r2_score :  0.9741881783595246\n",
      "r2_score :  0.511558233433728\n",
      "r2_score :  0.9239119987748343\n",
      "r2_score :  0.9856768684330682\n",
      "r2_score :  0.5403319086784298\n",
      "r2_score :  0.9999660571529204\n",
      "r2_score :  0.9296580829468903\n",
      "r2_score :  0.984967935283905\n",
      "r2_score :  0.9096835186957422\n",
      "r2_score :  0.9896131449021393\n",
      "r2_score :  0.9833564626088751\n",
      "r2_score :  0.9991865449340328\n",
      "r2_score :  0.7959303465569153\n",
      "r2_score :  0.9927463932846026\n",
      "r2_score :  0.9798234657144143\n",
      "r2_score :  0.9827582667694145\n",
      "r2_score :  0.998269161823788\n",
      "r2_score :  0.9909520051694776\n",
      "r2_score :  0.9834470875205422\n",
      "r2_score :  0.8784653115963642\n",
      "r2_score :  0.9975378434052299\n",
      "r2_score :  0.9995856910871058\n",
      "r2_score :  0.9879887849623341\n",
      "r2_score :  0.9730320238245738\n",
      "r2_score :  0.8123610891148558\n",
      "r2_score :  0.973871937749475\n",
      "r2_score :  0.8293227736930654\n",
      "r2_score :  0.987274279549525\n",
      "r2_score :  0.9098945304072628\n",
      "r2_score :  0.9975287315202946\n",
      "r2_score :  0.9958612785934017\n",
      "r2_score :  0.9996784880673284\n",
      "r2_score :  0.9802608399306646\n",
      "r2_score :  0.9569342336534256\n",
      "r2_score :  0.8866739302000994\n",
      "r2_score :  0.8119493232164795\n",
      "r2_score :  0.9769759669837362\n",
      "r2_score :  0.823416894670744\n",
      "r2_score :  0.9288243369677122\n",
      "r2_score :  0.995039663468841\n",
      "r2_score :  0.9152703492817658\n",
      "r2_score :  0.9945567269186406\n",
      "r2_score :  0.989366996537327\n",
      "r2_score :  0.9990964552895957\n",
      "r2_score :  0.9912839373317692\n",
      "r2_score :  0.965335309086731\n",
      "r2_score :  0.968084325863433\n",
      "r2_score :  0.9876941471592176\n",
      "r2_score :  0.9988672733193763\n",
      "r2_score :  0.9790452725994025\n",
      "r2_score :  0.9483260117843832\n",
      "r2_score :  0.9701566466428356\n",
      "r2_score :  0.9839634439981026\n",
      "r2_score :  -0.8392578691126806\n",
      "r2_score :  0.9889953320889115\n",
      "r2_score :  0.9734818122534553\n",
      "r2_score :  0.9930385963934218\n",
      "r2_score :  -23.705472805619113\n",
      "r2_score :  0.9975510343514843\n",
      "r2_score :  0.972322800662626\n",
      "r2_score :  -6.855154502954064\n",
      "r2_score :  0.9300362483282195\n",
      "r2_score :  0.11946383679300854\n",
      "r2_score :  0.9808955629258461\n",
      "r2_score :  0.9986073916155093\n",
      "r2_score :  0.9518225229113436\n",
      "r2_score :  0.9480574305012429\n",
      "r2_score :  0.9975431021055946\n",
      "r2_score :  0.6242958763830515\n",
      "r2_score :  0.93702468573006\n",
      "r2_score :  0.9984596448591131\n",
      "r2_score :  0.9955282444538466\n",
      "r2_score :  0.9898826004128789\n",
      "r2_score :  0.9966930003627629\n",
      "r2_score :  0.9888091850057598\n",
      "r2_score :  0.9695043491164329\n",
      "r2_score :  0.7640528515459705\n",
      "r2_score :  0.9491272375938877\n",
      "r2_score :  0.9962548131027107\n",
      "r2_score :  0.8811184961779122\n",
      "r2_score :  0.9898934563557428\n",
      "r2_score :  0.9999722717485575\n",
      "r2_score :  0.9444070924790442\n",
      "r2_score :  0.9653898007893472\n",
      "r2_score :  0.9832048208662308\n",
      "r2_score :  0.569311955839394\n",
      "r2_score :  0.9874111073519581\n",
      "r2_score :  0.9840825859562496\n",
      "r2_score :  0.9975827154031949\n",
      "r2_score :  0.9970144520721136\n",
      "r2_score :  0.8571316829079337\n",
      "r2_score :  0.9977215512245503\n",
      "r2_score :  0.988804686779694\n",
      "r2_score :  0.991596578442245\n",
      "r2_score :  0.9918405089192295\n",
      "r2_score :  0.9810450089373726\n",
      "r2_score :  0.9996576412068138\n",
      "r2_score :  0.2663246487782803\n",
      "r2_score :  0.9996713025040032\n",
      "r2_score :  0.9609548064713305\n",
      "r2_score :  0.900269668504154\n",
      "r2_score :  0.987000431616959\n",
      "r2_score :  0.993474156956798\n",
      "r2_score :  0.9977756548069056\n",
      "r2_score :  0.9911370333942267\n",
      "r2_score :  0.9384753877303758\n",
      "r2_score :  0.999362526471927\n",
      "r2_score :  0.31443592066264536\n",
      "r2_score :  0.9960825343852612\n",
      "r2_score :  0.9652507654483948\n",
      "r2_score :  0.9992654461924853\n",
      "r2_score :  0.8941736622598531\n",
      "r2_score :  0.9883615831060932\n",
      "r2_score :  0.9993762047914744\n",
      "r2_score :  0.999526654435165\n",
      "r2_score :  0.9757282548172066\n",
      "r2_score :  0.9987062423972841\n",
      "r2_score :  0.9897550261667634\n",
      "r2_score :  0.7334209606116635\n",
      "r2_score :  0.9590674868199074\n",
      "r2_score :  0.9883837209350763\n",
      "r2_score :  0.45306242068395575\n",
      "r2_score :  0.9823473459471839\n",
      "r2_score :  0.31350300298701794\n",
      "r2_score :  0.9792534190107669\n",
      "r2_score :  0.9654708183267778\n",
      "r2_score :  0.989391538021868\n",
      "r2_score :  0.99960057882903\n",
      "r2_score :  0.9851108596667839\n",
      "r2_score :  0.9754434512065893\n",
      "r2_score :  0.9674083019558513\n",
      "r2_score :  0.9291328899155851\n",
      "r2_score :  0.8433116704740721\n",
      "r2_score :  0.9989149924575891\n",
      "r2_score :  0.9074409857137568\n",
      "r2_score :  0.9999553298840019\n",
      "r2_score :  0.999425885116828\n",
      "r2_score :  0.9915808515822844\n",
      "r2_score :  0.9999731774612826\n",
      "r2_score :  0.9983838235986544\n",
      "r2_score :  0.9950297925702498\n",
      "r2_score :  0.4729736650654992\n",
      "r2_score :  0.984926687938688\n",
      "r2_score :  0.9642746097219209\n",
      "r2_score :  0.9864421522048511\n",
      "r2_score :  0.9994605273449922\n",
      "r2_score :  0.9851239319979603\n",
      "r2_score :  0.9797254043616939\n",
      "r2_score :  0.9810710455344221\n",
      "r2_score :  0.9797543085965077\n",
      "r2_score :  0.6436517637212291\n",
      "r2_score :  0.9956191883796378\n",
      "r2_score :  0.985133895457734\n",
      "r2_score :  0.9738061474659595\n",
      "r2_score :  0.9800667886991917\n",
      "r2_score :  0.9649731396993081\n",
      "r2_score :  0.9249668391779713\n",
      "r2_score :  0.9980051080306889\n",
      "r2_score :  0.8664047651293685\n",
      "r2_score :  0.99902559775241\n",
      "r2_score :  0.9947127880464395\n",
      "r2_score :  0.9914106435206438\n",
      "r2_score :  0.8885904465619257\n",
      "r2_score :  0.9744846261761303\n",
      "r2_score :  -49.247526926578374\n",
      "r2_score :  0.982819047877985\n",
      "r2_score :  0.8165345741483898\n",
      "r2_score :  0.9692822901440896\n",
      "r2_score :  0.997192786050291\n",
      "r2_score :  0.9784264680362013\n",
      "r2_score :  0.9676375323431678\n",
      "r2_score :  0.9951135631126378\n",
      "r2_score :  0.9689213899535641\n",
      "r2_score :  -0.27931046116643476\n",
      "r2_score :  0.9989629689057611\n",
      "r2_score :  0.9144040310578275\n",
      "r2_score :  0.988412897021063\n",
      "r2_score :  0.8313728824499999\n",
      "r2_score :  0.9964375994963413\n",
      "r2_score :  0.99035810196379\n",
      "r2_score :  0.9995945466801348\n",
      "r2_score :  0.9816107482669097\n",
      "r2_score :  -0.33356284632651034\n",
      "r2_score :  0.761476349691131\n",
      "r2_score :  0.9221786080770433\n",
      "r2_score :  0.9899904884779092\n",
      "r2_score :  0.9525711659966277\n",
      "r2_score :  0.9964018540912791\n",
      "r2_score :  0.9996945094765938\n",
      "r2_score :  0.4712375325995849\n",
      "r2_score :  0.8151346348705739\n",
      "r2_score :  0.998600853180059\n",
      "r2_score :  0.9788867600934018\n",
      "r2_score :  0.9117004359044915\n",
      "r2_score :  0.9918125306518784\n",
      "r2_score :  -17.004881933150344\n",
      "r2_score :  0.9259467965837669\n",
      "r2_score :  0.999535687146689\n",
      "r2_score :  0.9811202687211708\n",
      "r2_score :  0.6508861800777757\n",
      "r2_score :  0.8787012417059182\n",
      "r2_score :  0.9154459947778617\n",
      "r2_score :  -18.63247065012921\n",
      "r2_score :  0.9917265065697605\n",
      "r2_score :  0.9948153583029363\n",
      "r2_score :  0.9344117368989303\n",
      "r2_score :  0.9949215296102243\n",
      "r2_score :  0.9802963539253312\n",
      "r2_score :  0.9374277561011832\n",
      "r2_score :  0.9961353758285266\n",
      "r2_score :  0.9913804329116149\n",
      "r2_score :  0.9768758552936969\n",
      "r2_score :  0.9972954429077309\n",
      "r2_score :  0.8627883221865166\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(predictions)):\n",
    "    print('r2_score : ', r2_score(predictions[i], scaled_y_test[i]))\n",
    "    # print('Latency_r2_score : ', r2_score(predictions[i][1], scaled_y_test[i][1]))\n",
    "    \n",
    "    # print(predictions[i][1],'|', scaled_y_test[i][1])\n",
    "# print('--------------------')\n",
    "# print(scaled_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028212171 | 1.6034746226088859e-06\n",
      "0.4740873 | 0.4770761923036425\n",
      "0.53928494 | 0.4715801048708036\n",
      "0.594815 | 0.5021835315673376\n",
      "0.51900035 | 0.5709834163309614\n",
      "0.4601705 | 0.4548751953343877\n",
      "0.51705736 | 0.5171863082508924\n",
      "0.29538697 | 0.5506477057574182\n",
      "0.5018295 | 0.5106092562176064\n",
      "0.029605627 | 2.4809315688698577e-05\n",
      "0.5319015 | 0.5140742312541791\n",
      "0.51698893 | 0.7884990693611454\n",
      "0.5344096 | 0.5436569127305373\n",
      "-0.0028654523 | 1.282779698087108e-05\n",
      "0.49963063 | 0.5242157182916011\n",
      "0.017976433 | 5.919493815131134e-05\n",
      "0.006161824 | 4.222483172870064e-05\n",
      "0.49594703 | 0.5519464311198079\n",
      "0.5306203 | 0.43004013496980387\n",
      "0.06876944 | 0.0002851066960922076\n",
      "0.53697515 | 0.4698904880281912\n",
      "0.048449814 | 9.999445910435962e-05\n",
      "0.5283218 | 0.5759422952242647\n",
      "0.5473771 | 0.5070827701128722\n",
      "0.658903 | 0.5382167687456427\n",
      "0.5207573 | 0.4888570985197969\n",
      "0.48328966 | 0.5047949681541032\n",
      "0.50585884 | 0.48032852878887244\n",
      "0.5224398 | 0.47484486828435873\n",
      "0.5461555 | 0.5165302644254367\n",
      "0.5677705 | 0.5862646631073093\n",
      "0.5726301 | 0.5116645652240918\n",
      "0.5243375 | 0.516261816049035\n",
      "0.5437412 | 0.5321379519103707\n",
      "0.5484899 | 0.4556771108095391\n",
      "0.12636755 | 7.571963495653066e-06\n",
      "0.5544055 | 0.5294822416076365\n",
      "0.558413 | 0.7305790716986551\n",
      "0.48105246 | 0.49781125714013885\n",
      "0.55370504 | 0.5127494048882102\n",
      "0.5251306 | 0.508145161132274\n",
      "0.53747624 | 0.46039729468888224\n",
      "0.52974826 | 0.42275238735100823\n",
      "0.5796574 | 0.5132389991396468\n",
      "0.031814113 | 3.1624082834786347e-06\n",
      "0.5412863 | 0.537896920099394\n",
      "0.5645491 | 0.48584563955565224\n",
      "0.59788835 | 0.5529671317990219\n",
      "0.52016866 | 0.49953249806558603\n",
      "0.52546275 | 0.44062992678713037\n",
      "0.49978256 | 0.5468098783301273\n",
      "0.51884145 | 0.5244935648109298\n",
      "0.49513596 | 0.7204776269858365\n",
      "0.55053806 | 0.5348147746289693\n",
      "0.5564503 | 0.7848929885577832\n",
      "0.64520895 | 0.5007144815672575\n",
      "-0.0073168874 | 4.6322600208701094e-06\n",
      "0.5339421 | 0.4525127872647057\n",
      "0.5638671 | 0.5610326536917063\n",
      "0.5253211 | 0.8790641623243682\n",
      "0.56125987 | 0.593628709393564\n",
      "0.49426258 | 0.5550306254744726\n",
      "0.55541366 | 0.43485287496764097\n",
      "0.5345222 | 0.4743897041963465\n",
      "0.63288903 | 0.569311393168236\n",
      "0.521384 | 0.5416549301232484\n",
      "0.48898083 | 0.4646481949953419\n",
      "0.01939632 | 4.142309441739622e-06\n",
      "-0.0070652366 | 4.226937269043978e-05\n",
      "0.0036644265 | 3.741440786087396e-06\n",
      "-0.00089636445 | 0.000251745515749595\n",
      "0.5670975 | 0.5868083300862972\n",
      "0.47243637 | 0.6465400313675269\n",
      "0.5312464 | 0.5677261357989785\n",
      "0.554539 | 0.5550633630813508\n",
      "0.53355104 | 0.5221874119759243\n",
      "0.51202977 | 0.5740346949149009\n",
      "0.55317014 | 0.5902164263147289\n",
      "-0.02016125 | 5.96848887304418e-06\n",
      "0.5631499 | 0.4595473640569761\n",
      "0.6655748 | 0.5389328537875229\n",
      "0.5622413 | 0.5162858236274124\n",
      "0.6510082 | 0.5712615300960606\n",
      "0.19237907 | 2.734815050782932e-05\n",
      "0.5391865 | 0.5190742659961292\n",
      "0.7161182 | 0.5360272241484704\n",
      "0.5457311 | 0.4890286703044161\n",
      "0.53595656 | 0.5404427923904795\n",
      "0.5219952 | 0.5217016482471973\n",
      "0.012828976 | 4.458550270087484e-05\n",
      "0.51939243 | 0.48045315439981856\n",
      "0.5407578 | 0.6244230831930738\n",
      "0.5993214 | 0.57360389473296\n",
      "0.52930355 | 0.4666078191480169\n",
      "0.4880035 | 0.633905141291948\n",
      "0.50659204 | 0.5511091501210356\n",
      "0.5819745 | 0.5665609442398827\n",
      "0.33269092 | 0.5782352193936335\n",
      "0.5196704 | 0.6432819490982326\n",
      "0.5184945 | 0.5814956623339\n",
      "0.53734493 | 0.5000019598023165\n",
      "0.5475913 | 0.46782405464926574\n",
      "0.52941346 | 0.6027849503573165\n",
      "0.51490235 | 0.5375613930346131\n",
      "0.035870582 | 0.0002105005851791553\n",
      "0.5420485 | 0.4794330327531071\n",
      "0.5400758 | 0.49230461349936777\n",
      "0.5478711 | 0.5393743438002812\n",
      "0.47702026 | 0.5075858602757156\n",
      "0.53055537 | 0.4650129409310237\n",
      "0.5617641 | 0.5328012113716282\n",
      "0.513385 | 0.483111047209678\n",
      "0.529499 | 0.5547856501849073\n",
      "0.4541291 | 0.5519621986202635\n",
      "0.521446 | 0.47494673346385613\n",
      "0.5583916 | 0.5527940010807418\n",
      "0.58060116 | 0.4788337786538688\n",
      "0.5614344 | 0.5304626327164766\n",
      "0.61635435 | 0.48200879202951963\n",
      "0.517706 | 0.434989303933448\n",
      "0.5477754 | 2.2136857984350436e-05\n",
      "0.55743057 | 0.5247067378538134\n",
      "0.54628783 | 0.4685859723407754\n",
      "0.09407113 | 6.12438223913116e-05\n",
      "0.50192446 | 0.5542223406417924\n",
      "0.5171262 | 0.5614928063674334\n",
      "0.5803052 | 0.8844848864499446\n",
      "0.5253649 | 0.4266126634230157\n",
      "0.5146396 | 0.486126559401341\n",
      "0.55230147 | 0.5422134737834572\n",
      "0.025308246 | 2.7080904737394498e-05\n",
      "0.5484425 | 0.4987581979867129\n",
      "0.53018516 | 0.5066107695413226\n",
      "0.5216556 | 0.6696163918578409\n",
      "0.54942405 | 0.4776695224549695\n",
      "0.5625463 | 0.603059768091247\n",
      "0.50113547 | 0.446219461157698\n",
      "0.50172675 | 0.5258677425625057\n",
      "0.5503292 | 0.5606943205463358\n",
      "0.53548473 | 0.4820988983951179\n",
      "0.016079959 | 4.231391365217892e-05\n",
      "0.5439296 | 0.6931386964570871\n",
      "0.5285258 | 0.437808791352497\n",
      "0.5448015 | 0.4524971088461735\n",
      "0.48235488 | 0.7793240321115391\n",
      "0.5213762 | 0.45376821881228496\n",
      "0.5917536 | 0.5257234298464708\n",
      "0.024553567 | 2.561105300000303e-05\n",
      "0.5310857 | 0.49059775930456234\n",
      "0.51079714 | 0.7640373958788208\n",
      "0.5078034 | 0.5404879569256831\n",
      "0.6014874 | 0.5271804983278432\n",
      "0.5182076 | 0.4642218489095749\n",
      "0.52833456 | 0.4843576596468329\n",
      "-0.062137455 | 0.00023241473835481006\n",
      "0.5805173 | 0.5167474906958385\n",
      "0.51411134 | 0.5431435781464938\n",
      "0.62047905 | 0.4984224482171233\n",
      "0.20550177 | 7.269084955826945e-05\n",
      "0.01877591 | 2.9842444365220933e-06\n",
      "0.5026581 | 0.7375423829521428\n",
      "0.57153845 | 0.50025815941424\n",
      "0.5159421 | 0.4987927172320607\n",
      "0.552755 | 0.5390444734376412\n",
      "0.5140408 | 0.49742726950898575\n",
      "0.51665604 | 0.5731724264365929\n",
      "0.5310774 | 0.7084292968354002\n",
      "0.531867 | 0.7154333630688794\n",
      "0.49425173 | 0.506881133179079\n",
      "0.5953257 | 0.5671098670523558\n",
      "0.5746562 | 0.4907505348033276\n",
      "-0.0044315457 | 0.00016181731399827999\n",
      "0.53633034 | 0.5421118313087685\n",
      "-0.0054089427 | 0.0001055620793217516\n",
      "0.5563366 | 0.5002955292811392\n",
      "0.54563403 | 0.6613553796840834\n",
      "-0.0001417473 | 3.425199957739536e-05\n",
      "0.5377845 | 0.496690472919897\n",
      "0.01252009 | 9.709929659131582e-06\n",
      "0.5369266 | 0.5185747391102248\n",
      "-0.0335802 | 3.0466017829568818e-05\n",
      "0.36558038 | 0.45434649411854416\n",
      "0.2913245 | 0.4785205666109192\n",
      "0.53306776 | 0.5136578623438416\n",
      "0.5262228 | 0.4521944084701943\n",
      "0.594828 | 0.5291142887227095\n",
      "0.5481194 | 0.550949782559933\n",
      "0.50970477 | 0.7028278700280484\n",
      "0.6613829 | 0.5042702310838544\n",
      "0.5444684 | 0.5316618090293794\n",
      "0.5448002 | 0.5192423635857327\n",
      "0.5717422 | 0.4325652957136807\n",
      "0.5129061 | 0.5553142177778656\n",
      "0.5759681 | 0.5306544706386871\n",
      "0.01272732 | 0.00020618011189045915\n",
      "0.56844616 | 0.7491272643956833\n",
      "0.009424508 | 3.750348978435225e-05\n",
      "0.5296415 | 0.565042275608425\n",
      "0.5611007 | 0.5938187211363433\n",
      "0.51937854 | 0.5024558104664489\n",
      "0.56421643 | 0.5131046190580798\n",
      "-0.007549897 | 3.2381279184351656e-05\n",
      "0.5237433 | 0.44953566938206185\n",
      "0.5522157 | 0.37312930187743715\n",
      "0.55010986 | 0.5256556830436656\n",
      "0.5166811 | 0.4702816467541843\n",
      "0.5535096 | 0.493712018808401\n",
      "0.018709838 | 2.9441575709568693e-05\n",
      "0.4663625 | 0.4494129590324705\n",
      "0.57160705 | 0.7370185367011288\n",
      "0.524457 | 0.5064673031035608\n",
      "0.5402695 | 0.5276743685116068\n",
      "0.50479877 | 0.6873486832177317\n",
      "0.59033763 | 0.6003983120044484\n",
      "0.2748072 | 0.42204485417378207\n",
      "0.52458435 | 0.5480146668042092\n",
      "0.5256438 | 0.4823995053458953\n",
      "0.5480946 | 0.5193648066895535\n",
      "0.5286105 | 0.7695030172938301\n",
      "0.5290964 | 0.5391044701131037\n",
      "0.5724021 | 0.5100878597194881\n",
      "0.5096769 | 0.44895739407580265\n",
      "-0.011645004 | 7.44724880278349e-05\n",
      "0.15791312 | 8.124271421218351e-05\n",
      "0.5183891 | 0.6404362270527192\n",
      "0.5229395 | 0.505157308877851\n",
      "0.5250052 | 0.5273692183827319\n",
      "0.55743825 | 0.4802069319633246\n",
      "0.520656 | 0.8593203120504146\n",
      "0.07957901 | 1.665831969043675e-05\n",
      "0.5223609 | 0.5093979647631106\n",
      "0.5356369 | 0.47530194763372574\n",
      "0.53345484 | 0.4778774396643678\n",
      "0.009902112 | 8.792385847305385e-05\n",
      "0.47352535 | 0.548868739745557\n",
      "0.58160955 | 0.5439725745263826\n",
      "0.07164831 | 7.718948669392217e-05\n",
      "0.1992366 | 0.00028590843340351205\n",
      "0.5105866 | 0.5346195515936667\n",
      "0.5904269 | 0.5595799502245844\n",
      "0.60044014 | 0.5458162140146888\n",
      "-0.039740935 | 2.5566512038263893e-05\n",
      "0.56304055 | 0.5600972489542227\n",
      "-0.010078445 | 1.2159682554784045e-05\n",
      "0.5353335 | 0.5400829014196273\n",
      "-0.004904866 | 2.9664280518264378e-05\n",
      "0.61099225 | 0.5413638103973214\n",
      "0.13405776 | 2.4942938573915995e-06\n",
      "0.5568067 | 0.5221682593623765\n",
      "0.5497947 | 0.5051631437438389\n",
      "0.53197074 | 0.5127930104897528\n",
      "0.56838906 | 0.5654330780067243\n",
      "0.11749862 | 0.0002684483764017709\n",
      "0.52574444 | 0.5264218766675023\n",
      "0.526105 | 0.4917254473738738\n",
      "0.09535359 | 0.00017834201080349932\n",
      "0.5393722 | 0.5403827957150169\n",
      "0.4983743 | 0.4849631940216765\n",
      "0.5374868 | 0.48866762126855867\n",
      "0.57486665 | 0.44323860183426805\n",
      "0.5224573 | 0.43328075718209647\n",
      "0.2674219 | 0.5164170858416576\n",
      "0.51411325 | 0.5748640921634454\n",
      "0.5448626 | 0.49126783353296594\n",
      "0.52202016 | 0.7496495517130365\n",
      "0.53032565 | 0.5490200008516232\n",
      "0.57527745 | 0.5385719383745506\n",
      "0.53147507 | 0.49701125692634224\n",
      "0.5506109 | 0.4836667847892972\n",
      "0.547948 | 0.5225541177139227\n",
      "0.47832546 | 0.4955276865727351\n",
      "0.586801 | 0.505779679736232\n",
      "0.5231663 | 0.5104216051457995\n",
      "0.55324954 | 0.6281802469386552\n",
      "0.5446655 | 0.5458872568486628\n",
      "0.5634829 | 0.5469470644922838\n",
      "0.5864283 | 0.45023571967771586\n",
      "0.56821877 | 0.704092966964325\n",
      "0.5552508 | 0.5582642547557721\n",
      "0.5505867 | 0.5372850609079836\n",
      "0.54047513 | 0.4547490998717042\n",
      "0.5662885 | 0.4554874108534921\n",
      "0.5222758 | 0.5021240248424541\n",
      "0.5039006 | 0.45531989229639125\n",
      "0.06581049 | 3.4697409194786714e-05\n",
      "0.56792223 | 0.5528970243252445\n",
      "0.55108714 | 0.5268982422533023\n",
      "0.5603516 | 0.5362373238649938\n",
      "0.5196577 | 0.5571919756428642\n",
      "0.5638779 | 0.5448865996022314\n",
      "0.5554581 | 0.5357478186954807\n",
      "0.5368727 | 0.6217102268364283\n",
      "0.5002397 | 0.5097577221110776\n",
      "0.5570122 | 0.5087918958967262\n",
      "-0.01083076 | 1.5411172761740954e-05\n",
      "0.5539082 | 0.521313785552373\n",
      "0.5638564 | 0.5130428852851093\n",
      "0.47754112 | 0.45048394645748807\n",
      "-0.029970244 | 4.0977684800004846e-05\n",
      "0.48655894 | 0.5570967470666659\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=5)\n",
    "\n",
    "# print(predictions)\n",
    "# print('-------------------------------')\n",
    "# print(scaled_y_test)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    print(predictions[i][1] , '|' , scaled_y_test[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78120196, 0.9510397321203431)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(predictions)\n",
    "predictions[:, 0][0],scaled_y_test[:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78120196"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 R2 Score: 0.8879543183627583\n",
      "Column 1 R2 Score: 0.6207964594679785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#TPS , Latency\n",
    "\n",
    "for i in range(2):  \n",
    "    r2_score_column = r2_score(predictions[:, i], scaled_y_test[:, i])\n",
    "    print(f'Column {i} R2 Score: {r2_score_column}')\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LHS SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "knob_info = pd.read_csv('Knob_Information_MySQL_v5.7.csv')\n",
    "\n",
    "knob_min = knob_info['raw_min']\n",
    "knob_max = knob_info['raw_max']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.75000000e-01 5.25001250e+04 9.17555200e+06 ... 1.14816000e+05\n",
      "  1.14816000e+05 8.75000000e-01]\n",
      " [9.87250000e-01 5.92350128e+04 1.03521188e+07 ... 1.29413888e+05\n",
      "  1.29413888e+05 9.87250000e-01]\n",
      " [5.04000000e-01 3.02404960e+04 5.28685466e+06 ... 6.65681920e+04\n",
      "  6.65681920e+04 5.04000000e-01]\n",
      " ...\n",
      " [1.32000000e-01 7.92086800e+03 1.38767565e+06 ... 1.81903360e+04\n",
      "  1.81903360e+04 1.32000000e-01]\n",
      " [1.04500000e-01 6.27089550e+03 1.09942989e+06 ... 1.46140160e+04\n",
      "  1.46140160e+04 1.04500000e-01]\n",
      " [8.01250000e-01 4.80751988e+04 8.40252928e+06 ... 1.05224960e+05\n",
      "  1.05224960e+05 8.01250000e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lhs_sampling(min_val, max_val, num_samples):\n",
    "    # LHS 샘플 생성\n",
    "    lhs_samples = np.linspace(min_val, max_val, num_samples, endpoint=False)\n",
    "    np.random.shuffle(lhs_samples)\n",
    "    return lhs_samples\n",
    "samples = lhs_sampling(knob_min, knob_max, 4000)\n",
    "\n",
    "# 생성된 LHS 샘플 출력\n",
    "print(samples)\n",
    "# samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 138)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "Y_scaler_latecy = MinMaxScaler().fit(y_train_latency)\n",
    "Y_scaler_tps  = MinMaxScaler().fit(y_train_tps)\n",
    "\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "scaled_y_train_latecy = Y_scaler_latecy.transform(y_train_latency)\n",
    "scaled_y_train_tps = Y_scaler_tps.transform(y_train_tps)\n",
    "\n",
    "scaled_y_test_latecy = Y_scaler_latecy.transform(y_test_latency)\n",
    "scaled_y_test_tps = Y_scaler_tps.transform(y_test_tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LHS sampling으로 생성한 X값에 대한 scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "new_X = np.array(samples)\n",
    "Z_scaler = MinMaxScaler().fit(new_X)\n",
    "new_X_ = Z_scaler.transform(new_X)\n",
    "# print(new_X_)\n",
    "\n",
    "predictions_new = regressor.predict(new_X_) #scaling O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.6454044e-04,  5.7587624e-01],\n",
       "       [ 3.4839360e-03,  5.7733953e-01],\n",
       "       [ 9.4152335e-04,  5.9531534e-01],\n",
       "       ...,\n",
       "       [ 4.1965336e-02,  5.1820815e-01],\n",
       "       [ 4.4861302e-02,  5.4215348e-01],\n",
       "       [ 7.8166137e-05,  5.7564116e-01]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수정한 부분 = inverse_new_ ~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### new_metrics_re = 원래 metric + predic_metric\n",
    "### predictions_new == predict_model.predict(new_sample)\n",
    "\n",
    "# Y_scaler = MinMaxScaler().fit(predictions_new)\n",
    "predictions_new_df = pd.DataFrame(predictions_new)\n",
    "\n",
    "# Y_scaler_tps = MinMaxScaler().fit(predictions_new[:, 0].reshape(-1, 1))\n",
    "# Y_scaler_latency = MinMaxScaler().fit(predictions_new[:, 1].reshape(-1, 1))\n",
    "\n",
    "# inverse를 통해서 원래 데이터 형태로\n",
    "inverse_new_pred_tps = Y_scaler_tps.inverse_transform(predictions_new[:, 0].reshape(-1, 1))\n",
    "inverse_new_pred_lat = Y_scaler_latecy.inverse_transform(predictions_new[:, 1].reshape(-1, 1))\n",
    "\n",
    "# inverse_new_pred_tps = Y_scaler_tps.inverse_transform(predictions_new_tps)\n",
    "# inverse_new_pred_lat = Y_scaler_latecy.inverse_transform(predictions_new_lat)\n",
    " \n",
    "\n",
    "inverse_new_pred_sum = np.concatenate([inverse_new_pred_tps, inverse_new_pred_lat], axis=1)\n",
    "inverse_new_pred_pd = pd.DataFrame(inverse_new_pred_sum)\n",
    "inverse_new_pred_pd.rename(columns={0: \"tps\", 1:\"latency\"}, inplace=True)\n",
    "# inverse_new_pred_pd\n",
    "\n",
    "new_metrics_re = pd.concat([metrics,inverse_new_pred_pd], axis=0)\n",
    "# new_metrics_re = new_metrics_re.drop(['index'], axis=1)\n",
    "\n",
    "new_metrics_re = new_metrics_re.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-24.159760</td>\n",
       "      <td>12362169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-2.033373</td>\n",
       "      <td>12927488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>174.697647</td>\n",
       "      <td>11634883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>186.753723</td>\n",
       "      <td>12172507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.318986</td>\n",
       "      <td>12924377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tps     latency\n",
       "0        0.216666  20847397.0\n",
       "1        0.322221  12744942.0\n",
       "2     3789.313102      1076.0\n",
       "3        0.166667  12510551.0\n",
       "4        0.266666  10686198.0\n",
       "...           ...         ...\n",
       "4995   -24.159760  12362169.0\n",
       "4996    -2.033373  12927488.0\n",
       "4997   174.697647  11634883.0\n",
       "4998   186.753723  12172507.0\n",
       "4999     0.318986  12924377.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_metrics_re = new_metrics_re.drop(['index'], axis=1)\n",
    "\n",
    "new_metrics_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>2.084740e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>1.274494e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1.076000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.251055e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>1.068620e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-0.006409</td>\n",
       "      <td>5.664213e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-0.006072</td>\n",
       "      <td>5.689327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-0.003377</td>\n",
       "      <td>5.631903e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.003193</td>\n",
       "      <td>5.655788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-0.006036</td>\n",
       "      <td>5.689189e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tps       latency\n",
       "0        0.216666  2.084740e+07\n",
       "1        0.322221  1.274494e+07\n",
       "2     3789.313102  1.076000e+03\n",
       "3        0.166667  1.251055e+07\n",
       "4        0.266666  1.068620e+07\n",
       "...           ...           ...\n",
       "4995    -0.006409  5.664213e-01\n",
       "4996    -0.006072  5.689327e-01\n",
       "4997    -0.003377  5.631903e-01\n",
       "4998    -0.003193  5.655788e-01\n",
       "4999    -0.006036  5.689189e-01\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metrics_re = new_metrics_re.drop(['index'], axis=1)\n",
    "\n",
    "new_metrics_re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인자 정리\n",
    "- new_X = samples = LHS Sampling으로 생성한 데이터\n",
    "<!-- - new_metrics = 생성한 데이터에 대해서 TabNET이 예측한 metrics + 원래 metrics (scaling X) -->\n",
    "- new_metrics_re = 원래 metric (A_metrics) + 생성한 데이터로 예측한 metric (scaling X)\n",
    "- new_Samples = 원래 config + 생성한 config (scaling X)\n",
    "- newnewnew = AutoEncoder에 넣을 수 있는 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversed_new_config = pd.DataFrame(inverse_transformed_samples)\n",
    "new_X_pd = pd.DataFrame(new_X)\n",
    "new_X_pd = round(new_X_pd).astype(int)\n",
    "for i in range(len(new_X_pd.columns)):\n",
    "    new_X_pd.rename(columns={new_X_pd.columns[i]: A_config.columns[i]}, inplace=True)   \n",
    "    \n",
    "new_Samples = pd.concat([A_config,new_X_pd] , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>stored_program_cache</th>\n",
       "      <th>sync_binlog</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>489472</td>\n",
       "      <td>200000</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>374528</td>\n",
       "      <td>50000</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>37120</td>\n",
       "      <td>660000</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>427776</td>\n",
       "      <td>430000</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>388096</td>\n",
       "      <td>880000</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>14026</td>\n",
       "      <td>2454185</td>\n",
       "      <td>233750</td>\n",
       "      <td>233750</td>\n",
       "      <td>0</td>\n",
       "      <td>2454185</td>\n",
       "      <td>250987151</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>122565</td>\n",
       "      <td>233750</td>\n",
       "      <td>23682</td>\n",
       "      <td>2338</td>\n",
       "      <td>16</td>\n",
       "      <td>3830</td>\n",
       "      <td>250987936</td>\n",
       "      <td>31423</td>\n",
       "      <td>31423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>51600</td>\n",
       "      <td>9018327</td>\n",
       "      <td>860000</td>\n",
       "      <td>860000</td>\n",
       "      <td>1</td>\n",
       "      <td>9018327</td>\n",
       "      <td>923417969</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>450890</td>\n",
       "      <td>860000</td>\n",
       "      <td>86056</td>\n",
       "      <td>8600</td>\n",
       "      <td>55</td>\n",
       "      <td>14090</td>\n",
       "      <td>923418112</td>\n",
       "      <td>112865</td>\n",
       "      <td>112865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>7921</td>\n",
       "      <td>1387676</td>\n",
       "      <td>132000</td>\n",
       "      <td>132000</td>\n",
       "      <td>0</td>\n",
       "      <td>1387676</td>\n",
       "      <td>141733921</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>69220</td>\n",
       "      <td>132000</td>\n",
       "      <td>13547</td>\n",
       "      <td>1321</td>\n",
       "      <td>9</td>\n",
       "      <td>2163</td>\n",
       "      <td>141734810</td>\n",
       "      <td>18190</td>\n",
       "      <td>18190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>6271</td>\n",
       "      <td>1099430</td>\n",
       "      <td>104500</td>\n",
       "      <td>104500</td>\n",
       "      <td>0</td>\n",
       "      <td>1099430</td>\n",
       "      <td>112206021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>54802</td>\n",
       "      <td>104500</td>\n",
       "      <td>10808</td>\n",
       "      <td>1046</td>\n",
       "      <td>8</td>\n",
       "      <td>1712</td>\n",
       "      <td>112206938</td>\n",
       "      <td>14614</td>\n",
       "      <td>14614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>48075</td>\n",
       "      <td>8402529</td>\n",
       "      <td>801250</td>\n",
       "      <td>801250</td>\n",
       "      <td>1</td>\n",
       "      <td>8402529</td>\n",
       "      <td>860335636</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>420089</td>\n",
       "      <td>801250</td>\n",
       "      <td>80204</td>\n",
       "      <td>8013</td>\n",
       "      <td>51</td>\n",
       "      <td>13128</td>\n",
       "      <td>860335840</td>\n",
       "      <td>105225</td>\n",
       "      <td>105225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                           1     24000            7700480   \n",
       "1                           0     15000             622592   \n",
       "2                           1      8000            7110656   \n",
       "3                           0     34000            8519680   \n",
       "4                           0     12000            6291456   \n",
       "...                       ...       ...                ...   \n",
       "4995                        0     14026            2454185   \n",
       "4996                        1     51600            9018327   \n",
       "4997                        0      7921            1387676   \n",
       "4998                        0      6271            1099430   \n",
       "4999                        1     48075            8402529   \n",
       "\n",
       "     binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                             485000                                   352000   \n",
       "1                             140000                                   701000   \n",
       "2                             440000                                   801000   \n",
       "3                             760000                                   303000   \n",
       "4                             380000                                   630000   \n",
       "...                              ...                                      ...   \n",
       "4995                          233750                                   233750   \n",
       "4996                          860000                                   860000   \n",
       "4997                          132000                                   132000   \n",
       "4998                          104500                                   104500   \n",
       "4999                          801250                                   801250   \n",
       "\n",
       "     binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                                0                  655360   \n",
       "1                                1                 2637824   \n",
       "2                                1                 8093696   \n",
       "3                                0                10420224   \n",
       "4                                1                 5472256   \n",
       "...                            ...                     ...   \n",
       "4995                             0                 2454185   \n",
       "4996                             1                 9018327   \n",
       "4997                             0                 1387676   \n",
       "4998                             0                 1099430   \n",
       "4999                             1                 8402529   \n",
       "\n",
       "     bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                   356515840                    7                        1   \n",
       "1                   595591168                    5                        8   \n",
       "2                   570425344                    4                        4   \n",
       "3                   343932928                    3                        4   \n",
       "4                   243269632                    1                       13   \n",
       "...                       ...                  ...                      ...   \n",
       "4995                250987151                    2                        7   \n",
       "4996                923417969                    6                       26   \n",
       "4997                141733921                    1                        4   \n",
       "4998                112206021                    1                        3   \n",
       "4999                860335636                    6                       24   \n",
       "\n",
       "      ... stored_program_cache  sync_binlog  table_definition_cache   \\\n",
       "0     ...                489472       200000                   13200   \n",
       "1     ...                374528        50000                   91600   \n",
       "2     ...                 37120       660000                   15600   \n",
       "3     ...                427776       430000                   11200   \n",
       "4     ...                388096       880000                   11600   \n",
       "...   ...                   ...          ...                     ...   \n",
       "4995  ...                122565       233750                   23682   \n",
       "4996  ...                450890       860000                   86056   \n",
       "4997  ...                 69220       132000                   13547   \n",
       "4998  ...                 54802       104500                   10808   \n",
       "4999  ...                420089       801250                   80204   \n",
       "\n",
       "     table_open_cache  table_open_cache_instances  thread_cache_size   \\\n",
       "0                 4000                          18              11520   \n",
       "1                 4000                          17              15360   \n",
       "2                    1                           9               1024   \n",
       "3                10000                           9              13568   \n",
       "4                 4000                          25               1536   \n",
       "...                ...                         ...                ...   \n",
       "4995              2338                          16               3830   \n",
       "4996              8600                          55              14090   \n",
       "4997              1321                           9               2163   \n",
       "4998              1046                           8               1712   \n",
       "4999              8013                          51              13128   \n",
       "\n",
       "     tmp_table_size  transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0          255852544                         28672                      94208   \n",
       "1          402653184                        110592                      71680   \n",
       "2          851443712                          8192                     122880   \n",
       "3          163577856                         16384                      83968   \n",
       "4          348127232                        126976                      57344   \n",
       "...              ...                           ...                        ...   \n",
       "4995       250987936                         31423                      31423   \n",
       "4996       923418112                        112865                     112865   \n",
       "4997       141734810                         18190                      18190   \n",
       "4998       112206938                         14614                      14614   \n",
       "4999       860335840                        105225                     105225   \n",
       "\n",
       "     updatable_views_with_limit   \n",
       "0                              0  \n",
       "1                              1  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "4995                           0  \n",
       "4996                           1  \n",
       "4997                           0  \n",
       "4998                           0  \n",
       "4999                           1  \n",
       "\n",
       "[5000 rows x 138 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Samples = new_Samples.reset_index()\n",
    "new_Samples = new_Samples.drop(['index'], axis=1)\n",
    "new_Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>stored_program_cache</th>\n",
       "      <th>sync_binlog</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>489472</td>\n",
       "      <td>200000</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>374528</td>\n",
       "      <td>50000</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>37120</td>\n",
       "      <td>660000</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>427776</td>\n",
       "      <td>430000</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>388096</td>\n",
       "      <td>880000</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>14026</td>\n",
       "      <td>2454185</td>\n",
       "      <td>233750</td>\n",
       "      <td>233750</td>\n",
       "      <td>0</td>\n",
       "      <td>2454185</td>\n",
       "      <td>250987151</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>122565</td>\n",
       "      <td>233750</td>\n",
       "      <td>23682</td>\n",
       "      <td>2338</td>\n",
       "      <td>16</td>\n",
       "      <td>3830</td>\n",
       "      <td>250987936</td>\n",
       "      <td>31423</td>\n",
       "      <td>31423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>51600</td>\n",
       "      <td>9018327</td>\n",
       "      <td>860000</td>\n",
       "      <td>860000</td>\n",
       "      <td>1</td>\n",
       "      <td>9018327</td>\n",
       "      <td>923417969</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>450890</td>\n",
       "      <td>860000</td>\n",
       "      <td>86056</td>\n",
       "      <td>8600</td>\n",
       "      <td>55</td>\n",
       "      <td>14090</td>\n",
       "      <td>923418112</td>\n",
       "      <td>112865</td>\n",
       "      <td>112865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>7921</td>\n",
       "      <td>1387676</td>\n",
       "      <td>132000</td>\n",
       "      <td>132000</td>\n",
       "      <td>0</td>\n",
       "      <td>1387676</td>\n",
       "      <td>141733921</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>69220</td>\n",
       "      <td>132000</td>\n",
       "      <td>13547</td>\n",
       "      <td>1321</td>\n",
       "      <td>9</td>\n",
       "      <td>2163</td>\n",
       "      <td>141734810</td>\n",
       "      <td>18190</td>\n",
       "      <td>18190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>6271</td>\n",
       "      <td>1099430</td>\n",
       "      <td>104500</td>\n",
       "      <td>104500</td>\n",
       "      <td>0</td>\n",
       "      <td>1099430</td>\n",
       "      <td>112206021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>54802</td>\n",
       "      <td>104500</td>\n",
       "      <td>10808</td>\n",
       "      <td>1046</td>\n",
       "      <td>8</td>\n",
       "      <td>1712</td>\n",
       "      <td>112206938</td>\n",
       "      <td>14614</td>\n",
       "      <td>14614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>48075</td>\n",
       "      <td>8402529</td>\n",
       "      <td>801250</td>\n",
       "      <td>801250</td>\n",
       "      <td>1</td>\n",
       "      <td>8402529</td>\n",
       "      <td>860335636</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>420089</td>\n",
       "      <td>801250</td>\n",
       "      <td>80204</td>\n",
       "      <td>8013</td>\n",
       "      <td>51</td>\n",
       "      <td>13128</td>\n",
       "      <td>860335840</td>\n",
       "      <td>105225</td>\n",
       "      <td>105225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                           1     24000            7700480   \n",
       "1                           0     15000             622592   \n",
       "2                           1      8000            7110656   \n",
       "3                           0     34000            8519680   \n",
       "4                           0     12000            6291456   \n",
       "...                       ...       ...                ...   \n",
       "4995                        0     14026            2454185   \n",
       "4996                        1     51600            9018327   \n",
       "4997                        0      7921            1387676   \n",
       "4998                        0      6271            1099430   \n",
       "4999                        1     48075            8402529   \n",
       "\n",
       "     binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                             485000                                   352000   \n",
       "1                             140000                                   701000   \n",
       "2                             440000                                   801000   \n",
       "3                             760000                                   303000   \n",
       "4                             380000                                   630000   \n",
       "...                              ...                                      ...   \n",
       "4995                          233750                                   233750   \n",
       "4996                          860000                                   860000   \n",
       "4997                          132000                                   132000   \n",
       "4998                          104500                                   104500   \n",
       "4999                          801250                                   801250   \n",
       "\n",
       "     binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                                0                  655360   \n",
       "1                                1                 2637824   \n",
       "2                                1                 8093696   \n",
       "3                                0                10420224   \n",
       "4                                1                 5472256   \n",
       "...                            ...                     ...   \n",
       "4995                             0                 2454185   \n",
       "4996                             1                 9018327   \n",
       "4997                             0                 1387676   \n",
       "4998                             0                 1099430   \n",
       "4999                             1                 8402529   \n",
       "\n",
       "     bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                   356515840                    7                        1   \n",
       "1                   595591168                    5                        8   \n",
       "2                   570425344                    4                        4   \n",
       "3                   343932928                    3                        4   \n",
       "4                   243269632                    1                       13   \n",
       "...                       ...                  ...                      ...   \n",
       "4995                250987151                    2                        7   \n",
       "4996                923417969                    6                       26   \n",
       "4997                141733921                    1                        4   \n",
       "4998                112206021                    1                        3   \n",
       "4999                860335636                    6                       24   \n",
       "\n",
       "      ... stored_program_cache  sync_binlog  table_definition_cache   \\\n",
       "0     ...                489472       200000                   13200   \n",
       "1     ...                374528        50000                   91600   \n",
       "2     ...                 37120       660000                   15600   \n",
       "3     ...                427776       430000                   11200   \n",
       "4     ...                388096       880000                   11600   \n",
       "...   ...                   ...          ...                     ...   \n",
       "4995  ...                122565       233750                   23682   \n",
       "4996  ...                450890       860000                   86056   \n",
       "4997  ...                 69220       132000                   13547   \n",
       "4998  ...                 54802       104500                   10808   \n",
       "4999  ...                420089       801250                   80204   \n",
       "\n",
       "     table_open_cache  table_open_cache_instances  thread_cache_size   \\\n",
       "0                 4000                          18              11520   \n",
       "1                 4000                          17              15360   \n",
       "2                    1                           9               1024   \n",
       "3                10000                           9              13568   \n",
       "4                 4000                          25               1536   \n",
       "...                ...                         ...                ...   \n",
       "4995              2338                          16               3830   \n",
       "4996              8600                          55              14090   \n",
       "4997              1321                           9               2163   \n",
       "4998              1046                           8               1712   \n",
       "4999              8013                          51              13128   \n",
       "\n",
       "     tmp_table_size  transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0          255852544                         28672                      94208   \n",
       "1          402653184                        110592                      71680   \n",
       "2          851443712                          8192                     122880   \n",
       "3          163577856                         16384                      83968   \n",
       "4          348127232                        126976                      57344   \n",
       "...              ...                           ...                        ...   \n",
       "4995       250987936                         31423                      31423   \n",
       "4996       923418112                        112865                     112865   \n",
       "4997       141734810                         18190                      18190   \n",
       "4998       112206938                         14614                      14614   \n",
       "4999       860335840                        105225                     105225   \n",
       "\n",
       "     updatable_views_with_limit   \n",
       "0                              0  \n",
       "1                              1  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "4995                           0  \n",
       "4996                           1  \n",
       "4997                           0  \n",
       "4998                           0  \n",
       "4999                           1  \n",
       "\n",
       "[5000 rows x 138 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>2.084740e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>1.274494e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1.076000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.251055e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>1.068620e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-0.006409</td>\n",
       "      <td>5.664213e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-0.006072</td>\n",
       "      <td>5.689327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-0.003377</td>\n",
       "      <td>5.631903e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.003193</td>\n",
       "      <td>5.655788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-0.006036</td>\n",
       "      <td>5.689189e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tps       latency\n",
       "0        0.216666  2.084740e+07\n",
       "1        0.322221  1.274494e+07\n",
       "2     3789.313102  1.076000e+03\n",
       "3        0.166667  1.251055e+07\n",
       "4        0.266666  1.068620e+07\n",
       "...           ...           ...\n",
       "4995    -0.006409  5.664213e-01\n",
       "4996    -0.006072  5.689327e-01\n",
       "4997    -0.003377  5.631903e-01\n",
       "4998    -0.003193  5.655788e-01\n",
       "4999    -0.006036  5.689189e-01\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metrics_re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW_IDEA\n",
    "### AE Train set에 추가 (1000 + 10000) AUG == new_Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_X_pd.columns)):\n",
    "    new_X_pd.rename(columns={new_X_pd.columns[i]: A_config.columns[i]}, inplace=True)   \n",
    "    \n",
    "new_Samples = pd.concat([A_config,new_X_pd] , axis=0)\n",
    "\n",
    "new_Samples = new_Samples.reset_index()\n",
    "new_Samples = new_Samples.drop(['index'], axis=1)\n",
    "# new_Samples\n",
    "\n",
    "newnewwnew = pd.concat([new_Samples, new_metrics_re], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>14026</td>\n",
       "      <td>2454185</td>\n",
       "      <td>233750</td>\n",
       "      <td>233750</td>\n",
       "      <td>0</td>\n",
       "      <td>2454185</td>\n",
       "      <td>250987151</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>23682</td>\n",
       "      <td>2338</td>\n",
       "      <td>16</td>\n",
       "      <td>3830</td>\n",
       "      <td>250987936</td>\n",
       "      <td>31423</td>\n",
       "      <td>31423</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.159760</td>\n",
       "      <td>12362169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>51600</td>\n",
       "      <td>9018327</td>\n",
       "      <td>860000</td>\n",
       "      <td>860000</td>\n",
       "      <td>1</td>\n",
       "      <td>9018327</td>\n",
       "      <td>923417969</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>86056</td>\n",
       "      <td>8600</td>\n",
       "      <td>55</td>\n",
       "      <td>14090</td>\n",
       "      <td>923418112</td>\n",
       "      <td>112865</td>\n",
       "      <td>112865</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.033373</td>\n",
       "      <td>12927488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>7921</td>\n",
       "      <td>1387676</td>\n",
       "      <td>132000</td>\n",
       "      <td>132000</td>\n",
       "      <td>0</td>\n",
       "      <td>1387676</td>\n",
       "      <td>141733921</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13547</td>\n",
       "      <td>1321</td>\n",
       "      <td>9</td>\n",
       "      <td>2163</td>\n",
       "      <td>141734810</td>\n",
       "      <td>18190</td>\n",
       "      <td>18190</td>\n",
       "      <td>0</td>\n",
       "      <td>174.697647</td>\n",
       "      <td>11634883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>6271</td>\n",
       "      <td>1099430</td>\n",
       "      <td>104500</td>\n",
       "      <td>104500</td>\n",
       "      <td>0</td>\n",
       "      <td>1099430</td>\n",
       "      <td>112206021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10808</td>\n",
       "      <td>1046</td>\n",
       "      <td>8</td>\n",
       "      <td>1712</td>\n",
       "      <td>112206938</td>\n",
       "      <td>14614</td>\n",
       "      <td>14614</td>\n",
       "      <td>0</td>\n",
       "      <td>186.753723</td>\n",
       "      <td>12172507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>48075</td>\n",
       "      <td>8402529</td>\n",
       "      <td>801250</td>\n",
       "      <td>801250</td>\n",
       "      <td>1</td>\n",
       "      <td>8402529</td>\n",
       "      <td>860335636</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>80204</td>\n",
       "      <td>8013</td>\n",
       "      <td>51</td>\n",
       "      <td>13128</td>\n",
       "      <td>860335840</td>\n",
       "      <td>105225</td>\n",
       "      <td>105225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318986</td>\n",
       "      <td>12924377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                           1     24000            7700480   \n",
       "1                           0     15000             622592   \n",
       "2                           1      8000            7110656   \n",
       "3                           0     34000            8519680   \n",
       "4                           0     12000            6291456   \n",
       "...                       ...       ...                ...   \n",
       "4995                        0     14026            2454185   \n",
       "4996                        1     51600            9018327   \n",
       "4997                        0      7921            1387676   \n",
       "4998                        0      6271            1099430   \n",
       "4999                        1     48075            8402529   \n",
       "\n",
       "     binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                             485000                                   352000   \n",
       "1                             140000                                   701000   \n",
       "2                             440000                                   801000   \n",
       "3                             760000                                   303000   \n",
       "4                             380000                                   630000   \n",
       "...                              ...                                      ...   \n",
       "4995                          233750                                   233750   \n",
       "4996                          860000                                   860000   \n",
       "4997                          132000                                   132000   \n",
       "4998                          104500                                   104500   \n",
       "4999                          801250                                   801250   \n",
       "\n",
       "     binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                                0                  655360   \n",
       "1                                1                 2637824   \n",
       "2                                1                 8093696   \n",
       "3                                0                10420224   \n",
       "4                                1                 5472256   \n",
       "...                            ...                     ...   \n",
       "4995                             0                 2454185   \n",
       "4996                             1                 9018327   \n",
       "4997                             0                 1387676   \n",
       "4998                             0                 1099430   \n",
       "4999                             1                 8402529   \n",
       "\n",
       "     bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                   356515840                    7                        1   \n",
       "1                   595591168                    5                        8   \n",
       "2                   570425344                    4                        4   \n",
       "3                   343932928                    3                        4   \n",
       "4                   243269632                    1                       13   \n",
       "...                       ...                  ...                      ...   \n",
       "4995                250987151                    2                        7   \n",
       "4996                923417969                    6                       26   \n",
       "4997                141733921                    1                        4   \n",
       "4998                112206021                    1                        3   \n",
       "4999                860335636                    6                       24   \n",
       "\n",
       "      ... table_definition_cache  table_open_cache   \\\n",
       "0     ...                   13200              4000   \n",
       "1     ...                   91600              4000   \n",
       "2     ...                   15600                 1   \n",
       "3     ...                   11200             10000   \n",
       "4     ...                   11600              4000   \n",
       "...   ...                     ...               ...   \n",
       "4995  ...                   23682              2338   \n",
       "4996  ...                   86056              8600   \n",
       "4997  ...                   13547              1321   \n",
       "4998  ...                   10808              1046   \n",
       "4999  ...                   80204              8013   \n",
       "\n",
       "     table_open_cache_instances  thread_cache_size  tmp_table_size   \\\n",
       "0                             18              11520       255852544   \n",
       "1                             17              15360       402653184   \n",
       "2                              9               1024       851443712   \n",
       "3                              9              13568       163577856   \n",
       "4                             25               1536       348127232   \n",
       "...                          ...                ...             ...   \n",
       "4995                          16               3830       250987936   \n",
       "4996                          55              14090       923418112   \n",
       "4997                           9               2163       141734810   \n",
       "4998                           8               1712       112206938   \n",
       "4999                          51              13128       860335840   \n",
       "\n",
       "     transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0                            28672                      94208   \n",
       "1                           110592                      71680   \n",
       "2                             8192                     122880   \n",
       "3                            16384                      83968   \n",
       "4                           126976                      57344   \n",
       "...                            ...                        ...   \n",
       "4995                         31423                      31423   \n",
       "4996                        112865                     112865   \n",
       "4997                         18190                      18190   \n",
       "4998                         14614                      14614   \n",
       "4999                        105225                     105225   \n",
       "\n",
       "     updatable_views_with_limit           tps     latency  \n",
       "0                              0     0.216666  20847397.0  \n",
       "1                              1     0.322221  12744942.0  \n",
       "2                              0  3789.313102      1076.0  \n",
       "3                              0     0.166667  12510551.0  \n",
       "4                              0     0.266666  10686198.0  \n",
       "...                          ...          ...         ...  \n",
       "4995                           0   -24.159760  12362169.0  \n",
       "4996                           1    -2.033373  12927488.0  \n",
       "4997                           0   174.697647  11634883.0  \n",
       "4998                           0   186.753723  12172507.0  \n",
       "4999                           1     0.318986  12924377.0  \n",
       "\n",
       "[5000 rows x 140 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnewwnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.084740e+07\n",
       "1       1.274494e+07\n",
       "2       1.076000e+03\n",
       "3       1.251055e+07\n",
       "4       1.068620e+07\n",
       "            ...     \n",
       "4995    5.664213e-01\n",
       "4996    5.689327e-01\n",
       "4997    5.631903e-01\n",
       "4998    5.655788e-01\n",
       "4999    5.689189e-01\n",
       "Name: latency, Length: 5000, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_Samples\n",
    "new_metrics_re['latency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 138)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Samples.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원래 sample + 생성한 sample에 대해 AE가 되는지 확인\n",
    "- Config와 Metric 따로 스케일링!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_samples = scaler.fit_transform(new_Samples)\n",
    "# tps , latency 따로 scaling\n",
    "scaled_new_metrics_re_tps = scaler.fit_transform(new_metrics_re['tps'].values.reshape(-1, 1))\n",
    "scaled_new_metrics_re_lat = scaler.fit_transform(new_metrics_re['latency'].values.reshape(-1, 1))\n",
    "\n",
    "scaled_new_Samples = np.concatenate([scaled_samples,scaled_new_metrics_re_tps,scaled_new_metrics_re_lat], axis = 1)\n",
    "\n",
    "# tps , Latency 따로 sclaling하고 합친거\n",
    "X_train, X_test = train_test_split(scaled_new_Samples, test_size=0.2, shuffle=True)\n",
    "\n",
    "dataset_tr = TensorDataset(torch.tensor(X_train))\n",
    "dataset_te = TensorDataset(torch.tensor(X_test))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset_tr, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset_te, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "\n",
    "X_train, X_test = train_test_split(newnewwnew, test_size=0.2, shuffle=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# new_train = pd.concat([X_train,full_samples])\n",
    "X_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "dataset_tr = TensorDataset(torch.tensor(X_scaler))\n",
    "dataset_te = TensorDataset(torch.tensor(X_test_scaler))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset_tr, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset_te, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 원본\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = nn.Sequential(\n",
    "        # nn.Linear(140,64),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Dropout(p=0.3),\n",
    "        # nn.Linear(64,32),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(32,16), #잠재변수 15개로 줄임 \n",
    "        # nn.Sigmoid())\n",
    "        nn.Linear(140,128),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(p=0.2),\n",
    "        nn.Linear(128,64),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(p=0.2),\n",
    "        nn.Linear(64,32),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Dropout(p=0.2),\n",
    "        # nn.Linear(32,16), #잠재변수 15개로 줄임 \n",
    "        #잠재변수 15개로 줄임 \n",
    "        nn.Sigmoid())\n",
    "    \n",
    "    self.decoder = nn.Sequential(\n",
    "        # nn.Linear(16,32),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(32,64),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(64, 140), \n",
    "        # nn.Sigmoid()\n",
    "        # nn.Linear(16,32),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Dropout(p=0.2),\n",
    "        nn.Linear(32,64),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(p=0.2),\n",
    "        nn.Linear(64,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(128, 140), \n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  \n",
    "  #인코더와 디코더 연산을 차례대로 수행하도록 설정 \n",
    "  def forward(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] tr_loss : 0.126 | val_loss : 0.126\n",
      "R2_Score : -0.014198556022450648\n",
      "[301] tr_loss : 0.025 | val_loss : 0.022\n",
      "R2_Score : 0.7972968248949501\n",
      "[601] tr_loss : 0.025 | val_loss : 0.022\n",
      "R2_Score : 0.8451884941513573\n",
      "[901] tr_loss : 0.025 | val_loss : 0.022\n",
      "R2_Score : 0.7847171768215299\n",
      "[1201] tr_loss : 0.024 | val_loss : 0.022\n",
      "R2_Score : 0.8845696132472239\n",
      "[1501] tr_loss : 0.023 | val_loss : 0.021\n",
      "R2_Score : 0.8293247150575676\n",
      "[1801] tr_loss : 0.023 | val_loss : 0.021\n",
      "R2_Score : 0.8398522234620229\n",
      "[2101] tr_loss : 0.022 | val_loss : 0.021\n",
      "R2_Score : 0.8076171609106997\n",
      "[2401] tr_loss : 0.022 | val_loss : 0.022\n",
      "R2_Score : 0.763624122968811\n",
      "[2701] tr_loss : 0.022 | val_loss : 0.021\n",
      "R2_Score : 0.8562577840178072\n"
     ]
    }
   ],
   "source": [
    "# from torch import device\n",
    "from torch import optim\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# model =Autoencoder().to(device)\n",
    "model = Autoencoder().to(device)\n",
    "# model = Autoencoder()\n",
    "\n",
    "\n",
    "critertion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "#lr=1e-4\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "trainloss = []\n",
    "validationloss = []\n",
    "epoch_list = []\n",
    "\n",
    "for epoch in range(3000):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  \n",
    "  for data in trainloader:\n",
    "    inputs = data[0].float().to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs) \n",
    "    loss = critertion(inputs, outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "  train_loss = running_loss / len(trainloader)\n",
    "  trainloss.append(train_loss)\n",
    "  # epoch_list.append(epoch)\n",
    "  \n",
    "  if epoch % 300 == 0:\n",
    "    total_val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      running_loss = 0\n",
    "      \n",
    "      for data in testloader:\n",
    "        inputs = data[0].float().to(device)\n",
    "        # optimizer.zero_grad()\n",
    "        outputs = model(inputs) \n",
    "        loss = critertion(inputs, outputs)\n",
    "        running_loss += loss.item()\n",
    "        inputs_np = inputs.cpu().detach().numpy()\n",
    "        outputs_np = outputs.cpu().detach().numpy()\n",
    "      total_val_loss = running_loss / len(testloader)\n",
    "      validationloss.append(total_val_loss)\n",
    "        \n",
    "    print('[%d] tr_loss : %.3f | val_loss : %.3f' %(epoch +1, train_loss, total_val_loss))\n",
    "    print('R2_Score :', r2_score(inputs_np, outputs_np, multioutput='variance_weighted') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 140]), torch.Size([64, 140]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape , outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE_R2_Score: 0.8409458762680269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch Tensor를 NumPy 배열로 변환\n",
    "inputs_np = inputs.cpu().detach().numpy()\n",
    "outputs_np = outputs.cpu().detach().numpy()\n",
    "\n",
    "# r2_score 함수로 계산\n",
    "r2 = r2_score(inputs_np, outputs_np, multioutput='variance_weighted')\n",
    "\n",
    "# 결과 출력\n",
    "print(\"AE_R2_Score:\", r2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization in latent space\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "\n",
    "# for data in testloader:\n",
    "#     inputs = data[0].float().to(device)\n",
    "#     with torch.no_grad():\n",
    "#         encoded_vector = model.encoder(inputs)\n",
    "#         print(\"Encoded Latent Vector:\", encoded_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88, 140])\n",
      "torch.Size([88, 32])\n"
     ]
    }
   ],
   "source": [
    "# print(inputs.shape)\n",
    "# print(encoded_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_space = encoded_vector\n",
    "# print(latent_space.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet (Optimization과정에서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>automatic_sp_privileges</th>\n",
       "      <th>back_log</th>\n",
       "      <th>binlog_cache_size</th>\n",
       "      <th>binlog_group_commit_sync_delay</th>\n",
       "      <th>binlog_group_commit_sync_no_delay_count</th>\n",
       "      <th>binlog_rows_query_log_events</th>\n",
       "      <th>binlog_stmt_cache_size</th>\n",
       "      <th>bulk_insert_buffer_size</th>\n",
       "      <th>default_week_format</th>\n",
       "      <th>div_precision_increment</th>\n",
       "      <th>...</th>\n",
       "      <th>table_definition_cache</th>\n",
       "      <th>table_open_cache</th>\n",
       "      <th>table_open_cache_instances</th>\n",
       "      <th>thread_cache_size</th>\n",
       "      <th>tmp_table_size</th>\n",
       "      <th>transaction_alloc_block_size</th>\n",
       "      <th>transaction_prealloc_size</th>\n",
       "      <th>updatable_views_with_limit</th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>7700480</td>\n",
       "      <td>485000</td>\n",
       "      <td>352000</td>\n",
       "      <td>0</td>\n",
       "      <td>655360</td>\n",
       "      <td>356515840</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13200</td>\n",
       "      <td>4000</td>\n",
       "      <td>18</td>\n",
       "      <td>11520</td>\n",
       "      <td>255852544</td>\n",
       "      <td>28672</td>\n",
       "      <td>94208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>622592</td>\n",
       "      <td>140000</td>\n",
       "      <td>701000</td>\n",
       "      <td>1</td>\n",
       "      <td>2637824</td>\n",
       "      <td>595591168</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>91600</td>\n",
       "      <td>4000</td>\n",
       "      <td>17</td>\n",
       "      <td>15360</td>\n",
       "      <td>402653184</td>\n",
       "      <td>110592</td>\n",
       "      <td>71680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>7110656</td>\n",
       "      <td>440000</td>\n",
       "      <td>801000</td>\n",
       "      <td>1</td>\n",
       "      <td>8093696</td>\n",
       "      <td>570425344</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15600</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1024</td>\n",
       "      <td>851443712</td>\n",
       "      <td>8192</td>\n",
       "      <td>122880</td>\n",
       "      <td>0</td>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>8519680</td>\n",
       "      <td>760000</td>\n",
       "      <td>303000</td>\n",
       "      <td>0</td>\n",
       "      <td>10420224</td>\n",
       "      <td>343932928</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11200</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>13568</td>\n",
       "      <td>163577856</td>\n",
       "      <td>16384</td>\n",
       "      <td>83968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>6291456</td>\n",
       "      <td>380000</td>\n",
       "      <td>630000</td>\n",
       "      <td>1</td>\n",
       "      <td>5472256</td>\n",
       "      <td>243269632</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>11600</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>1536</td>\n",
       "      <td>348127232</td>\n",
       "      <td>126976</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>14026</td>\n",
       "      <td>2454185</td>\n",
       "      <td>233750</td>\n",
       "      <td>233750</td>\n",
       "      <td>0</td>\n",
       "      <td>2454185</td>\n",
       "      <td>250987151</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>23682</td>\n",
       "      <td>2338</td>\n",
       "      <td>16</td>\n",
       "      <td>3830</td>\n",
       "      <td>250987936</td>\n",
       "      <td>31423</td>\n",
       "      <td>31423</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.159760</td>\n",
       "      <td>12362169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>51600</td>\n",
       "      <td>9018327</td>\n",
       "      <td>860000</td>\n",
       "      <td>860000</td>\n",
       "      <td>1</td>\n",
       "      <td>9018327</td>\n",
       "      <td>923417969</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>86056</td>\n",
       "      <td>8600</td>\n",
       "      <td>55</td>\n",
       "      <td>14090</td>\n",
       "      <td>923418112</td>\n",
       "      <td>112865</td>\n",
       "      <td>112865</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.033373</td>\n",
       "      <td>12927488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>7921</td>\n",
       "      <td>1387676</td>\n",
       "      <td>132000</td>\n",
       "      <td>132000</td>\n",
       "      <td>0</td>\n",
       "      <td>1387676</td>\n",
       "      <td>141733921</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13547</td>\n",
       "      <td>1321</td>\n",
       "      <td>9</td>\n",
       "      <td>2163</td>\n",
       "      <td>141734810</td>\n",
       "      <td>18190</td>\n",
       "      <td>18190</td>\n",
       "      <td>0</td>\n",
       "      <td>174.697647</td>\n",
       "      <td>11634883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>6271</td>\n",
       "      <td>1099430</td>\n",
       "      <td>104500</td>\n",
       "      <td>104500</td>\n",
       "      <td>0</td>\n",
       "      <td>1099430</td>\n",
       "      <td>112206021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10808</td>\n",
       "      <td>1046</td>\n",
       "      <td>8</td>\n",
       "      <td>1712</td>\n",
       "      <td>112206938</td>\n",
       "      <td>14614</td>\n",
       "      <td>14614</td>\n",
       "      <td>0</td>\n",
       "      <td>186.753723</td>\n",
       "      <td>12172507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>48075</td>\n",
       "      <td>8402529</td>\n",
       "      <td>801250</td>\n",
       "      <td>801250</td>\n",
       "      <td>1</td>\n",
       "      <td>8402529</td>\n",
       "      <td>860335636</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>80204</td>\n",
       "      <td>8013</td>\n",
       "      <td>51</td>\n",
       "      <td>13128</td>\n",
       "      <td>860335840</td>\n",
       "      <td>105225</td>\n",
       "      <td>105225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318986</td>\n",
       "      <td>12924377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     automatic_sp_privileges  back_log  binlog_cache_size   \\\n",
       "0                           1     24000            7700480   \n",
       "1                           0     15000             622592   \n",
       "2                           1      8000            7110656   \n",
       "3                           0     34000            8519680   \n",
       "4                           0     12000            6291456   \n",
       "...                       ...       ...                ...   \n",
       "4995                        0     14026            2454185   \n",
       "4996                        1     51600            9018327   \n",
       "4997                        0      7921            1387676   \n",
       "4998                        0      6271            1099430   \n",
       "4999                        1     48075            8402529   \n",
       "\n",
       "     binlog_group_commit_sync_delay  binlog_group_commit_sync_no_delay_count   \\\n",
       "0                             485000                                   352000   \n",
       "1                             140000                                   701000   \n",
       "2                             440000                                   801000   \n",
       "3                             760000                                   303000   \n",
       "4                             380000                                   630000   \n",
       "...                              ...                                      ...   \n",
       "4995                          233750                                   233750   \n",
       "4996                          860000                                   860000   \n",
       "4997                          132000                                   132000   \n",
       "4998                          104500                                   104500   \n",
       "4999                          801250                                   801250   \n",
       "\n",
       "     binlog_rows_query_log_events  binlog_stmt_cache_size   \\\n",
       "0                                0                  655360   \n",
       "1                                1                 2637824   \n",
       "2                                1                 8093696   \n",
       "3                                0                10420224   \n",
       "4                                1                 5472256   \n",
       "...                            ...                     ...   \n",
       "4995                             0                 2454185   \n",
       "4996                             1                 9018327   \n",
       "4997                             0                 1387676   \n",
       "4998                             0                 1099430   \n",
       "4999                             1                 8402529   \n",
       "\n",
       "     bulk_insert_buffer_size  default_week_format  div_precision_increment   \\\n",
       "0                   356515840                    7                        1   \n",
       "1                   595591168                    5                        8   \n",
       "2                   570425344                    4                        4   \n",
       "3                   343932928                    3                        4   \n",
       "4                   243269632                    1                       13   \n",
       "...                       ...                  ...                      ...   \n",
       "4995                250987151                    2                        7   \n",
       "4996                923417969                    6                       26   \n",
       "4997                141733921                    1                        4   \n",
       "4998                112206021                    1                        3   \n",
       "4999                860335636                    6                       24   \n",
       "\n",
       "      ... table_definition_cache  table_open_cache   \\\n",
       "0     ...                   13200              4000   \n",
       "1     ...                   91600              4000   \n",
       "2     ...                   15600                 1   \n",
       "3     ...                   11200             10000   \n",
       "4     ...                   11600              4000   \n",
       "...   ...                     ...               ...   \n",
       "4995  ...                   23682              2338   \n",
       "4996  ...                   86056              8600   \n",
       "4997  ...                   13547              1321   \n",
       "4998  ...                   10808              1046   \n",
       "4999  ...                   80204              8013   \n",
       "\n",
       "     table_open_cache_instances  thread_cache_size  tmp_table_size   \\\n",
       "0                             18              11520       255852544   \n",
       "1                             17              15360       402653184   \n",
       "2                              9               1024       851443712   \n",
       "3                              9              13568       163577856   \n",
       "4                             25               1536       348127232   \n",
       "...                          ...                ...             ...   \n",
       "4995                          16               3830       250987936   \n",
       "4996                          55              14090       923418112   \n",
       "4997                           9               2163       141734810   \n",
       "4998                           8               1712       112206938   \n",
       "4999                          51              13128       860335840   \n",
       "\n",
       "     transaction_alloc_block_size  transaction_prealloc_size   \\\n",
       "0                            28672                      94208   \n",
       "1                           110592                      71680   \n",
       "2                             8192                     122880   \n",
       "3                            16384                      83968   \n",
       "4                           126976                      57344   \n",
       "...                            ...                        ...   \n",
       "4995                         31423                      31423   \n",
       "4996                        112865                     112865   \n",
       "4997                         18190                      18190   \n",
       "4998                         14614                      14614   \n",
       "4999                        105225                     105225   \n",
       "\n",
       "     updatable_views_with_limit           tps     latency  \n",
       "0                              0     0.216666  20847397.0  \n",
       "1                              1     0.322221  12744942.0  \n",
       "2                              0  3789.313102      1076.0  \n",
       "3                              0     0.166667  12510551.0  \n",
       "4                              0     0.266666  10686198.0  \n",
       "...                          ...          ...         ...  \n",
       "4995                           0   -24.159760  12362169.0  \n",
       "4996                           1    -2.033373  12927488.0  \n",
       "4997                           0   174.697647  11634883.0  \n",
       "4998                           0   186.753723  12172507.0  \n",
       "4999                           1     0.318986  12924377.0  \n",
       "\n",
       "[5000 rows x 140 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnewwnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BO'S Encoded Latent Vector: tensor([[0.0575, 0.6138, 0.8563,  ..., 0.4573, 0.8201, 0.7714],\n",
      "        [0.0909, 0.7782, 0.8587,  ..., 0.5558, 0.6487, 0.7060],\n",
      "        [0.3300, 0.7510, 0.6827,  ..., 0.7445, 0.4633, 0.6043],\n",
      "        ...,\n",
      "        [0.8455, 0.9490, 0.9923,  ..., 0.9910, 0.6729, 0.9879],\n",
      "        [0.8998, 0.9713, 0.9945,  ..., 0.9948, 0.6149, 0.9923],\n",
      "        [0.0139, 0.3480, 0.0683,  ..., 0.1807, 0.2270, 0.1046]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### 원래 데이터 + LHS Sampling data 차원을 32로 줄인 latent space 구하기\n",
    "### X = latent config (# 1500) , Y = metrics (# 2)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# scaler_x = MinMaxScaler()\n",
    "# # samples_scaler = scaler_x.fit_transform(newnewwnew)\n",
    "# samples_scaler = scaler_x.fit_transform(scaled_new_Samples)\n",
    "\n",
    "# # samples_np = samples_scaler.values\n",
    "# samples_torch = torch.Tensor(samples_scaler).to(device)\n",
    "ex_scaled_new_Samples = torch.Tensor(scaled_new_Samples).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_vector_BO = model.encoder(ex_scaled_new_Samples)\n",
    "    print(\"BO'S Encoded Latent Vector:\", encoded_vector_BO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 32])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_vector_BO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_vector_BO.shape\n",
    "new_metrics_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 32]), (5000, 2))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_vector_BO.shape , new_metrics_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>20847397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322221</td>\n",
       "      <td>12744942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3789.313102</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>12510551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266666</td>\n",
       "      <td>10686198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-24.159760</td>\n",
       "      <td>12362169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-2.033373</td>\n",
       "      <td>12927488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>174.697647</td>\n",
       "      <td>11634883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>186.753723</td>\n",
       "      <td>12172507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.318986</td>\n",
       "      <td>12924377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tps     latency\n",
       "0        0.216666  20847397.0\n",
       "1        0.322221  12744942.0\n",
       "2     3789.313102      1076.0\n",
       "3        0.166667  12510551.0\n",
       "4        0.266666  10686198.0\n",
       "...           ...         ...\n",
       "4995   -24.159760  12362169.0\n",
       "4996    -2.033373  12927488.0\n",
       "4997   174.697647  11634883.0\n",
       "4998   186.753723  12172507.0\n",
       "4999     0.318986  12924377.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metrics_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00664287, 0.59613637],\n",
       "        [0.05028929, 0.54034801],\n",
       "        [0.0060534 , 0.46704272],\n",
       "        ...,\n",
       "        [0.00931821, 0.57720615],\n",
       "        [0.00555245, 0.57567287],\n",
       "        [0.05296036, 0.55682237]]),\n",
       " array([[0.00242117, 0.56991956],\n",
       "        [0.05578837, 0.57563309],\n",
       "        [0.00914385, 0.57708539],\n",
       "        ...,\n",
       "        [0.00777202, 0.51841332],\n",
       "        [0.00285107, 0.57200318],\n",
       "        [0.00607651, 0.57562418]]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_lt_y_train , scaled_lt_y_test\n",
    "\n",
    "\n",
    "# scaled_lt_y_test_tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.14202 | val_0_mse: 0.04108 |  0:00:00s\n",
      "epoch 10 | loss: 0.01168 | val_0_mse: 0.00924 |  0:00:05s\n",
      "epoch 20 | loss: 0.01118 | val_0_mse: 0.0089  |  0:00:10s\n",
      "epoch 30 | loss: 0.01102 | val_0_mse: 0.00904 |  0:00:15s\n",
      "epoch 40 | loss: 0.01094 | val_0_mse: 0.00927 |  0:00:20s\n",
      "epoch 50 | loss: 0.01056 | val_0_mse: 0.00963 |  0:00:25s\n",
      "epoch 60 | loss: 0.01056 | val_0_mse: 0.00923 |  0:00:30s\n",
      "epoch 70 | loss: 0.01101 | val_0_mse: 0.00953 |  0:00:35s\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 20 and best_val_0_mse = 0.0089\n",
      "BEST VALID SCORE :  0.008897248121006947\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sein/mk_config/LHS+Optimization_tps-latency.ipynb Cell 68\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.172.85/home/sein/mk_config/LHS%2BOptimization_tps-latency.ipynb#Y123sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# 성능 평가\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B165.132.172.85/home/sein/mk_config/LHS%2BOptimization_tps-latency.ipynb#Y123sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBEST VALID SCORE : \u001b[39m\u001b[39m'\u001b[39m, lt_regressor\u001b[39m.\u001b[39mbest_cost)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B165.132.172.85/home/sein/mk_config/LHS%2BOptimization_tps-latency.ipynb#Y123sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mR2 SCORE : \u001b[39m\u001b[39m'\u001b[39m , r2_score(scaled_lt_y_test, lt_predictions, multioutput\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvariance_weighted\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "### TabNet\n",
    "### X = encoded_vector_BO (Scaling O) , Y = metrics (Scaling X)\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_latent = np.array(encoded_vector_BO.cpu().numpy())\n",
    "Y_latent = np.array(new_metrics_re)\n",
    "\n",
    "lt_X_train, lt_X_test, lt_y_train, lt_y_test = train_test_split(X_latent,Y_latent,test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "y_train_tps = lt_y_train[:,0][:, np.newaxis]\n",
    "y_train_latecy = lt_y_train[:,1][:, np.newaxis]\n",
    "y_test_tps = lt_y_test[:,0][:, np.newaxis]\n",
    "y_test_latecy = lt_y_test[:,1][:, np.newaxis]\n",
    "\n",
    "\n",
    "Y_scaler_tps  = MinMaxScaler().fit(y_train_tps)\n",
    "Y_scaler_latecy = MinMaxScaler().fit(y_train_latecy)\n",
    "\n",
    "\n",
    "scaled_lt_y_train_tps = Y_scaler_tps.transform(y_train_tps)\n",
    "scaled_lt_y_train_latency = Y_scaler_latecy.transform(y_train_latecy)\n",
    "\n",
    "\n",
    "scaled_lt_y_test_tps = Y_scaler_tps.transform(y_test_tps)\n",
    "scaled_lt_y_test_latency = Y_scaler_latecy.transform(y_test_latecy)\n",
    "\n",
    "\n",
    "scaled_lt_y_train = np.concatenate([scaled_lt_y_train_tps, scaled_lt_y_train_latency], axis = 1)\n",
    "scaled_lt_y_test = np.concatenate([scaled_lt_y_test_tps, scaled_lt_y_test_latency], axis = 1)\n",
    "\n",
    "# Tabnet 모델 생성\n",
    "lt_regressor = TabNetRegressor(verbose = 10,seed = 42,optimizer_fn=torch.optim.AdamW) \n",
    "    \n",
    "# 모델 학습\n",
    "lt_regressor.fit(X_train=lt_X_train, y_train=scaled_lt_y_train,\n",
    "              eval_set=[(lt_X_test, scaled_lt_y_test)],\n",
    "              patience=50, \n",
    "              batch_size = 128,\n",
    "              max_epochs=10000,\n",
    "              eval_metric=['mse'])\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "lt_predictions = lt_regressor.predict(lt_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "print('BEST VALID SCORE : ', lt_regressor.best_cost)\n",
    "print('R2 SCORE : ' , r2_score(scaled_lt_y_test, lt_predictions, multioutput='variance_weighted'))\n",
    "\n",
    "\n",
    "# print('MSE_SCORE : ', test_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.astype>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_lt_y_test.astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.863746567585121\n"
     ]
    }
   ],
   "source": [
    "# 예측값\n",
    "lt_predictions = lt_regressor.predict(lt_X_test)\n",
    "\n",
    "# 관측값\n",
    "observed_values = scaled_lt_y_test  \n",
    "\n",
    "# R2 스코어 계산\n",
    "ssr = np.sum((observed_values - lt_predictions) ** 2)  # SSR\n",
    "sst = np.sum((observed_values - np.mean(observed_values)) ** 2)  # SST\n",
    "\n",
    "r2score = 1 - (ssr / sst)\n",
    "print('R2 Score:', r2score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sein/mk_config/LHS+Optimization_tps-latency.ipynb Cell 71\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B165.132.172.85/home/sein/mk_config/LHS%2BOptimization_tps-latency.ipynb#Y323sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m r2_score(scaled_lt_y_test, lt_predictions, multioutput\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvariance_weighted\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "r2_score(scaled_lt_y_test, lt_predictions, multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VALID SCORE (R2 Score): 0.9886005177530005\n",
      "Best Model Epoch: 34\n"
     ]
    }
   ],
   "source": [
    "best_model = lt_regressor\n",
    "best_r2_score = 1 - best_model.best_cost\n",
    "\n",
    "# 최상의 모델의 에포크 번호를 얻기\n",
    "best_epoch = best_model.best_epoch\n",
    "\n",
    "# 성능 출력\n",
    "print('BEST VALID SCORE (R2 Score):', best_r2_score)\n",
    "print('Best Model Epoch:', best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.05665900e-03, 5.43692635e-01],\n",
       "       [1.51600490e-03, 5.64382758e-01],\n",
       "       [6.29513932e-03, 5.27069012e-01],\n",
       "       ...,\n",
       "       [8.41421647e-03, 5.76731784e-01],\n",
       "       [8.93822908e-01, 6.54752138e-06],\n",
       "       [6.61032755e-03, 5.95678663e-01]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_lt_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00295807,  0.56790143],\n",
       "       [-0.00607052,  0.56894195],\n",
       "       [-0.00598805,  0.57103807],\n",
       "       ...,\n",
       "       [-0.00598848,  0.57104397],\n",
       "       [-0.00604525,  0.56891561],\n",
       "       [-0.00632609,  0.56781536]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 32), (300, 2))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_X_test.shape , scaled_lt_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.31746525, 0.26020995, 0.06084776, ..., 0.00118747, 0.0038612 ,\n",
       "         0.7310653 ],\n",
       "        [0.73175013, 0.9991596 , 0.99310064, ..., 0.917063  , 0.9329298 ,\n",
       "         0.06691827],\n",
       "        [0.7671887 , 0.9965803 , 0.9675231 , ..., 0.8392722 , 0.9045803 ,\n",
       "         0.14178357],\n",
       "        ...,\n",
       "        [0.61093044, 0.10683972, 0.47569457, ..., 0.03675497, 0.3021546 ,\n",
       "         0.10509179],\n",
       "        [0.31511614, 0.19928375, 0.04729942, ..., 0.00117616, 0.00543735,\n",
       "         0.75075114],\n",
       "        [0.6606059 , 0.99821544, 0.9529776 , ..., 0.6966284 , 0.86929256,\n",
       "         0.6932039 ]], dtype=float32),\n",
       " array([[5.17438012e-01, 3.06939138e-05],\n",
       "        [5.77290124e-01, 6.13878955e-05],\n",
       "        [3.37706586e-05, 8.56315220e-01],\n",
       "        ...,\n",
       "        [6.26258683e-01, 6.67261880e-05],\n",
       "        [5.23713982e-01, 3.46976998e-05],\n",
       "        [4.59452928e-01, 3.33631632e-05]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_X_train , scaled_lt_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " ...\n",
      " [ 0.00071219 -0.00268302]\n",
      " [ 0.00072886 -0.00271483]\n",
      " [ 0.          0.        ]]\n",
      "-----------------------------------------------\n",
      "[[6.59663204e-13 8.52900483e-06]\n",
      " [4.10457294e-13 8.52905660e-06]\n",
      " [6.36125876e-09 8.52678553e-06]\n",
      " ...\n",
      " [1.45836742e-04 6.46241822e-06]\n",
      " [1.03140924e-04 7.06210675e-06]\n",
      " [3.81139128e-13 8.52904590e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(lt_predictions)\n",
    "print('-----------------------------------------------')\n",
    "print(scaled_lt_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.23794711e-01 4.41426307e-01 9.18241203e-01 ... 2.50850737e-01\n",
      "  9.71134543e-01 2.23279044e-01]\n",
      " [1.46030575e-01 8.41418207e-01 8.62705827e-01 ... 2.99709439e-01\n",
      "  2.15932012e-01 9.25122380e-01]\n",
      " [6.96771324e-01 3.86776835e-01 6.51102424e-01 ... 4.75303620e-01\n",
      "  5.61440706e-01 2.82645792e-01]\n",
      " ...\n",
      " [8.99117906e-03 7.92759180e-01 1.78370182e-03 ... 6.31797314e-02\n",
      "  1.09356776e-01 4.46293890e-01]\n",
      " [3.10261291e-03 8.73375118e-01 1.50288703e-04 ... 2.23087948e-02\n",
      "  1.10358626e-01 3.98751765e-01]\n",
      " [6.00627899e-01 3.80117774e-01 4.84747857e-01 ... 2.17551485e-01\n",
      "  5.63026488e-01 1.58527270e-01]]\n",
      "-----------------------------------------------\n",
      "[[6.59663204e-13 8.52900483e-06]\n",
      " [4.10457294e-13 8.52905660e-06]\n",
      " [6.36125876e-09 8.52678553e-06]\n",
      " ...\n",
      " [1.45836742e-04 6.46241822e-06]\n",
      " [1.03140924e-04 7.06210675e-06]\n",
      " [3.81139128e-13 8.52904590e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(lt_X_test)\n",
    "print('-----------------------------------------------')\n",
    "print(scaled_lt_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.78525694e-13, 8.53510497e-06],\n",
       "        [4.37804669e-04, 2.36799726e-06],\n",
       "        [8.77058296e-01, 8.77059645e-01],\n",
       "        ...,\n",
       "        [5.86363873e-14, 8.53520716e-06],\n",
       "        [9.25035584e-01, 9.25036309e-01],\n",
       "        [3.07845338e-13, 8.53618058e-06]]),\n",
       " array([[ 0.00265984,  0.00440948],\n",
       "        [ 0.02361161,  0.01335548],\n",
       "        [ 0.6752999 ,  0.6727661 ],\n",
       "        ...,\n",
       "        [ 0.00570246,  0.00457435],\n",
       "        [ 0.680132  ,  0.6671624 ],\n",
       "        [-0.01929884, -0.01031821]], dtype=float32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_lt_y_test, lt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 8.6209309e-01,  8.6343294e-01],\n",
       "        [-1.7992589e-03, -1.6201108e-03],\n",
       "        [-4.8071379e-05, -4.7473618e-04],\n",
       "        ...,\n",
       "        [-6.2339089e-04, -7.5627741e-04],\n",
       "        [ 4.8741698e-04, -1.4071446e-04],\n",
       "        [ 8.0739552e-01,  8.0812407e-01]], dtype=float32),\n",
       " array([[8.81996862e-01, 8.81998445e-01],\n",
       "        [2.03473552e-05, 8.23526950e-06],\n",
       "        [1.00603566e-04, 7.10807332e-06],\n",
       "        ...,\n",
       "        [3.22665924e-13, 8.53940563e-06],\n",
       "        [1.78271072e-04, 6.01720332e-06],\n",
       "        [7.97495617e-01, 7.97496896e-01]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_predictions , scaled_lt_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_X_test.shape, lt_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_lt_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions, scaled_y_test\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# r2_score(lt_predictions, lt_y_test)\n",
    "r2_score(scaled_lt_y_test, lt_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=32, step=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_pd = pd.DataFrame(encoded_vector_BO.cpu().numpy())\n",
    "latent_pd_T = latent_pd.T\n",
    "latent_pd_T.index\n",
    "# latent_pd_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_pd_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BO 코드\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "\n",
    "class BO(object):\n",
    "    def __init__(self, iteration, configs, metrics, config_info_path=None):\n",
    "        self.iteration = iteration\n",
    "        self.configs = configs\n",
    "        self.metrics = metrics\n",
    "        self.config_info_path = config_info_path\n",
    "        # self.min_max_same_knobs = []\n",
    "        \n",
    "        self._get_config_info()\n",
    "        self._init_pbounds()\n",
    "    \n",
    "    def _get_config_info(self):\n",
    "        if self.config_info_path is None:\n",
    "            self.config_info = pd.read_csv('/home/sein/mk_config/Knob_Information_MySQL_v5.7.csv', index_col=0)\n",
    "        else:\n",
    "            self.config_info = pd.read_csv(self.config_info_path, index_col=0)\n",
    "        \n",
    "        # if self.top_z_knob is not None:\n",
    "        #     self.config_info = self.config_info.loc[self.top_z_knob]\n",
    "        #     self.configs = self.configs[self.top_z_knob]\n",
    "            \n",
    "\n",
    "#     def _get_history(self):\n",
    "#         self.history_configs = self.smac.runhistory.get_configs()\n",
    "    \n",
    "    def _init_pbounds(self):\n",
    "        self.pbounds = {}\n",
    "        \n",
    "        for v in latent_pd_T.index:\n",
    "            # self.pbounds[v] = (0,18)\n",
    "            self.pbounds[str(v)] = (0, 1)\n",
    "            \n",
    "    \n",
    "    def train_regression_model(self):\n",
    "        X_all = np.array(self.configs)\n",
    "        Y_all = np.array(self.metrics)\n",
    "        \n",
    "        cnt = 0\n",
    "        while(True):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_all,Y_all,test_size=0.3, shuffle=True)         \n",
    "            \n",
    "            self.X_scaler = MinMaxScaler().fit(X_train)\n",
    "            self.y_scaler = MinMaxScaler().fit(y_train)\n",
    "\n",
    "            # scaled_X_train = self.X_scaler.transform(X_train)\n",
    "            # scaled_X_test = self.X_scaler.transform(X_test)\n",
    "            scaled_y_train = self.y_scaler.transform(y_train)\n",
    "            scaled_y_test = self.y_scaler.transform(y_test)\n",
    "            \n",
    "            \n",
    "            estimator = TabNetRegressor(verbose = 100, seed = 42, optimizer_fn=torch.optim.AdamW)\n",
    "\n",
    "            estimator.fit(X_train=X_train, y_train=scaled_y_train,\n",
    "              eval_set=[(X_test, scaled_y_test)],\n",
    "              patience=50, \n",
    "              batch_size = 128,\n",
    "              max_epochs=10000,\n",
    "              eval_metric=['mse'])\n",
    "            pred = estimator.predict(X_test)\n",
    "            accuracy = mean_squared_error(y_pred = pred, y_true = scaled_y_test)\n",
    "            r2_score_ = r2_score(scaled_y_test, pred)\n",
    "\n",
    "            cnt += 1\n",
    "            print(cnt, accuracy)\n",
    "            print(r2_score_)\n",
    "            if r2_score_ > 0.90 or cnt > 10:\n",
    "                break\n",
    "\n",
    "\n",
    "            # print('BEST VALID SCORE : ', regressor.best_cost)\n",
    "\n",
    "        self.model = estimator\n",
    "    \n",
    "    def _target_function(self, **kwargs):\n",
    "        x = np.fromiter(kwargs.values(), dtype=float)        \n",
    "        # scaled_X = self.X_scaler.transform([x])\n",
    "        res = self.model.predict(x)\n",
    "        res = res[:,0] / res[:,1]\n",
    "        # for name in self.config_info.index:\n",
    "        #     knob = self.config_info.loc[name]\n",
    "        #     knob_min = knob['raw_min']\n",
    "        #     knob_max = knob['raw_max']\n",
    "            \n",
    "            # if self.reduce_search_space:\n",
    "            #     knob_min = self.best_configs[name].min()\n",
    "            #     knob_max = self.best_configs[name].max()\n",
    "            #     if knob_min == knob_max:\n",
    "            #         self.min_max_same_knobs.append(name)\n",
    "            #         knob_max += 1\n",
    "            # with torch.no_grad():\n",
    "            #     scaled_X_t = torch.tensor(scaled_X)\n",
    "            #     scaled_X_t = scaled_X_t.to('cuda:0')\n",
    "            #     if model.decoder(scaled_X_t) < knob_min:\n",
    "            #         res == 0\n",
    "            #     elif model.decoder(scaled_X_t) > knob_max:\n",
    "            #         res == 0\n",
    "        \n",
    "        \n",
    "        return res.squeeze()\n",
    "        # return res\n",
    "    \n",
    "    \n",
    "    def tune(self):\n",
    "        self.optimizer = BayesianOptimization(f=self._target_function, pbounds=self.pbounds, verbose=2, random_state=2)\n",
    "        # self.optimizer = BayesianOptimization(f=self._target_function, verbose=2, random_state=2)\n",
    "        self.acquisition_function = UtilityFunction(kind=\"ei\", xi=0.01)\n",
    "        self.optimizer.maximize(n_iter=self.iteration, acquisition_function=self.acquisition_function)\n",
    "    \n",
    "    \n",
    "    def plot_history(self):\n",
    "        self.y_obs = - np.array([res[\"target\"] for res in self.optimizer.res])\n",
    "        \n",
    "        self.his_inc = []\n",
    "        inc = np.inf\n",
    "        ## Get minimum results on each iteration\n",
    "        for res in self.y_obs:\n",
    "            if res < inc:\n",
    "                inc = res\n",
    "            self.his_inc.append(inc)\n",
    "#             res.append(his_res)\n",
    "\n",
    "        plt.plot(self.his_inc)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('result')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 밑에 다 돌린거고 decoding해서 값 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner1 = BO(iteration=1000, \n",
    "           configs=encoded_vector_BO.cpu().numpy(),\n",
    "           metrics=new_metrics_re\n",
    "           )\n",
    "tuner1.train_regression_model()\n",
    "tuner1.tune()\n",
    "# tuner1.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [0.2515,  0.3851, 0.1983, 0.2072, 0.04203, 0.6034, 0.7527, 0.309, 0.01957, 0.107,\n",
    "           0.6571, 0.7406, 0.9737, 0.1054, 0.5471, 0.467, 0.3135, 0.9268, 0.1925, 0.1914, 0.7365,\n",
    "           0.4656, 0.9693, 0.5216, 0.2464, 0.4485, 0.282, 0.4303, 0.4483, 0.5755, 0.1848, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [0.2168, 0.0, 0.138, 1.0, 0.3111, 0.333, 0.6079, 0.1281, 0.0, 0.2796, 0.3718, 0.3238, 0.5304,\n",
    "           0.474, 0.1646, 0.5807, 0.9193, 0.09729, 0.1823, 0.1282, 0.3789, 0.4876, 0.9011, 0.1251, 0.3144,\n",
    "           0.04871, 0.8719, 1.0, 0.5318, 0.5375, 0.7821, 0.865]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = [0.8619, 0.5249, 0.6002, 0.9991, 0.3543, 0.5662, 0.6583, 0.9311, 0.7842, 0.05524,\n",
    "           0.02226, 0.5493, 0.7891, 0.3761, 0.1813, 0.631, 0.4767, 0.1582, 0.9703, 0.9681,\n",
    "           0.9885, 0.0, 0.8136, 0.3381, 0.3356, 0.998, 0.8706, 0.2109, 0.389, 0.1532, 0.0, 0.9467  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Value: tensor([6.4824e-01, 8.2373e-01, 5.4986e-01, 4.6874e-01, 5.0770e-01, 1.3226e-07,\n",
      "        7.3256e-01, 4.1707e-01, 2.4584e-01, 5.5880e-01, 4.5944e-03, 3.6874e-01,\n",
      "        4.4241e-01, 1.0000e+00, 4.1733e-01, 7.0821e-01, 4.6285e-01, 1.4779e-01,\n",
      "        1.9396e-01, 3.4814e-01, 4.1392e-01, 3.0256e-01, 3.6378e-01, 7.0773e-01,\n",
      "        8.7684e-01, 4.3775e-01, 4.7638e-01, 4.9350e-01, 5.1865e-01, 1.3259e-01,\n",
      "        6.5164e-01, 4.1798e-01, 3.8149e-01, 6.0668e-01, 2.6327e-01, 6.7646e-01,\n",
      "        2.9503e-05, 9.9994e-01, 5.3028e-01, 6.0091e-01, 6.0628e-01, 7.1926e-01,\n",
      "        4.7253e-01, 5.9855e-01, 2.6013e-01, 4.4548e-01, 3.2324e-01, 5.8244e-01,\n",
      "        8.3967e-01, 1.3947e-01, 5.7830e-01, 6.3821e-01, 4.8185e-01, 4.6733e-01,\n",
      "        3.5292e-01, 6.0820e-01, 5.9133e-01, 4.2697e-01, 5.0241e-01, 1.8115e-01,\n",
      "        3.1135e-01, 4.6330e-01, 3.3856e-01, 3.1810e-01, 9.9703e-01, 3.5718e-01,\n",
      "        5.0331e-01, 2.6912e-01, 9.9668e-01, 2.4544e-01, 5.7020e-01, 4.3492e-01,\n",
      "        9.9931e-01, 2.7908e-06, 9.4584e-01, 9.1145e-01, 4.3131e-01, 2.1991e-02,\n",
      "        7.9047e-01, 3.8945e-01, 8.3694e-01, 5.9340e-01, 8.0685e-01, 9.7410e-01,\n",
      "        3.8401e-01, 5.8893e-01, 3.4002e-01, 4.4552e-01, 2.0868e-01, 4.6806e-01,\n",
      "        3.1773e-03, 9.9862e-01, 9.9006e-01, 6.8570e-01, 2.9191e-01, 8.3099e-01,\n",
      "        3.8659e-01, 5.7107e-01, 4.6049e-01, 1.3886e-01, 2.2500e-01, 5.4938e-01,\n",
      "        2.1615e-01, 6.2396e-01, 5.2206e-01, 5.7823e-01, 6.9690e-01, 2.9053e-01,\n",
      "        3.4738e-01, 3.1790e-01, 6.3105e-01, 2.6448e-03, 6.9107e-01, 3.4266e-01,\n",
      "        3.6882e-01, 4.0680e-01, 1.6960e-01, 4.8556e-01, 9.9307e-01, 2.6245e-01,\n",
      "        4.3235e-01, 4.6868e-01, 7.9501e-01, 9.8937e-04, 9.9991e-01, 8.6744e-05,\n",
      "        9.9988e-01, 4.3804e-01, 6.9912e-01, 5.4076e-01, 5.4003e-01, 2.9762e-01,\n",
      "        1.6211e-01, 7.6746e-01, 5.2199e-01, 4.8009e-01, 1.2571e-01, 7.2677e-02,\n",
      "        4.7882e-36, 1.7572e-36], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ex_data = torch.tensor(ex_data)\n",
    "ex_data = ex_data.to('cuda:0')  # ex_data를 GPU로 이동\n",
    "\n",
    "with torch.no_grad():\n",
    "    decode_value = model.decoder(ex_data)\n",
    "    print(\"Decoded Value:\", decode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6482, device='cuda:0')\n",
      "tensor(0.8237, device='cuda:0')\n",
      "tensor(0.5499, device='cuda:0')\n",
      "tensor(0.4687, device='cuda:0')\n",
      "tensor(0.5077, device='cuda:0')\n",
      "tensor(1.3226e-07, device='cuda:0')\n",
      "tensor(0.7326, device='cuda:0')\n",
      "tensor(0.4171, device='cuda:0')\n",
      "tensor(0.2458, device='cuda:0')\n",
      "tensor(0.5588, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0')\n",
      "tensor(0.3687, device='cuda:0')\n",
      "tensor(0.4424, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0.4173, device='cuda:0')\n",
      "tensor(0.7082, device='cuda:0')\n",
      "tensor(0.4629, device='cuda:0')\n",
      "tensor(0.1478, device='cuda:0')\n",
      "tensor(0.1940, device='cuda:0')\n",
      "tensor(0.3481, device='cuda:0')\n",
      "tensor(0.4139, device='cuda:0')\n",
      "tensor(0.3026, device='cuda:0')\n",
      "tensor(0.3638, device='cuda:0')\n",
      "tensor(0.7077, device='cuda:0')\n",
      "tensor(0.8768, device='cuda:0')\n",
      "tensor(0.4378, device='cuda:0')\n",
      "tensor(0.4764, device='cuda:0')\n",
      "tensor(0.4935, device='cuda:0')\n",
      "tensor(0.5186, device='cuda:0')\n",
      "tensor(0.1326, device='cuda:0')\n",
      "tensor(0.6516, device='cuda:0')\n",
      "tensor(0.4180, device='cuda:0')\n",
      "tensor(0.3815, device='cuda:0')\n",
      "tensor(0.6067, device='cuda:0')\n",
      "tensor(0.2633, device='cuda:0')\n",
      "tensor(0.6765, device='cuda:0')\n",
      "tensor(2.9503e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0')\n",
      "tensor(0.5303, device='cuda:0')\n",
      "tensor(0.6009, device='cuda:0')\n",
      "tensor(0.6063, device='cuda:0')\n",
      "tensor(0.7193, device='cuda:0')\n",
      "tensor(0.4725, device='cuda:0')\n",
      "tensor(0.5985, device='cuda:0')\n",
      "tensor(0.2601, device='cuda:0')\n",
      "tensor(0.4455, device='cuda:0')\n",
      "tensor(0.3232, device='cuda:0')\n",
      "tensor(0.5824, device='cuda:0')\n",
      "tensor(0.8397, device='cuda:0')\n",
      "tensor(0.1395, device='cuda:0')\n",
      "tensor(0.5783, device='cuda:0')\n",
      "tensor(0.6382, device='cuda:0')\n",
      "tensor(0.4818, device='cuda:0')\n",
      "tensor(0.4673, device='cuda:0')\n",
      "tensor(0.3529, device='cuda:0')\n",
      "tensor(0.6082, device='cuda:0')\n",
      "tensor(0.5913, device='cuda:0')\n",
      "tensor(0.4270, device='cuda:0')\n",
      "tensor(0.5024, device='cuda:0')\n",
      "tensor(0.1812, device='cuda:0')\n",
      "tensor(0.3114, device='cuda:0')\n",
      "tensor(0.4633, device='cuda:0')\n",
      "tensor(0.3386, device='cuda:0')\n",
      "tensor(0.3181, device='cuda:0')\n",
      "tensor(0.9970, device='cuda:0')\n",
      "tensor(0.3572, device='cuda:0')\n",
      "tensor(0.5033, device='cuda:0')\n",
      "tensor(0.2691, device='cuda:0')\n",
      "tensor(0.9967, device='cuda:0')\n",
      "tensor(0.2454, device='cuda:0')\n",
      "tensor(0.5702, device='cuda:0')\n",
      "tensor(0.4349, device='cuda:0')\n",
      "tensor(0.9993, device='cuda:0')\n",
      "tensor(2.7908e-06, device='cuda:0')\n",
      "tensor(0.9458, device='cuda:0')\n",
      "tensor(0.9114, device='cuda:0')\n",
      "tensor(0.4313, device='cuda:0')\n",
      "tensor(0.0220, device='cuda:0')\n",
      "tensor(0.7905, device='cuda:0')\n",
      "tensor(0.3895, device='cuda:0')\n",
      "tensor(0.8369, device='cuda:0')\n",
      "tensor(0.5934, device='cuda:0')\n",
      "tensor(0.8069, device='cuda:0')\n",
      "tensor(0.9741, device='cuda:0')\n",
      "tensor(0.3840, device='cuda:0')\n",
      "tensor(0.5889, device='cuda:0')\n",
      "tensor(0.3400, device='cuda:0')\n",
      "tensor(0.4455, device='cuda:0')\n",
      "tensor(0.2087, device='cuda:0')\n",
      "tensor(0.4681, device='cuda:0')\n",
      "tensor(0.0032, device='cuda:0')\n",
      "tensor(0.9986, device='cuda:0')\n",
      "tensor(0.9901, device='cuda:0')\n",
      "tensor(0.6857, device='cuda:0')\n",
      "tensor(0.2919, device='cuda:0')\n",
      "tensor(0.8310, device='cuda:0')\n",
      "tensor(0.3866, device='cuda:0')\n",
      "tensor(0.5711, device='cuda:0')\n",
      "tensor(0.4605, device='cuda:0')\n",
      "tensor(0.1389, device='cuda:0')\n",
      "tensor(0.2250, device='cuda:0')\n",
      "tensor(0.5494, device='cuda:0')\n",
      "tensor(0.2161, device='cuda:0')\n",
      "tensor(0.6240, device='cuda:0')\n",
      "tensor(0.5221, device='cuda:0')\n",
      "tensor(0.5782, device='cuda:0')\n",
      "tensor(0.6969, device='cuda:0')\n",
      "tensor(0.2905, device='cuda:0')\n",
      "tensor(0.3474, device='cuda:0')\n",
      "tensor(0.3179, device='cuda:0')\n",
      "tensor(0.6310, device='cuda:0')\n",
      "tensor(0.0026, device='cuda:0')\n",
      "tensor(0.6911, device='cuda:0')\n",
      "tensor(0.3427, device='cuda:0')\n",
      "tensor(0.3688, device='cuda:0')\n",
      "tensor(0.4068, device='cuda:0')\n",
      "tensor(0.1696, device='cuda:0')\n",
      "tensor(0.4856, device='cuda:0')\n",
      "tensor(0.9931, device='cuda:0')\n",
      "tensor(0.2625, device='cuda:0')\n",
      "tensor(0.4323, device='cuda:0')\n",
      "tensor(0.4687, device='cuda:0')\n",
      "tensor(0.7950, device='cuda:0')\n",
      "tensor(0.0010, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0')\n",
      "tensor(8.6744e-05, device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0')\n",
      "tensor(0.4380, device='cuda:0')\n",
      "tensor(0.6991, device='cuda:0')\n",
      "tensor(0.5408, device='cuda:0')\n",
      "tensor(0.5400, device='cuda:0')\n",
      "tensor(0.2976, device='cuda:0')\n",
      "tensor(0.1621, device='cuda:0')\n",
      "tensor(0.7675, device='cuda:0')\n",
      "tensor(0.5220, device='cuda:0')\n",
      "tensor(0.4801, device='cuda:0')\n",
      "tensor(0.1257, device='cuda:0')\n",
      "tensor(0.0727, device='cuda:0')\n",
      "tensor(4.7882e-36, device='cuda:0')\n",
      "tensor(1.7572e-36, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for x in decode_value:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.912178995759835, 2.2789735949138907, 1.7330114134427155, 1.597984258355564, 1.6614631920616965, 1.000000132257975, 2.0803938716322485, 1.5175015913200782, 1.2786893807613118, 1.7485660432166548, 1.0046049419613148, 1.4459078578027134, 1.5564478061710612, 2.718281828459045, 1.5179080834726542, 2.030358978378201, 1.5885974568696961, 1.1592693894888686, 1.2140511525883404, 1.4164299047781657, 1.5127391014767344, 1.3533162940503463, 1.4387626148435155, 2.029378115761251, 2.403296714663861, 1.5492245906112134, 1.6102346297956847, 1.638033859426608, 1.6797570348813826, 1.1417782282184568, 1.9186761979531235, 1.5188868792509453, 1.4644623873146607, 1.8343245848565575, 1.301183794193486, 1.966903668002052, 1.000029503009967, 2.7181259675492755, 1.6994156630544832, 1.8237857419154884, 1.8335980932324465, 2.0529127117365844, 1.6040440646668888, 1.8194739103291697, 1.2971037858974417, 1.5612458147856194, 1.3815925051603606, 1.7903941420867773, 2.31559663458674, 1.1496588116366608, 1.7830083567872093, 1.8930919204280798, 1.619065167124534, 1.5957333896984836, 1.423214094362512, 1.837129839620432, 1.8063967306442228, 1.532603767338654, 1.6526988808079557, 1.19859772854216, 1.3652711961829023, 1.5893170576088271, 1.4029221382301917, 1.374513016749294, 2.710208123283814, 1.4292877940134558, 1.6541878179733667, 1.3088119651999566, 2.7092752231083743, 1.27818736946772, 1.7686136178479037, 1.5448461166034926, 2.7164146778287055, 1.0000027908374995, 2.5749656298846215, 2.4879236290807856, 1.5392742530874377, 1.0222343687290671, 2.2044406842352435, 1.476174637031147, 2.309278418842274, 1.810137164920086, 2.240846534373028, 2.648788374537659, 1.4681550725256702, 1.8020556550098559, 1.4049723413904016, 1.5612947172688878, 1.2320547413498792, 1.5968979990849699, 1.0031823916030018, 2.7145416905403748, 2.691401008824961, 1.9851694800392032, 1.3389771467785399, 2.29558207815929, 1.4719582245614737, 1.7701600315889783, 1.5848527617914685, 1.1489682356820414, 1.252316475948058, 1.7321824585469847, 1.2412836390821351, 1.8663088088648503, 1.6854944514841355, 1.7828834873537123, 2.007521674983064, 1.3371301591375737, 1.4153612242126876, 1.3742347786359166, 1.879580063342772, 1.002648259131014, 1.99585486833218, 1.4086870530193119, 1.4460329144884585, 1.5020052443908618, 1.1848345965396292, 1.6250785538485404, 2.6995047693844034, 1.3001122483581558, 1.5408676831007866, 1.5978818231848682, 2.214453044972499, 1.000989860451754, 2.7180323256872057, 1.0000867481583617, 2.717942899100464, 1.549663503288018, 2.0119905887386205, 1.717307804980804, 1.7160526196612391, 1.3466559013133632, 1.1759865449556304, 2.154284944303869, 1.6853865573555071, 1.6162236963378667, 1.1339535733378663, 1.0753826207370487, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "real_values = [math.exp(x) for x in decode_value]  #지수함수 없는 상태\n",
    "\n",
    "print(real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 원본\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# real_values 리스트를 NumPy 배열로 변환\n",
    "real_values = np.array(real_values)\n",
    "rescaled_actual = scaler.inverse_transform(real_values.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91217900e+00, 1.36737137e+05, 1.81239031e+07, 1.58621046e+06,\n",
       "        1.65349441e+06, 1.00000013e+00, 2.17419152e+07, 1.62723437e+09,\n",
       "        8.95082567e+00, 5.24569813e+01, 1.00460494e+00, 1.44590786e+04,\n",
       "        1.08951346e+01, 2.71828183e+00, 2.73223455e+02, 3.14553847e+01,\n",
       "        1.58859746e+03, 1.15926939e+00, 4.94455261e+03, 7.24795681e+02,\n",
       "        1.50668815e+06, 1.34684308e+03, 2.42466357e+10, 1.01468906e+02,\n",
       "        2.40329671e+00, 1.54922459e+03, 1.61023463e+02, 1.47423047e+01,\n",
       "        1.25981778e+02, 1.13593369e+05, 1.91867620e+00, 1.51888688e+00,\n",
       "        1.46446239e+00, 1.75089213e+02, 1.30118379e+00, 1.55199001e+08,\n",
       "        1.00002950e+00, 2.71812597e+00, 4.19559175e+02, 2.91805719e+01,\n",
       "        1.75023828e+04, 2.19107302e+09, 5.07253660e+01, 2.33910458e+09,\n",
       "        1.29413275e+04, 1.55543959e+05, 1.47938954e+09, 1.91159646e+09,\n",
       "        3.72651498e+04, 1.14683026e+04, 1.77517827e+02, 1.89309192e+02,\n",
       "        1.61906517e+05, 1.59573339e+07, 2.44461942e+10, 1.10227790e+05,\n",
       "        1.93179293e+09, 1.52642009e+05, 1.65269888e+00, 7.65116569e+01,\n",
       "        1.36527120e+00, 7.94599597e+03, 1.77768189e+02, 4.36099035e+01,\n",
       "        2.71020812e+00, 9.14744188e+01, 1.04559645e+02, 7.80601971e+04,\n",
       "        2.70927522e+00, 1.63329796e+02, 1.18639279e+08, 3.08969223e+02,\n",
       "        2.71641468e+00, 1.00000279e+00, 2.57496563e+00, 2.48792363e+00,\n",
       "        1.53926886e+05, 1.02223437e+00, 2.25614282e+03, 2.95234927e+02,\n",
       "        2.30927842e+00, 1.81013716e+02, 2.24084653e+00, 2.64878837e+00,\n",
       "        9.30256145e+01, 1.88201296e+07, 1.50466404e+09, 1.55068625e+04,\n",
       "        2.00671729e+04, 1.59092902e+02, 1.00318239e+00, 2.71454169e+00,\n",
       "        2.69140101e+00, 1.98516948e+00, 2.41015886e+02, 2.44956912e+09,\n",
       "        1.57852357e+09, 3.80138657e+09, 3.39213936e+09, 1.20196980e+06,\n",
       "        8.18152195e+04, 1.84940620e+09, 1.04126409e+07, 1.95696403e+06,\n",
       "        1.76175346e+06, 1.49559076e+07, 2.00752067e+06, 1.39371825e+06,\n",
       "        2.42304184e+02, 2.24908173e+02, 1.79162206e+01, 1.00264826e+00,\n",
       "        1.23743002e+02, 9.40589741e+07, 9.65950037e+07, 1.60791463e+09,\n",
       "        7.92459688e+07, 1.73205818e+09, 2.69950477e+00, 8.68949496e+07,\n",
       "        1.03334987e+08, 1.06787500e+08, 1.48319174e+08, 1.00098986e+00,\n",
       "        2.71803233e+00, 1.00008675e+00, 2.71794290e+00, 1.03443205e+08,\n",
       "        1.04814513e+06, 1.71730780e+06, 1.70349431e+05, 1.34662124e+04,\n",
       "        7.50871523e+01, 3.52958045e+04, 1.80243066e+09, 2.11210659e+05,\n",
       "        1.48492394e+05, 1.07538262e+00, 1.19577903e+11, 1.08212177e+15]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rescaled_actual.shape\n",
    "# real_values.shape\n",
    "rescaled_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.912178996</td>\n",
       "      <td>136737.136721239</td>\n",
       "      <td>18123903.122629706</td>\n",
       "      <td>1586210.462996942</td>\n",
       "      <td>1653494.412909326</td>\n",
       "      <td>1.000000132</td>\n",
       "      <td>21741915.203722715</td>\n",
       "      <td>1627234367.592443228</td>\n",
       "      <td>8.950825665</td>\n",
       "      <td>52.456981296</td>\n",
       "      <td>...</td>\n",
       "      <td>170349.430927770</td>\n",
       "      <td>13466.212357232</td>\n",
       "      <td>75.087152332</td>\n",
       "      <td>35295.804527475</td>\n",
       "      <td>1802430661.499608755</td>\n",
       "      <td>211210.659261347</td>\n",
       "      <td>148492.394305443</td>\n",
       "      <td>1.075382621</td>\n",
       "      <td>119577903103.999984741</td>\n",
       "      <td>1082121774956543.875000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                1                  2                 3    \\\n",
       "0 1.912178996 136737.136721239 18123903.122629706 1586210.462996942   \n",
       "\n",
       "                4           5                  6                    7    \\\n",
       "0 1653494.412909326 1.000000132 21741915.203722715 1627234367.592443228   \n",
       "\n",
       "          8            9    ...              130             131          132  \\\n",
       "0 8.950825665 52.456981296  ... 170349.430927770 13466.212357232 75.087152332   \n",
       "\n",
       "              133                  134              135              136  \\\n",
       "0 35295.804527475 1802430661.499608755 211210.659261347 148492.394305443   \n",
       "\n",
       "          137                    138                        139  \n",
       "0 1.075382621 119577903103.999984741 1082121774956543.875000000  \n",
       "\n",
       "[1 rows x 140 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.9f}'.format #지수함수 없이 출력하는 option\n",
    "\n",
    "rescaled_actual_pd = pd.DataFrame(rescaled_actual)\n",
    "rescaled_actual_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136737.13672123852"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(A_config.columns)\n",
    "rescaled_actual_pd.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatic_sp_privileges  = 2\n",
      "back_log  = 136737\n",
      "binlog_cache_size  = 18123903\n",
      "binlog_group_commit_sync_delay  = 1586210\n",
      "binlog_group_commit_sync_no_delay_count  = 1653494\n",
      "binlog_rows_query_log_events  = 1\n",
      "binlog_stmt_cache_size  = 21741915\n",
      "bulk_insert_buffer_size  = 1627234368\n",
      "default_week_format  = 9\n",
      "div_precision_increment  = 52\n",
      "end_markers_in_json  = 1\n",
      "eq_range_index_dive_limit  = 14459\n",
      "expire_logs_days  = 11\n",
      "explicit_defaults_for_timestamp  = 3\n",
      "flush_time  = 273\n",
      "ft_min_word_len  = 31\n",
      "ft_query_expansion_limit  = 1589\n",
      "general_log  = 1\n",
      "group_concat_max_len  = 4945\n",
      "innodb_adaptive_hash_index_parts  = 725\n",
      "innodb_adaptive_max_sleep_delay  = 1506688\n",
      "innodb_autoextend_increment  = 1347\n",
      "innodb_buffer_pool_size  = 24246635739\n",
      "innodb_change_buffer_max_size  = 101\n",
      "innodb_cmp_per_index_enabled  = 2\n",
      "innodb_commit_concurrency  = 1549\n",
      "innodb_compression_failure_threshold_pct  = 161\n",
      "innodb_compression_level  = 15\n",
      "innodb_compression_pad_pct_max  = 126\n",
      "innodb_concurrency_tickets  = 113593\n",
      "innodb_deadlock_detect  = 2\n",
      "innodb_disable_sort_file_cache  = 2\n",
      "innodb_file_per_table  = 1\n",
      "innodb_fill_factor  = 175\n",
      "innodb_flush_sync  = 1\n",
      "innodb_ft_cache_size  = 155199001\n",
      "innodb_ft_enable_diag_print  = 1\n",
      "innodb_ft_enable_stopword  = 3\n",
      "innodb_ft_max_token_size  = 420\n",
      "innodb_ft_min_token_size  = 29\n",
      "innodb_ft_num_word_optimize  = 17502\n",
      "innodb_ft_result_cache_limit  = 2191073023\n",
      "innodb_ft_sort_pll_degree  = 51\n",
      "innodb_ft_total_cache_size  = 2339104576\n",
      "innodb_io_capacity  = 12941\n",
      "innodb_io_capacity_max  = 155544\n",
      "innodb_log_buffer_size  = 1479389543\n",
      "innodb_log_file_size  = 1911596461\n",
      "innodb_log_write_ahead_size  = 37265\n",
      "innodb_lru_scan_depth  = 11468\n",
      "innodb_max_dirty_pages_pct  = 178\n",
      "innodb_max_dirty_pages_pct_lwm  = 189\n",
      "innodb_max_purge_lag  = 161907\n",
      "innodb_max_purge_lag_delay  = 15957334\n",
      "innodb_max_undo_log_size  = 24446194241\n",
      "innodb_old_blocks_time  = 110228\n",
      "innodb_online_alter_log_max_size  = 1931792931\n",
      "innodb_open_files  = 152642\n",
      "innodb_optimize_fulltext_only  = 2\n",
      "innodb_page_cleaners  = 77\n",
      "innodb_print_all_deadlocks  = 1\n",
      "innodb_purge_batch_size  = 7946\n",
      "innodb_purge_rseg_truncate_frequency  = 178\n",
      "innodb_purge_threads  = 44\n",
      "innodb_random_read_ahead  = 3\n",
      "innodb_read_ahead_threshold  = 91\n",
      "innodb_read_io_threads  = 105\n",
      "innodb_replication_delay  = 78060\n",
      "innodb_rollback_on_timeout  = 3\n",
      "innodb_rollback_segments  = 163\n",
      "innodb_sort_buffer_size  = 118639279\n",
      "innodb_spin_wait_delay  = 309\n",
      "innodb_stats_auto_recalc  = 3\n",
      "innodb_stats_include_delete_marked  = 1\n",
      "innodb_stats_on_metadata  = 3\n",
      "innodb_stats_persistent  = 2\n",
      "innodb_stats_transient_sample_pages  = 153927\n",
      "innodb_strict_mode  = 1\n",
      "innodb_sync_array_size  = 2256\n",
      "innodb_sync_spin_loops  = 295\n",
      "innodb_table_locks  = 2\n",
      "innodb_thread_concurrency  = 181\n",
      "innodb_undo_log_truncate  = 2\n",
      "innodb_use_native_aio  = 3\n",
      "innodb_write_io_threads  = 93\n",
      "join_buffer_size  = 18820130\n",
      "key_buffer_size  = 1504664043\n",
      "key_cache_age_threshold  = 15507\n",
      "key_cache_block_size  = 20067\n",
      "key_cache_division_limit  = 159\n",
      "local_infile  = 1\n",
      "log_bin_trust_function_creators  = 3\n",
      "log_queries_not_using_indexes  = 3\n",
      "log_slow_admin_statements  = 2\n",
      "long_query_time  = 241\n",
      "max_allowed_packet  = 2449569123\n",
      "max_binlog_cache_size  = 1578523573\n",
      "max_binlog_size  = 3801386568\n",
      "max_binlog_stmt_cache_size  = 3392139361\n",
      "max_digest_length  = 1201970\n",
      "max_error_count  = 81815\n",
      "max_heap_table_size  = 1849406203\n",
      "max_length_for_sort_data  = 10412641\n",
      "max_points_in_geometry  = 1956964\n",
      "max_prepared_stmt_count  = 1761753\n",
      "max_sort_length  = 14955908\n",
      "max_write_lock_count  = 2007521\n",
      "net_buffer_length  = 1393718\n",
      "net_read_timeout  = 242\n",
      "net_write_timeout  = 225\n",
      "ngram_token_size  = 18\n",
      "optimizer_prune_level  = 1\n",
      "optimizer_search_depth  = 124\n",
      "preload_buffer_size  = 94058974\n",
      "query_alloc_block_size  = 96595004\n",
      "query_cache_limit  = 1607914635\n",
      "query_cache_min_res_unit  = 79245969\n",
      "query_cache_size  = 1732058180\n",
      "query_cache_wlock_invalidate  = 3\n",
      "query_prealloc_size  = 86894950\n",
      "range_alloc_block_size  = 103334987\n",
      "read_buffer_size  = 106787500\n",
      "read_rnd_buffer_size  = 148319174\n",
      "session_track_schema  = 1\n",
      "session_track_state_change  = 3\n",
      "show_compatibility_56  = 1\n",
      "slow_query_log  = 3\n",
      "sort_buffer_size  = 103443205\n",
      "stored_program_cache  = 1048145\n",
      "sync_binlog  = 1717308\n",
      "table_definition_cache  = 170349\n",
      "table_open_cache  = 13466\n",
      "table_open_cache_instances  = 75\n",
      "thread_cache_size  = 35296\n",
      "tmp_table_size  = 1802430661\n",
      "transaction_alloc_block_size  = 211211\n",
      "transaction_prealloc_size  = 148492\n",
      "updatable_views_with_limit  = 1\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(A_config.columns)):\n",
    "    print('{} = {}'.format(A_config.columns[i], round(rescaled_actual_pd.iloc[0][i])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepare (Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_pd = pd.DataFrame(latent_space.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_pd.max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabnet type 나눈거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_all = np.array(latent_space.cpu().numpy())\n",
    "Y_all = np.array(new_metric)\n",
    "\n",
    "### 데이터 나누기\n",
    "### boolean에 해당하는 열 정리\n",
    "\n",
    "discrete_columns = [samples.columns[0], samples.columns[5],samples.columns[10],samples.columns[13],\n",
    "                    samples.columns[17],samples.columns[24],samples.columns[30],samples.columns[31],\n",
    "                    samples.columns[32],samples.columns[34],samples.columns[36],samples.columns[37],\n",
    "                    samples.columns[58],samples.columns[60],samples.columns[64],samples.columns[68],\n",
    "                    samples.columns[72],samples.columns[73],samples.columns[74],samples.columns[75],\n",
    "                    samples.columns[77],samples.columns[80],samples.columns[82],samples.columns[83],\n",
    "                    samples.columns[90],samples.columns[91],samples.columns[92],samples.columns[93],\n",
    "                    samples.columns[118],samples.columns[123],samples.columns[124],samples.columns[125],\n",
    "                    samples.columns[126]]\n",
    "\n",
    "discrete_idxs = [0, 5, 10, 13, 17, 24, 30, 31, 32, 34, 36, 37, 58, 60, 64, 68, 72, 73, 74, 75, 77, 80, 82,\n",
    "                 83, 90, 91, 92, 93, 118, 123, 124, 125, 126]\n",
    "\n",
    "discrete_dims = \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all,Y_all,test_size=0.2, shuffle=True)\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "Y_scaler = MinMaxScaler().fit(y_train)\n",
    "\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "scaled_y_train = Y_scaler.transform(y_train)\n",
    "scaled_y_test = Y_scaler.transform(y_test)\n",
    "\n",
    "# Tabnet 모델 생성\n",
    "regressor = TabNetRegressor(verbose = 10,seed = 42,optimizer_fn=torch.optim.AdamW) ### Basic\n",
    "\n",
    "# 모델 학습\n",
    "regressor.fit(X_train=scaled_X_train, y_train=scaled_y_train,\n",
    "              eval_set=[(scaled_X_test, scaled_y_test)],\n",
    "              patience=50, \n",
    "              batch_size = 128,\n",
    "              max_epochs=10000,\n",
    "              eval_metric=['mse'])\n",
    "\n",
    "# regressor.fit(X_train=scaled_X_train, y_train=scaled_y_train)\n",
    "\n",
    "\n",
    "\n",
    "# predictions_array =[]\n",
    "# CV_score_array    =[]\n",
    "\n",
    "# CV_score_array.append(regressor.best_cost)\n",
    "# predictions_array.append(np.expm1(regressor.predict(scaled_X_test)))\n",
    "\n",
    "# predictions = np.mean(predictions_array,axis=0)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "# y_pred = rf_regressor.predict(scaled_X_test)\n",
    "predictions = regressor.predict(scaled_X_test)\n",
    "\n",
    "test_score = mean_squared_error(y_pred = predictions, y_true = scaled_y_test)\n",
    "# 성능 평가\n",
    "print('BEST VALID SCORE : ', regressor.best_cost)\n",
    "print('MSE_SCORE : ', test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_all = np.array(new_knobs)\n",
    "Y_all = np.array(new_metric)\n",
    "\n",
    "est = XGBRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [15000, 20000, 25000],\n",
    "    'max_depth' : [12,13,14,15],\n",
    "    'learning_rate' : [0.1, 0.001],  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=est, param_grid=param_grid, scoring='accuracy', cv = 3)\n",
    "\n",
    "grid_search.fit(X_all,Y_all)\n",
    "\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ㅎㅎ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Shap_value\n",
    "\n",
    "###XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "# from sklearn.metrics import explained_variance_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "X_all = np.array(new_knobs)\n",
    "Y_all = np.array(new_metric)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all,Y_all,test_size=0.4, shuffle=True)\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "Y_scaler = MinMaxScaler().fit(y_train)\n",
    "\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "scaled_y_train = Y_scaler.transform(y_train)\n",
    "scaled_y_test = Y_scaler.transform(y_test)\n",
    "\n",
    "# xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "#                            colsample_bytree=1, max_depth=7)\n",
    "\n",
    "estimator = XGBRegressor(\n",
    "    objective = 'reg:squarederror',\n",
    "    random_state = 2, n_estimators = 15000, max_depth = 12, learning_rate = 0.01)\n",
    "\n",
    "my_model_pred = MultiOutputRegressor(estimator = estimator).fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "\n",
    "pred = my_model_pred.predict(scaled_X_test)\n",
    "\n",
    "#rmse\n",
    "print('RMSE : ',mean_squared_error(scaled_y_test, pred, squared=False))\n",
    "print('R2_SCORE : ', r2_score(scaled_y_test, pred))\n",
    "# print('PCC : ', precision_score(y_test, pred, average='weighted'))\n",
    "\n",
    "# rmse r2 pcc\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "\n",
    "class BO(object):\n",
    "    def __init__(self, iteration, configs, metrics,config_info_path=None):\n",
    "        self.iteration = iteration\n",
    "        self.configs = configs\n",
    "        self.metrics = metrics\n",
    "        self.config_info_path = config_info_path\n",
    "        # self.reduce_search_space = reduce_search_space\n",
    "        # self.top_z_knob = top_z_knob\n",
    "        # self.best_configs = best_configs\n",
    "        self.min_max_same_knobs = []\n",
    "        \n",
    "        self._get_config_info()\n",
    "        self._init_pbounds()\n",
    "    \n",
    "    def _get_config_info(self):\n",
    "        if self.config_info_path is None:\n",
    "            self.config_info = pd.read_csv('/home/sein/mk_config/Knob_Information_MySQL_v5.7.csv', index_col=0)\n",
    "        else:\n",
    "            self.config_info = pd.read_csv(self.config_info_path, index_col=0)\n",
    "        \n",
    "        # if self.top_z_knob is not None:\n",
    "        #     self.config_info = self.config_info.loc[self.top_z_knob]\n",
    "        #     self.configs = self.configs[self.top_z_knob]\n",
    "            \n",
    "\n",
    "#     def _get_history(self):\n",
    "#         self.history_configs = self.smac.runhistory.get_configs()\n",
    "    \n",
    "    def _init_pbounds(self):\n",
    "        self.pbounds = {}\n",
    "        \n",
    "        for name in self.config_info.index:\n",
    "            knob = self.config_info.loc[name]\n",
    "            knob_type = knob['type']\n",
    "            knob_min = knob['raw_min']\n",
    "            knob_max = knob['raw_max']\n",
    "            \n",
    "            # if self.reduce_search_space:\n",
    "            #     knob_min = self.best_configs[name].min()\n",
    "            #     knob_max = self.best_configs[name].max()\n",
    "            #     if knob_min == knob_max:\n",
    "            #         self.min_max_same_knobs.append(name)\n",
    "            #         knob_max += 1\n",
    "            \n",
    "            if knob_type == 'boolean' or knob_type == 'integer':\n",
    "                self.pbounds[name] = (int(knob_min), int(knob_max))\n",
    "            elif knob_type == 'float':\n",
    "                self.pbounds[name] = (float(knob_min), float(knob_max))\n",
    "    \n",
    "    def train_regression_model(self):\n",
    "        X_all = np.array(self.configs)\n",
    "        Y_all = np.array(self.metrics)\n",
    "\n",
    "        cnt = 0\n",
    "        while(True):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_all,Y_all,test_size=0.3, shuffle=True)\n",
    "            self.X_scaler = MinMaxScaler().fit(X_train)\n",
    "            self.y_scaler = MinMaxScaler().fit(y_train)\n",
    "\n",
    "            scaled_X_train = self.X_scaler.transform(X_train)\n",
    "            scaled_X_test = self.X_scaler.transform(X_test)\n",
    "            scaled_y_train = self.y_scaler.transform(y_train)\n",
    "            scaled_y_test = self.y_scaler.transform(y_test)\n",
    "\n",
    "            estimator = XGBRegressor(\n",
    "                objective = 'reg:squarederror',\n",
    "                random_state = 2, n_estimators = 15000, max_depth = 12, learning_rate = 0.01)\n",
    "\n",
    "            my_model_pred = MultiOutputRegressor(estimator = estimator).fit(scaled_X_train, scaled_y_train)\n",
    "            pred = my_model_pred.predict(scaled_X_test)\n",
    "            accuracy = r2_score(scaled_y_test, pred)\n",
    "\n",
    "            cnt += 1\n",
    "            print(cnt, accuracy)\n",
    "            if accuracy > 0.45 or cnt > 10:\n",
    "                break\n",
    "\n",
    "        #rmse\n",
    "        print('RMSE : ',mean_squared_error(scaled_y_test, pred, squared=False))\n",
    "        print('R2_SCORE : ', r2_score(scaled_y_test, pred))\n",
    "\n",
    "        self.model = my_model_pred\n",
    "    \n",
    "    def _target_function(self, **kwargs):\n",
    "        x = np.fromiter(kwargs.values(), dtype=float)        \n",
    "        scaled_X = self.X_scaler.transform([x])\n",
    "        \n",
    "        res = self.model.predict(scaled_X)\n",
    "        res = res[:,0] / res[:,1]\n",
    "        \n",
    "        return res.squeeze()\n",
    "#         print(y)\n",
    "        \n",
    "#         X = pd.DataFrame(config.get_dictionary().values(), index=self.config_info.index).T\n",
    "#         X = np.array(X)\n",
    "#         scaled_X = self.X_scaler.transform(X)\n",
    "        \n",
    "#         res = self.model.predict(scaled_X)\n",
    "#         res = res[:,1] / res[:,0]\n",
    "        \n",
    "#         return res # a smaller result means better\n",
    "    \n",
    "    \n",
    "    def tune(self):\n",
    "        self.optimizer = BayesianOptimization(f=self._target_function, pbounds=self.pbounds, verbose=2, random_state=2)\n",
    "        # self.optimizer = BayesianOptimization(f=self._target_function, verbose=2, random_state=2)\n",
    "        self.acquisition_function = UtilityFunction(kind=\"ei\", xi=0.01)\n",
    "        self.optimizer.maximize(n_iter=self.iteration, acquisition_function=self.acquisition_function)\n",
    "    \n",
    "    \n",
    "    def plot_history(self):\n",
    "        self.y_obs = - np.array([res[\"target\"] for res in self.optimizer.res])\n",
    "        \n",
    "        self.his_inc = []\n",
    "        inc = np.inf\n",
    "        ## Get minimum results on each iteration\n",
    "        for res in self.y_obs:\n",
    "            if res < inc:\n",
    "                inc = res\n",
    "            self.his_inc.append(inc)\n",
    "#             res.append(his_res)\n",
    "\n",
    "        plt.plot(self.his_inc)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('result')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner1 = BO(iteration=150, \n",
    "           configs=new_knobs,\n",
    "           metrics=new_metric\n",
    "           )\n",
    "tuner1.train_regression_model()\n",
    "tuner1.tune()\n",
    "# tuner1.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
